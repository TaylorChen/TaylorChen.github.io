[

  {
    "url": "/ai/2025/08/02/%E5%85%B3%E4%BA%8EAI%E5%BA%94%E7%94%A8%E7%9A%84%E6%80%9D%E8%80%83.html",
    "title": "关于AI应用的思考",
    "content": "关于AI应用的思考与IA共创1. 梯人纵发展目前的速度AI工具及应用层出不穷，几乎每天都会有新的style出来，从应用的角度来看有点应接不暇。从单纯的chat聊天模式开始，会发现有一部分的内容AI其实处理的不是很好，即使用到了一些先进的prompt词也不一定会有效果。这个可以想象AI技术能力的提升也是依赖于海量的知识数据，如果现行互联网的数据维持在一个相对静态的状态下，单纯靠AI在此基础上升华创造，不是说不肯能，只是需要的时间会更长。其实反过来如果在AI的加持下，通过人类的思维创造出更高维度的知识或者解决问题的思路，把这些方式公开到网络上，让AI进行提取学习，可能这种发展离真正的“智能”会更近一步。这种模式就是左脚踩右脚的模式，一步步靠近终极目标方向。2. 企业应用AI Accessibility现在AI应用无处不在，日常文案的优化、生活和工作中遇到问题会先用AI进行科普扫盲、AI Coding、代码review、调研报告等。但是可以看看真正企业与AI的结合程度如何？按照目前阶段来说还在初级阶段，目前使用的模型都是基于现有公开的网络的数据进行训练的，那么对于企业本身的数据在公网是无法被访问到的，这里面包括企业运过程中产生的数据、文档、知识库、业务领域知识、企业文化、日常工作流程等。成本角度  大多数企业不太可能基于开源的模型进行训练自己的私有模型，这个训练时需要额外的开销。当然大公司或者一些医院机构在使用AI的时候，会考虑用模型进行训练，给AI投喂的都是私有数据，在这种情况下进行使用的。安全角度  数据安全是目前企业考虑的一个方面，担心敏感隐私数据泄漏。这也是目前AI与企业业务结合相对慢的一个原因。这个当时也是可以解决的，就是把敏感数据排除在外进行脱敏处理，再让AI访问。从未来的角度看，如果那一天公司的相关数据能够被AI学习，那么有一天可能会出现的几个场景如下：  企业文化深度融入AI，大家日常工作中的行为、态度如果做的有不符合企业文化方面，系统会通过即时通讯工具进行提醒、在做决策时如果违反企业文化同样会被提醒，并给出对应的解决方案。  在软件研发时当一套方案出来时，AI会结合历史业务、业务代码、产品文档、知识库等直接给出方案是否可行（给打一个分），对于决策者只需要根据AI给出的结论再一次思考及决策。  日常的事物处理流程、会议形成、事情准备、日常团队沟通、培训这些，变成了AI每天或者提前规划一个人的事情，并给出重要性及优先级设定等。以上虽然目前还做不到，但是在不久的将来一定会如期而至。效率提升不等于生产力提升1. 效率提升当前AI coding是发展的非常迅猛，几乎头部公司都在开源自己的模型，从AI coding 模型的演进、AI IDE、围绕产研环节的产品非常众多（从0到1打造一款产品）。甚至在早期在国外有一些团队只有几个人凭借AI产生出几倍的ROI（这不是噱头）。对于AI从业者来说，效率的确是提升了，以工作为例，效率提升后是不是会有一些空闲时间去做其它的事情。从工作和个人方面来说可以借此机会去触达AI目前还不能涉及到的方面，例如个人成长、个人能力提升、AI实践方法论、以及使用AI过程的盲点梳理。代码编写提升效率60%，项目单侧覆盖80%，这些是AI现阶段的强项，利用这些的时候多一些自己的思考见解。2. 生产力提升效率的提升对于单次产出的确很明显。但是如果需要从生产力提升方面将，还需要多探索。例如这种效率的提升是否可以产生规模效用，使用过程中的SOP是否具有通用性，是否可以复制。这次是AI Coding的提升，那么下一次是否可以从需求理解开始到最终的交付，这个过程中如何让AI参与80%以上，真正达到AI工具在”干苦力“，对于这个过程中的使用者来说就有更多精力花在项目稳定性、安全性、可拓展、以及技术架构演进，相当于把效率本身做了一次升华及放大。生产力提升的同时，对于AI使用者来说也是能力的升华及迭代，提升AI从业者的竞争力。使用技巧在日常Al使用时，可以使用过程中的问题分为两类，待解决问题库和已验证问题库。1. 待解决问题库就是把工作中通过Al解决的，但是现在的模型还做不到的硬骨头，全部记下来，“例如根据这张草图直接生成可用代码”、“根据产品方案直接生成业务代码，达到可交付的目的”、“参考某款App的UI及业务进行复刻”等。2. 已验证问题库把你那些能够用尽AI潜力的，好的提示次（prompt） 和 交互技巧分门别类记录好，方便下次继续使用。当新的模型发布之后，不要只光看测评、不要迷信测评，可以直接用待解决问题库的问题，扔给新模型或者新工具，看看之前的问题是否能够得到解决（是骡子是马拉出来溜溜）。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/nginx/2025/07/01/Nginx-Ingress-%E9%AB%98%E5%B9%B6%E5%8F%91%E5%9C%BA%E6%99%AF%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.html",
    "title": "Nginx Ingress 高并发场景优化实践",
    "content": "在高并发/高吞吐场景下，Ingress-Nginx 的瓶颈往往在四处：连接与端口、文件句柄、握手与 TIME_WAIT、日志 I/O。本文给出值可直接落地的 Helm values.yaml 片段、Linux 内核参数、日志轮转 sidecar、压测与观测清单。1. 云负载均衡（CLB/NLB）容量  选择性能容量型/增强型实例，并调高带宽上限；入口成为系统上限的概率远高于后端。  自建 CLB 后通过注解/固定 loadBalancerIP 复用为 Ingress 入口。2. Linux 内核参数（容器内以 initContainer 动态设置）Helm values.yaml：controller:  extraInitContainers:    - name: sysctl      image: busybox      imagePullPolicy: IfNotPresent      securityContext:        privileged: true      command:        - sh        - -c        - |          sysctl -w net.core.somaxconn=65535          sysctl -w net.ipv4.ip_local_port_range=\"1024 65535\"          sysctl -w net.ipv4.tcp_tw_reuse=1          sysctl -w fs.file-max=1048576说明：  somaxconn 提升监听队列，缓解 SYN/accept 队列溢出。  ip_local_port_range 扩大源端口范围，降低端口耗尽风险。  tcp_tw_reuse 在客户端侧端口紧张时复用 TIME_WAIT（谨慎，仍以观测为准）。  fs.file-max 与容器 ulimit/worker_rlimit_nofile 对齐。3. Ingress-Nginx 配置（连接与工作线程）controller:  config:    keep-alive-requests: \"1000\"                 # client &lt;-&gt; ingress 单连接可承载请求数    upstream-keepalive-connections: \"2000\"      # ingress &lt;-&gt; upstream 空闲长连接上限    max-worker-connections: \"65536\"             # 每 worker 可开的最大连接数要点：  keep-alive-requests 过高可能导致扩容后负载不均；建议结合压测观察。  upstream-keepalive-connections 是空闲连接上限（非总连接数）；按 worker 数乘算总上限。4. 日志落盘与轮转（降低高并发下 stdout CPU 开销）controller:  config:    access-log-path: /var/log/nginx/nginx_access.log    error-log-path: /var/log/nginx/nginx_error.log  extraVolumes:    - name: log      emptyDir: {}  extraVolumeMounts:    - name: log      mountPath: /var/log/nginx  extraContainers:    - name: logrotate      image: imroc/logrotate:latest      imagePullPolicy: IfNotPresent      env:        - name: LOGROTATE_FILE_PATTERN          value: \"/var/log/nginx/nginx_*.log\"        - name: LOGROTATE_FILESIZE          value: \"100M\"        - name: LOGROTATE_FILENUM          value: \"3\"        - name: CRON_EXPR          value: \"*/1 * * * *\"        - name: CROND_LOGLEVEL          value: \"8\"      volumeMounts:        - name: log          mountPath: /var/log/nginx5. 端到端压测与观测  压测：wrk（HTTP/1.x）、h2load（HTTP/2/3）、vegeta/fortio；建议 10–30 分钟稳定压测并观测收敛。  指标：活动连接、连接错误、$upstream_response_time 分位数、5xx 率、worker_connections 使用率、TIME_WAIT 总数、端口使用率。  日志：使用 JSON 格式，记录上游地址、上游时延、路由信息，便于定位热点与异常。6. 常见排障路径  端口耗尽：增大 ip_local_port_range，提升上游 keepalive，排查异常关闭；观测 ss -s。  队列溢出/5xx：调大 somaxconn 与 backlog，核查上游超时/重试策略，查丢包。  CPU 飙升：stdout I/O 抖动，切换日志落盘+轮转；或减少日志字段。参考链接：  高并发场景优化（外部实践指南）：https://imroc.cc/tke/networking/ingress-nginx/high-concurrency"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/nginx/2025/06/28/Nginx-%E9%9B%B6%E5%81%9C%E6%9C%BA%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E4%B8%8E%E5%9B%9E%E6%BB%9A%E7%AD%96%E7%95%A5.html",
    "title": "Nginx 零停机灰度发布与回滚策略",
    "content": "从运维架构视角，结合 Nginx 的多种路由能力（权重、Header/Cookie、子域名、子路径）与容器编排（Docker/Kubernetes），构建“低风险、可审计、可回滚”的上线流程。本文给出平滑发布步骤、生产级配置、容器化集成与回滚预案。0. 目标与原则  不中断：对外 0 失败率、0 连接重置；  可回滚：故障秒级回退；  可观测：全链路指标与日志可追溯；  可审计：变更有记录，可复现。1. 平滑发布（通用步骤）1) 版本准备：构建 v2 镜像（含健康检查、版本信息接口），在 v1 旁路启动；2) 预热：v2 只接入探活与预热流量（本地缓存、JIT、连接池预连接）；3) 小流量灰度：按 1%/5%/10%/20%/50%/100% 切流，每步 5-15 分钟观察 SLI；4) 监控门禁：4xx/5xx、P95/P99、错误率、特定业务 KPI（下单/支付成功率）；5) 扩展面：流量达到 100% 后保持观察窗口（30-60 分钟）；6) 收尾：下线 v1 或保留一段时间作为热备用。  SLI/SLO 建议：错误率 &lt; 0.1%，P95 &lt; 目标阈值（如 300ms），下单成功率不下降。2. Nginx 路由策略2.1 权重切流upstream svc_v1 { server 10.0.0.1:8080 max_fails=2 fail_timeout=10s; }upstream svc_v2 { server 10.0.0.2:8080 max_fails=2 fail_timeout=10s; }map $upstream_choice $backend {  default      svc_v1;  v2           svc_v2;}# 灰度权重由外部工具写入变量（例如 lua_shared_dict / env / include 片段）map $cookie_gray $upstream_choice {  default      v1;  ~*gray=1     v2;  # 指定用户灰度}server {  location / {    proxy_next_upstream error timeout http_502 http_503 http_504; # 故障向上游重试    proxy_pass http://$backend;  }}2.2 百分比灰度（无 Cookie）借助 Nginx JavaScript（njs）或 lua，按哈希实现稳定的百分比切分：# 伪代码：基于 IP/用户ID 哈希到 0..99，&lt;10 命中 v2（10%）优势：用户命中稳定，不会在刷新间抖动；便于问题复现。2.3 子路径/子域名灰度  子路径：/v2/ 仅路由到 v2，便于 A/B 对比；  子域名：v2.api.example.com 专供内测或机器人流量。3. 容器化集成3.1 Docker Compose（蓝/绿）services:  nginx:    image: nginx:1.25    volumes: [\"./nginx.conf:/etc/nginx/nginx.conf:ro\"]    ports: [\"80:80\"]  app_v1:    image: app:1.0.0    healthcheck: { test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"], interval: 5s, retries: 5 }  app_v2:    image: app:1.1.0    healthcheck: { test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"], interval: 5s, retries: 5 }  切换方式：通过替换 map 变量/包含片段，或修改 upstream 指向容器服务名；  回滚：即时切回 app_v1。3.2 Kubernetes（Ingress/Service）  Ingress-Nginx + 两个 Service（v1/v2），通过 canary 注解分流：    metadata:annotations:  nginx.ingress.kubernetes.io/canary: \"true\"  nginx.ingress.kubernetes.io/canary-weight: \"10\" # 10%        替代方案：使用 nginx-ingress + njs/lua 做更复杂的路由，或使用 Gateway API/Service Mesh（Istio/Linkerd）进行百分比灰度、熔断、重试与熔断。4. 策略矩阵与适用场景  权重路由：最通用，适合整体灰度；  Cookie 灰度：便于定向用户/业务方验证；  Header 灰度：CI/CD/自动化探测流量；  子路径/子域名：A/B 实验或大版本对照；  哈希百分比：稳定命中，适合逐步放量。5. 生产案例（示意）  背景：交易系统网关，QPS 峰值 3w/s；  步骤：1) v2 部署完成，预热接口返回 200；2) Cookie 灰度给内部账号与监控机器人；3) 百分比灰度 1% -&gt; 5% -&gt; 10% -&gt; 20%（每步 10 分钟），观察错误率、P95、下单成功率；4) 50% -&gt; 100%，保持观察 30 分钟；5) 稳定后下线 v1，保留应急镜像与配置。  指标与日志：接入 Prometheus/Grafana，日志落 ES/ClickHouse，保留版本号与路由信息便于追踪。6. 回滚策略与演练  触发条件：错误率 &gt; 0.2% 或 P95 恶化 30% 且持续 5 分钟；  动作：1) 立即将灰度比例设为 0（或 Cookie 开关关闭）；2) 恢复 v1 权重至 100%；3) 保持观察窗口（10-30 分钟），同时收集 v2 诊断材料；4) 进入问题单流程与修复迭代；  演练：季度至少一次“带压回滚”演练（非峰值时段），验证脚本与值守响应。7. 关键配置清单  上游健康检查与 proxy_next_upstream 策略；  keepalive 连接池，proxy_http_version 1.1 与关闭 Connection: close；  请求超时/重试上限（避免风暴）；  限流与熔断（njs/lua 或接入网关/Service Mesh）。8. 审计与自动化  配置即代码（Git 管控），灰度参数来自集中配置；  CI/CD：合规检查（lint）、预热检查通过才允许放量；  ChatOps：发布与回滚都有机器人宣告与记录。9. 常见坑  预热不足：v2 首次请求抖动；  粘性策略缺失：会话跨版本导致登录/购物车异常；  观测延迟太长：等到告警触发时已影响大量用户；  权限与合规：回滚权限受限导致响应慢。  结论：Nginx + 容器编排可实现高可靠的零停机灰度。把“参数化灰度 + 可观测 + 自动化回滚”做成流程与工具，才是长期可靠之道。"
  },

  {
    "url": "/%E5%B7%A5%E5%85%B7/2025/05/13/%E5%85%85%E5%88%86%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7%E4%B9%8Bgithub.html",
    "title": "充分使用工具之github",
    "content": "定期追更的项目：1. Weekly（科技爱好者周刊）2. 《HelloGitHub》月刊无边界的学习资料库1. Librarian-pku 北大全套课程资料2. 清华大学计算机系课程攻略3. BiliBili公开课目录4. 从小学到高中所有教材5. 各教育机构学习资源6. 感觉把中医的知识全放进去了，推拿针灸啥的，几十T，应有尽有7. 各种各种资料，影视、学习、读书、自媒体神仙设计资源库1. design-resource2. Awesome Design Tools3. 中国色彩4. 字体[得意黑]Smiley Sans5. 白情包博物馆 ChineseBQB不只用来学习的GitHub1. 程序员做饭指南2. 996.ICU3. 各种资料、知识、影视、记录片、音乐、书籍、媒体聚集地，持续整理中GitHub依然固执地生长着最开放的互联网精神。"
  },

  {
    "url": "/ai/2025/05/04/AI%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84LLM%E9%80%89%E6%8B%A9%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html",
    "title": "AI 辅助编程中的 LLM 选择最佳实践",
    "content": "AI 辅助编程中的 LLM 选择最佳实践看开发阶段、试不同模型、管好成本，最终找到最适合自己的方案软件开发有不同阶段，每个阶段需要 AI 的不同能力。开发分成四个阶段，并给出如何选择模型的建议：1. 设计与架构阶段      需求：这个阶段你需要一个能深度思考、有丰富知识的模型，帮助理解业务需求并设计架构。        推荐模型：OpenAI o1、Gemini 2.5 Pro、DeepSeek R1        为什么选这些：这些模型推理能力强，能帮你做出清晰的早期决策        成本建议：这里值得用高级模型，因为好的架构能省下后期改动的麻烦  2. 开发阶段      需求：写代码时，需要模型能理解代码模式、建议补全、解释实现        推荐模型：Gemini 2.5 Pro、GPT-4o、Grok 3        额外亮点：Claude 3.7 Sonnet 虽然基准测试分数不最高，但很多开发者喜欢，建议多试试        成本建议：简单编码用中档模型就够，复杂任务再用高级模型  3. 测试阶段      需求：写测试时，模型要能发现边缘情况、写出可靠的测试代码        推荐模型：Claude 3.7、OpenAI o1、GPT-4o Mini        成本建议：普通测试用中档模型，复杂或关键测试用高级模型  4. 部署与审查阶段      需求：审查大段代码时，模型要有大上下文窗口，能一次看懂整个代码库        推荐模型：Gemini 2.5 Pro、GPT-4o Mini、GPT-4.1、OpenAI o1        成本建议：高级模型能加快审查速度，节省时间，值得投资  实用建议：如何选到适合的模型除了按阶段选模型，还有一些实用技巧：      从小模型开始：先试试中档模型（如 Claude 3 Haiku 或 GPT-3.5），不够用再升级        任务分模型：在 Cline 中，可以为不同任务设置不同模型。比如头脑风暴用高级模型，日常编码用中档，写文档用便宜的        关注花销：用 Cline 的 token 计数器，看看哪些任务花钱多，优化模型选择        别只看分数：基准测试（如 MMLU Pro、Big CodeBench）只是参考，实际用起来可能不一样        多试试：在不重要的项目上实验不同模型，找到感觉        Plan/Act 分开选：Cline 有个 Plan/Act 模式，规划可以用推理强的模型（如 Gemini 2.5 Pro），实现用快又便宜的（如 Gemini 2.5 Flash Preview）  "
  },

  {
    "url": "/%E6%80%9D%E8%80%83/2025/05/03/%E5%AE%9E%E6%97%B6%E5%8F%8D%E6%80%9D%E4%BC%98%E5%8C%96%E7%AE%A1%E7%90%86%E8%83%BD%E5%8A%9B.html",
    "title": "实时反思优化管理能力",
    "content": "实时反思，优化管理能力回顾工作这么多年，从开始的基本的coding工作开始，一线资深研发到后来的技术决策者，再到后来的创业。这些工作过程中我体会到在技术管理方面有很多道理在人生道路上也一样。总结归纳为用三个词来形容：父母心、为人真诚、反思精进，这些也是我一直再坚守执行的。1. 父母心在最近两年家里有了小朋友，在照顾小朋友的同时会去学习如何照顾、怎么哄睡、怎么做辅食、对于一些游戏怎么交小朋友去做、平时在互动的过程中如何用精简的指令让小朋友明白你的表达是什么(特别是在还不太会说话阶段)，这些都是从书中去学习，过程中越觉得其中的理念跟管理相同。书里面所讲的不是数理化，而是一个人最根本的东西：好奇心、同理心、韧性、乐观、与遇到问题用不放弃。这里面也会谈到一个话题就是作为家长对于子女的期待是什么？是出人头地吗？放到现在这个时代背景下，大部分父母应该都不会是这个答案。我的答案也很简单就是有积极向上的价值观，长大了有自己独立思考的能力，即便没有大人的依靠，依然能够很好的过自己的生活。2. 为人真诚为人真诚，众多的管理方法都更像是术，而在这些技术之上是道的层面。这个真诚既是我们对自己真诚，也是我们对身边所有人都保持真诚的态度。说到真诚，我觉得它趋于一种价值观判断，甚至是道德要求，这部分无论在工作还是生活上都是相同的。对自己真诚：作为工作十多年的老兵来说，人的能力是逐步进行提升的，这个里面没有所谓的捷径。想提高、提升自己就得多精力一些事情，特别是经历所谓的“挫折”。踩坑不可怕，可怕的是不能真诚的面对，不能想法设法地赶上来（清晰的认识自己，往往大家总是强调自己会什么？而忽略了自己不会什么）。当我们在相对顺境的情况下呢，就会遇到另外一种考验，我们也不要膨胀，而是要始终带着一颗感恩的心。对别人的真诚：遇事情不能冲动，碰到冲突态度要好但是话重要。对一个人好，有时候可以一针见血，因为对人真诚当然也包括指出对方存在的问题，他可能会不好受，但是相信平静之后大部分人还是可以理解的。痛了，改了，就是更好的自己。3. 反思精进无论从事什么工作，最开始的部分都是从基础做起，遇到一些跨界的伙伴更是如此。回顾自己工作更是如此，能够逐渐成长、成熟起来，能够独挡一面，不断优化自己的能力，其实离不开反思精进这个方法。这个里面涉及到最基本的一个话题就是认知，让我不断反思的动力，其实是源于我想成为一个什么样子的人（这个很重要，真的很重要）。我一直相信人生是长跑，再难的事情也挡不住多年的专注与死磕，这里很重要的一个点就是一定要实践。这种模式就是：实践、认识、再实践、再认识的过程，循环往复以至无穷，而实践和认识之每一循环的内容，都比较地进到了高一级的程度。很多事情想做好，都不容易的，所以也希望你身处顺境时正视自己，遇到挫折时不被外界干扰。最后关于人生的意义。随着工作和生活阅历的增加以及年龄的增长，看多了一些身边的人情冷暖，生老病死。现在想来，我觉得每一个人在人生的不同阶段会有不一样的诉求。我还是觉得一个人活在世上应该不断努力不断精进，但是目的不是出人头地，而是自我实现和这一路的风景。如果你现在就要离开这个世界，闭上眼睛回顾这一生你会想起些什么呢？那个时候你会想起的事情和人才是你现在应该珍惜的。去追求更好的自己，但是不要太计较结果，活在当下。"
  },

  {
    "url": "/%E6%80%9D%E8%80%83/2024/08/25/%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B.html",
    "title": "你需要知道的事情",
    "content": "你需要知道的事情最近“黑神话悟空”游戏比较火热，看到有一句话就是直面天命，能量满满。想到游戏中角色扮演，想到生活中每个人也是一种角色，我们不也是在“扮演”吗？以下是近期的一些思考。1. 商业熟悉所有行业的底层逻辑，冷静的思考每一个行业(特别是作为商业投资者)。任何一个商业模式再变，商业底层逻辑万变不离其宗。日常生活中就有一些类似的场景，当你在一家餐饮店吃完饭后，老板说我们现在有个活动就是充值1000元，当前这顿饭免费(例如这顿饭价值200)，这个看似划算，可能当时一心动就充值了。理解本质的话这个顿饭并不是免费的，800/1000 = 0.8，相当于8折，就是用800充值抵1000。直接打折容易产生“产品价值被贬低”等副作用，而隐形打折却让人感觉占到了便宜又不容易产生“该产品质量有问题”等等的认知问题。类似的还有骗子的诈骗电话，你接到一个电话，对方操着很奇怪的口音对你说：“我是你领导，明天到我办公室来一趟。”，你一听就知道他是骗子，你甚至会觉得你不是在被骗而是在被羞辱。或许你会想：骗子现在也太不专业了吧，接受过培训吗？有成功率的考核吗？如果你有这样的想法，那你是在是多虑了。蹩脚的骗术才是高明的骗术，其实质是条件概率在起作用。把骗子人群分为易骗人群和难骗人群，比例各占（20% 和 80%）。易骗人群中60%容易得手，40%失败。难骗人群中10%容易得手，90%失败。骗子的得手率为20%，具体公式为：20%(易骗) * 60%(得手) + 80%（难骗）*10%（得手） = 20%，得手率20%意味着骗子打5个电话能骗到1个人，看起来 “效率有点低”。但是如果能把”难骗的人群“筛选出去。那么这个条件就是故意很像骗子，当难骗的人听到奇怪的口音明显感觉不是自己的老板时，会很快挂掉电话，这样，骗子就不用在他们身上多费口舌了，而骗子真花时间去聊的人群随之缩小为“易骗人群”，这样得手率就到了60%，即打5个电话可以骗到3个。条件概率不是骗子的独家武器，当它被用到正道时，可以发挥出难以想象的巨大作用。多和找真正的从业者交流，聊聊这行的底层商业逻辑。世界都在进步，你不进则退，没有一成不变的。2. 宏观、中观、微观的结合宏观规律、中观行业的基本面特征、微观交易上的、投资的技巧。 提早做未来5-10年的预判。大的宏观-&gt;中观的产业-&gt;微观的个体。99%是选择，1%时努力。选择错了，努力不值钱。对于年轻人或者是这个阶段的你，有时间可以与不同行业了解接触，即使当前跟我没有直接关系，也愿意去听，多问问why？因为这就是信息差。透过某个想象捕捉到背后的行业变化。在疫情前有一个外卖小哥负责片区的外卖配送，但是在做这份工作的时候，发现当时有一些餐馆的餐食就是预制菜，出单很快，甚至有一些店面都没有实际的餐厅。这个小哥当时打听到预制菜这一途径，自己也开了餐馆，等这波风口过了就把餐馆直接退掉，这也不为对于信息差的利用。反而到了现在你去餐馆吃饭，有一些餐馆还特别挂出牌子说明不是预制菜。即便在目前的传统行业中，也在爆发新的变化，比如台球厅、网吧等，整体模式相比5-10年前有巨大变化。用户在迭代，商业模式也要跟上。目前播客节目也比较好，在微观世界对于个体来说，可能单独的那一期播客或者文章很少能特别影响深刻的改变生活，可这一期、那一期、再加上其他主播或者节目的某一期，会碰撞出新的思路，总会链接到一起。就算现在没用，那也比刷视频强吧。3. 资产端回报到负债端回报资产端回报：资产升值，比如房价上涨负债端回报：资产不涨的前提下，降低成本，比如每年租金。过去二三十年，资产端回报太高，对于当时房子的这点租金根本看不上，同样那个阶段前存到银行产生的利息同样可能会被忽略，也从来没考虑过负债端回报。因为经济的整体走向，以及人们对经济的预期走势向好，整体因素作用直接购买房子带来的收益相比其它途径来的更快。不过现在大周期结束了，经济也是有周期性的，上行周期和下行周期相互交替，未来10-15年，大的宏观环境不支持太高的资产回报率了，应该投具有“负债端回报的资产”。 只有一代人腾出资源和空间，下一代人的风险偏好才会改善，这种大周期基本5-10年甚至更长时间。日本走了25年。如果目前你还在考虑职业规划、投资、创业，第一件事情是“稳”、当期现金流。一定要适应经济周期性的发展规律，如果所做的事情龉经济周期相反，那么最终的结果可能是努力了，但是收益并不是很大。追求资产端回报的时代结束了，是时候追求负债端回报了。4. 永远输钱的股民按照时间定律，要尽可能地做对事情，只要事情做得对，时间一长，想不进步都不可能。但是做对的事情并不容易，人总是在不断的犯错误。接下来的问题时，犯错误可怕吗？一个错误犯一次并不可怕，可怕的是同一个错误不断重复还不自知，当然比这更可怕的是，明知道什么是错误，明知道什么是对的，但依然要坚持错误。 在股市上，有输有赢是一件很正常的事情，但是有的故名永远只输不硬，这就有大问题了，因为让一直猴子来炒股，它可能输赢各半。有几点需要避免：不要把赌场当作投资的场合。 我们都知道长赌必输这句话，赌场玩的是一个零和游戏，考虑到赌场本身的运行成本，也就是庄稼必须抽取的费用，赌场是一个回报率为负值的地方。只要时间玩的长一些，再多的钱都必然会交给赌场。在股市中因为总有人觉得别人赔钱，自己能够把哪些“菜鸟”的钱挣到手，岂不知，想割“韭菜”的人，总是自己成为“韭菜”。投资和投机是有本质区别的。不要相信自己能够把我住时机。 我们从小被教育要把握时机，但是在股市中的时机难以把握。今天，但凡一个具备充足流动性的时长，资产的价格和它的价值就是一致的，因此不存在别人看不到，你看到的机会。有人看到某只股票下跌了10%，觉的自己能够便宜10%买到同样的东西，殊不知，昨天的这只股票和今天的这只股票不是同一个东西。股价是靠共识维持的，换句话说，当共识不在了，其价值也就不在了。不要相信自己看到了别人看不到的投资机会。今天，很多人投资喜欢买一些几分钱、几角钱一股的股票，因为他们觉得这些股票的价格已经低到无法再低了，只有向上的空间，没有向下的空间。事实上，一角钱一股的股票，未必比100元一股的更便宜。 一家股价不断上涨的企业，说明它的盈利越来越越多，这背后体现的是管理好，市场大，产品优。一家长期股价在一角钱徘徊的企业，其内部一定存在一大堆问题。在世界上任何人、任何组织、包括球队，都没那么重要，放弃他们，世界照样运转，更重要的是，我们可以把资源和专注度放在更有意义的事情上。5. 兴趣&amp;专业爱好最后不能当饭吃，是没有用的，得先养活自己。专业和商业的结合专业、兴趣很深，但不会把它转成赚钱，也活不下去。兴趣和最后的商业模式联合在一起。真正成功的大都是把自己的兴趣做成了事业，最难的是跨过爱好和商业化之间的鸿沟。一个事儿当你做起来毫不费力，但是别人很痛苦的时候，就是你的优势。6. 延展主业不可以放弃，但任何关联的都要延展。不要拒绝在任何一点上做延展，可以不测重于此，但不要拒绝新事物。各行各业只要愿意观察，还是有机会的。渗透率从0到1的时候是挖金子(赚钱),从1到10的过程是卖铲子(卖方法)。女装店：真正的逻辑是社交。日积月累的客群，是一个小社群的场景。如果创业那么商业逻辑必须非常清楚（变现），不是单纯的烧钱，最不确定的变量是“人”，合伙人很关键。创业时尽量选择同阶层的，能抗风险的、潜意识的社会资源更加匹配。新的行业、兴趣加上深度-&gt;专业，再多加一个商业思考，形成闭环。晚安！"
  },

  {
    "url": "/%E6%80%9D%E8%80%83/2024/08/18/%E6%95%B0%E5%AD%A6%E6%80%9D%E7%BB%B4%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%BC%8F.html",
    "title": "日常思考问题的5种数学思维思维模式",
    "content": "日常思考问题的5种数学思维思维模式1. 从不确定性中找到确定性第一种数学思维源于概率论，叫作“从不确定性中找到确定性”。假如一件事情的成功概率是20%，是不是意味着我重复做这件事5次就一定能成功呢?很多人会这样想，但事实并不是这样。如果我们把95%的概率定义为成功，那么，这件20%成功概率的事，你需要重复做14次才能成功。换句话说，你只要把这件20%成功概率的事重复做14次，你就有95%的概率能做成。计算过程如下，对公式头疼的朋友可以直接略过。做1次失败的概率为:1-20%=80%=0.8重复做n次都失败的概率是:80%”=1-95%=5%=0.05(重复做n次至少有1次成功的概率是95%，就相当于重复做 n次、每一次都不成功的概率是5%)  n = log0.08^0.05≈13.42所以，重复做14次，你成功的概率能达到 95%。如果你要达到99%的成功概率，那么你需要重复做21次。虽然这个世界上没有100%的成功概率，但是只要重复做大概率成功的事情，你成功的概率就能够接近100%。这就是从不确定性中找到确定性，这是概率论交给我们最重要的思维2. 用动态的眼光看问题第二种数学思维源于微积分，叫做“用动态的眼光看问题”。宏观上，我们看到的是位移，但是从微观的角度来看，整个过程是从加速度开始的：加速度累积，变成速度；速度累积，变成位移。这就是积分。反过来说，物体之所以会有位移，是因为加速度经过了一段时间的累积。而物体之所以会有速度，是因为加速度经过了一段时间的累积。而物体之所以会有位移，是因为加速度经过一段时间的累积。位移相对于时间的一阶导数是速度，速度相对时间的一阶导数是位移，微观上其实是每一个瞬间速度的累积。而位移的倒数，就是从宏观回到微观，去观察它瞬间的速度。这就是微分。那么微积分对于我们日常生活到底有什么作用呢？理解微积分，你看问题的眼光就会从静态变为动态。加速度累积，变成速度；速度累积，变成位移，其实人也一样。你今天晚上努力学习了，但是一晚上的努力并不会直接变成你的能力。你的努力得积累一段时间，才会变成你的能力。而你有了能力，并不会马上作出成绩。你的能力得积累到一段时间，才会变成你的成绩。而你有了一次成绩，并不会马上得到领导的赏识。你的成绩也得积累一段时间，才会使你得到领导的赏识。从努力到能力、到成绩、到赏识，是有一个过程的，有一个积分的效应。努力的时候，希望瞬间得到大家的认可，但是出了问题后却不去想几个月前的懈怠。这是很多人容易走进的思维误区。从本质上讲，微积分的思维方式就是用动态的眼光看问题。一件事情的结果并不是瞬间产生的，而是长期以来的积累效应造成的。出了问题，不要只看当时那个瞬间，只有从宏观一直追述到微观，才能找到问题的根源。3. 公里体系第三种数学思维源于几何学，叫做公里体系。如果说公里体系是一个大树，那么，公里体系就是大树的树根。在几何学中，一旦制定了不同的公里，就会得到完全不同的知识体系。这就是公里体系的思维。这种思维在我们的生活中非常重要，比如，每家公司都有自己的愿景、使命、价值观，或者说公司基因、文化。因为愿景，使命，价值观不同，公司与公司之间的行为和决策差异就会很大。一家公司的愿景、使命、价值观，就相当于这家公司的公里。公里直接决定了这家公司的各种行为往那个方向发展。所有的规章制度，工作流程，决策行为，都是在愿景，使命，价值观这些公里上“生长”出来的定理，他们构成这家公司的公里体系。而这个体系一定是完全自洽的。不管公司以后如何发展，只要有公里存在，就会演绎一出一套能够解决问题的新法则（定理）。公理没有对错，不需要被证明，公理是一种选择，是一种共识，是一种基准原则。制定不同的公理，就会得到完全不同的公理体系，并因此得到完全不同的结果。4. 数字的方向性第四种数学思维源于代数，叫作“数字的方向性”。数这个东西，除了大小，还有一个非常重要的属性：方向。在数学上，我们把有方向的数字叫作向量。数其实是有方向的，在日常的工作和生活中可以得以体现。在公司做事情，两个人都是很有能力，合作的时候，如果他们的能力都往一个方向使，形成合力，这是最好的结果。但如果他们的能力不往一个方向使，反而相互牵制，那可能还不如把这件事情交给其中一个人来做。5. 全局最优和达成共赢第五种数学思维源于博弈论，叫作“全局最优和达成共赢”。我们每天大大小小的决策，每个决策的背后逻辑就是一场博弈。下围棋就是典型的博弈场景。没走一步棋，我的所得就是你的所失，我的所失就是你的所得。这是博弈论中典型的零和博弈。在零和博弈中，你一定要保持清醒：你要的是全局最优解，而不是局部的最优解。经营公司也一样，不要总是想着每件事情都必须一凡风顺，如果你想得到最好的结果，在一些关键步骤上就要做出妥协。除了零和博弈之外，还有一种是非零和博弈，它讲究共赢，共赢的前提是建立信任，但是建立信任特别不容易。孔子说“三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲不逾矩”。所谓“从心所欲不逾矩”，不是说你要通过约束自己来让自己做的事情不越出边界，而是当你拥有符合规律的思维方式时，你做的事情根本就不会越出边界。"
  },

  {
    "url": "/%E6%80%9D%E8%80%83/2024/08/11/%E5%91%A8%E6%9C%AB%E6%80%9D%E8%80%83%E8%AE%B0%E5%BD%95.html",
    "title": "周末思考记录20240811",
    "content": "周末思考记录202408111. 找到知识的盲点在小时候记得映像比较深刻的就是，就是在课堂上背诵九九乘法表，背不过放学后还不让回家（天快黑了，还是会放的）。包括现在一些简单的乘法算术在计算的时候也会采用乘法表进行，当时以为乘法只有一种计算方式，其实后来才了解到乘法在不同的国家则计算方式不一样，在俄罗斯采用的是“俄罗斯农夫乘法”，在古埃及通过垒石头的方式进行计算，叫做“古埃及乘法”，类似的还有“印度乘法”。同样的还有10进制、12进制、60进制、生肖等，这些是如何进行计数的，到目前知道的是，这些进制就跟人类的双手和脚趾有关，10个手指头，直接计数比较简单这就是10进制，12进制就是把一个人的的单手除大拇指之外的，其它每一根手指分为3节，所以一只手除开大拇指就是12节，类似的还有60进制，无非是用上双手等。其实想想这些定义和发明都是源于事物本身，如果当时学习的时候能知道这些，那么学习的时候是否兴趣会更大一些。2. 把手弄脏的理解回顾过往的工作经历中，在职场中有意或者无意的会去把一件事情整的明明白白、或者是对于业务来说那块是难点就会花时间去啃、在团队中会时不时出现救火场面。其实这些成长也罢、或者让自己的工作经历更加丰富，这无非是通过一种把手弄脏的途径（路径），到逼自己成长的一种方式。记得一次我回老家，去一家在县城从上学期间就在吃的蒸面店，据说蒸面老板在当地相当有钱（相对），那次去吃的时候，在蒸面端上桌子的时候，应该是鞋子比较滑的原因，有一半蒸面直接倒在的地上，老板下意识的去拿扫帚和纸巾把地上收拾干净，其实当时我看了店里还有其他服务员（当时并没有在做事情）。其实老板的行为是自主意识的，地上脏了就回去擦。现在想想，我们身处现实生活中，那个人的手是干净的呢？与其说把手弄脏，反倒是可以说何必在意是否会把手弄脏，在这个过程中重要的是如何面对或这面对这件事情的反应。3. 听到的不一定可靠这个事情也许在现实生活中，太司空见惯了。这里说一个不争的事实，尤其在近1-2年，大家都在讨论经济不好，大环境不好之类的话，或者是针对这些还做了一些讨论。有意思的是我看了一个数据（真正的大众群体：月薪3000~5000，分布在三四线城市，平均受教育年限10.9年左右（即中专到大专水平）。中国有护照的人不到1亿、没做过飞机的大概10亿、缴纳个人所得税大概几千万。1970年~1985年出生的人占总人口23%左右，占总消费量58%。90后、00后占比不足10%。）。不难看出，目前的这些声音很多是通过媒体平台或者是能在网上留下足迹之后被人看到进行传播的，那么还有很多人从不接触互联网，或者是在网络上的足迹相对比较少，那么这部分的声音是无法被外界知道的，。在当前的经济环境下，养老、医疗等服务性行业任然是很具前景的，大环境不好是事实，但是并不是所有的行业，只是我们常常只关注我们看到的罢了。4. 日常反思无论在生活上和工作上，都需要对自己当下的状态进行一些反思、总结。在工作中我会专门花时间回顾一周或一个月的工作，其实工作的过程和日常处理的事情并没有那么高大上，但是如果这些反思通过笔记记录下来，会很有意思，工作中的周报这些我同样会花时间思考记录，可能有人会问这有啥用？其实你想想，整个过程不就是一个成长的过程吗，这些记录下的思考和总结是不同阶段对新事物的反馈，或者是旧事物的思考，这也代表了当下最真实的自己，如果回过头再看这些，这就是一部成长记录，也许在未来的某个时间可以发挥巨大作用。也就像此时此刻，我在记录一些东西，记录一些的思考见闻。这些记录当然可以选择一个不易丢失的设备进行存储，这也是一路走过来我发现现在互联网上搜索到的东西没有以前多的原因。5. 家人陪伴在职业生涯中，家庭给予我的帮助挺大的，一些重大选择都选择基于支持，我非常欣慰能有这样的家庭。即使目前即使在工作中会疲惫不堪，但是回到家中看到家人和小孩之后，这些都消失了，感觉自己立刻切换了场景，这也许就是被治愈的一种方式。当我们放下键盘，关掉电源的这一刻，我们的生活才刚刚开始，抽出时间尽量陪伴家人，做一些高价值的陪伴。PS：最近身边的一些伙伴感冒发烧，咳嗽不断，去检测是新冠病毒，方便化大家备一些常用的药（对乙酰氨基酚片，可以备一点）"
  },

  {
    "url": "/%E6%88%90%E9%95%BF/2024/05/19/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E7%9A%84%E7%90%86%E8%A7%A3.html",
    "title": "最佳实践的理解",
    "content": "最佳实践的理解最近因为家里的事情，有一段时间没有更新了。刚在整理近期的工作和生活中的事情，想到一个词是“最佳实践“这个词。这个词也不陌生，经常在软件研发领域会说这个方案是最佳实践或者不是、在其他行业有时后会说应该这么做才是最好的、在生活中回顾做的一些决策和操作之后，在现在看来可能部分决策不是最佳实践。1. 概率在生活和工作中处处面临选择，每种选择其实可能都会伴随着不同的结果，其实这就产生了概率问题。只是现实社会中往往大家可能会总结经验，让好的结果尽可能发生，那么从概率的角度讲就是正向概率增大，那么这就是最佳实践的叠加效应。回想最早的机器学习(监督和无监督)、当前生成式AI(GAI)、金融行业的量化交易等，这些其实最终追求的就是概率问题，在量化交易行业中这个就是胜率问题。那么最佳实践本质上来说就是做选择，既然做选择就会存在概率问题，在实际生活中会发现最佳实践多了，那么就会形成叠加效应，胜率会增大，就会直接或间接带来一定的收益。2. 学习既然面临选择，那么当时不是盲目选择，这里也需要基于一定的事实客观规律，那就是学习。选择要建立在一定的理论基础和方法论，这里有很多关于这方面的文章。我想说的就是费曼的学习法，知识的积累是需要通过学习的方式。其实费曼的学习法是后人通过费曼的诸多文献总结出来的，学习法的精髓有2点：1. 把学到的知识内容用自己的理解进行输出、记录笔记，输出形式没有限制，重要的就是需要用自己理解的方式，这很重要2. 把通过获取知识理解后的内容作为输入给到自己，倒逼自己输出，其实这个环节就是说的实践把上述方法应用到实际的场景中，至少在做选择时会多一个参考，一定不要盲目选择，通过知识的积累，让自己有做更多选择的可能性，从而增加最佳实践的概率。3. 因小失大，得不偿失在重要的事情上多花心思，不是重要的事情上选择果断。可能很多人说什么事情时重要的事情？就是一件事情这么做都无畏那么就可以视为不重要，但凡还要经过大脑思考几回那说明存在一定的重要性。回想自己生活中就做过比较草率的决定，当时买房子的时候，没有话很多心思、没有参考过一些数据、甚至房子都没仔细看过就决定把房子买了，在当时想着自己能挣到钱无所谓。但是随着房价的下行，发现房子跌了不少，其实这个直接带来的就是经济上的损失，由于当初自己的没有经过认真思考导致的。反而有时间在tb和jd上买东西会纠结这个平台比那个平台便宜，因为这个会在上面停留过多的时间，这个就是不值当的。相比事情来说这就是典型的时捡了芝麻丢了西瓜，这就不是最佳实践。在工作中同样存在类似的问题，在做重大的技术方案时，虽然不要求面面具到，但是一定要抓住关键核心、识别出方案中的盲点、救命稻草、基础框架逻辑稳定自洽。这个就可以算在当时那一刻的最佳实践，最担心的就是考虑较少，一顿操作猛如虎，回头一地鸡毛。 在核心业务、核心领域上要多花心思，反倒是一些相对不是那么重要的业务功能迭代上方案上考虑够用就好，不要锦上添花。4. 主动与被动生活和工作中我们需要主动去面对和take一些事情。很多人认为这是心态问题，其实这是能力问题。主动与不主动，生命资源相差30倍。在工作中，主动思考和行动的能力尤其重要，主动承担能力和责任之外的事情，本身就是一个非常好的锻炼和成长机会，不要总担心自己的能力不够，害怕没把事情做好，其实不管你最终有没有把这件事情做成，但在做的过程中就是一次非常好的锻炼机会，用了公司的资源，成长了自己的能力，这是一个很划算的事情。 主动者每天都在日拱一卒，被动者每天都在左右徘徊。这个象限在现实情况下普遍存在，主动一些会让一些不可能成为可能，经历过这样几次之后，你可能在能力上会有很大的提升，在后面做决策和选择时，胜率就会加大，这也是最佳实践。5. 把手弄脏在目前阶段获取资讯或者知识的方式很多，知识在传递的过程中也会发生一些变化(理解偏差)，加上知识的输出者也不不可能把所有细节和方法论都讲出来，这也不太现实。我们在理解这些知识后切记隔岸观火，把这些知识和输出直接用在实际的场景中。我们一定要结合实际情况，深入理解事情的逻辑和本质，适当的结合和改造、优化，切记空有一套方法论。在软件研发领域，可能你已经是研发小组长、研发Leader，但是对于一线的一些问题必须去了解，知根知底。一定要 do something ，而不是 own stomething。"
  },

  {
    "url": "/web3/2024/04/16/Web3-%E6%B8%B8%E6%88%8F-%E9%93%BE%E4%B8%8A%E8%B5%84%E4%BA%A7%E4%B8%8E%E7%BB%8F%E6%B5%8E%E5%B9%B3%E8%A1%A1.html",
    "title": "Web3 游戏：链上资产、可组合性与经济平衡",
    "content": "Web3 游戏并非“把游戏搬上链”，而是利用“链上可验证资产 + 可组合协议 + 开放市场”构建新型经济系统：资产可流通、玩法可叠加、内容可共建。工程落地的关键是资产与经济的严谨设计、反作弊与反女巫、链上/链下分工与可观测体系。本文给出一套可直接实操的参考方案。1. 资产设计：ERC-721/1155 与可组合  角色/装备：稀有度、属性、成长路径；  可组合：装备作为组件装配到角色（EIP-998/可组合规范），或在外部合约读取“装备映射”；  动态属性：升级/附魔/修复，链上存储核心属性，链下计算细节；  元数据：图素与动画通过 IPFS/Arweave 存储，链上记录 CID。2. 经济平衡（产出/消耗闭环）  产出：打怪/任务/挖矿 掉落；  消耗：修理/强化/合成/门票；  通胀控制：掉率衰减、合成概率、消耗品设计；  市场：玩家间自由交易（AMM/订单簿），平台抽取少量手续费回流金库；  预言机：如涉及法币锚定，采用时间加权价格，规避闪崩影响。3. 反脚本与反女巫  行为指纹：节奏/移动/时序统计识别自动化；  风控阈值：异常收益、频繁交易、深夜高频；  DID/VC：绑定可验证凭证降低批量女巫；  处罚与申诉：温和限流、冻结审核、黑白名单。4. 链上/链下分层  链下高频：战斗匹配、物理/数值计算；  链上结算：资产增减、关键事件（铸造/销毁/合成）；  事件设计：每个关键变化 emit 事件以供索引器重放；  可验证随机数：Chainlink VRF 或 commit-reveal。5. 市场与交易  订单：固定价/拍卖/荷兰拍；  税费：平台费、创作者分成、回购与销毁；  防洗钱与反作弊：同地址/相关地址频繁交易告警；  订单撮合：链上撮合（昂贵）或链下签名订单 + 链上结算（高效）。6. 跨链与 L2  L2 部署：降低 Gas，提升交互体验；  跨链：资产映射/桥接，小游戏分链分服；  同步：统一身份（DID）与跨链资产视图（索引层聚合）。7. 反作弊与可观测  监控：日活/留存、经济指标（通胀率/回收率/交易额）、机器人占比；  日志：关键交互埋点与链上事件对账；  告警：异常产出/价格操纵/批量转移；  A/B：经济参数灰度试验，避免一次性调整导致崩盘。8. 上线与运营 SOP  技术：Testnet 压测 → L2 主网灰度；  市场：创作者合作、空投/白名单；  安全：审计/赏金计划、Key 管理、多签金库；  版本：前端 CDN 可回滚、合约保留暂停开关；  演练：回滚/风控封禁/桥接中断的应急预案。9. 示例：装备合成合约（简）function combine(uint256 a, uint256 b) external payable {  // 检查持有、扣除消耗、概率判定、生成新装备token  emit Combined(msg.sender, a, b, newId, success);}10. 小结Web3 游戏成功的关键不在“链”。它需要与玩法、经济、反作弊、内容生态共同作用。以“链上凭证 + 可组合资产 + 开放市场”打造可持续的经济系统，再用工程化手段（索引、风控、看板、演练）保证长期稳定，才是可走通的路线。"
  },

  {
    "url": "/%E6%80%9D%E8%80%83/2024/03/25/%E4%BA%8C%E5%85%AB%E6%B3%95%E5%88%99%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83.html",
    "title": "二八法则的一些思考",
    "content": "关于二八法则的另外一种叫法是80/20法则，或者叫关键少数法则。在生活工作方各方面都有体现：在经济学领域，全球最富有的20%的人口，控制着世界收入的82.7%。在软件领域，可以应用于优化软件工作，通过修复报告最多的错误的前20%，给定系统中80%的相关错误将被消除。在运动锻炼上，20%的练习和习惯影响着80%的结果，受训者不应该专注于多种训练。将二八法则落实到行动上，简单整理了如下方法做有复利积累的事情复利特别在经济学领域比较常用，例如做量化一般也会评估复利的长期收益(常说的利滚利)。最常见的复利即资产，即可以自行为持有人带来收益的东西，资产本身是固化的劳动，而靠其赚到的钱又可以固化为资产，从而以指数增长的方式增殖。当然，任何可以积累的东西都是具有复利效应：知识是可以积累下来的，积累的知识帮助做出更高概率正确的决策，带来更大的视野，从而有需求及动力学习更多知识；个人IP影响力是可以积累的，更高的影响力带来更大的曝光，接触更多优秀的人，有更多合作机会，反过来又增强个人的影响力。极致聚焦，做减法现实中每个人的精力有限，不太可能可以做所有的事情，要通过分析和评估来确定哪些是产生最大价值的关键因素。旦识别出关键因素，就需要对它们进行优先排序。这意味着要将资源和精力集中在那些最能产生效益的领域。识别并剔除那些消耗时间、金钱和资源但收益甚微的活动。在决策过程中，尽量减少不必要的选项和复杂性。通过简化流程，可以提高效率并减少错误。有效地利用资源，提高效率和产出。战略优于战术程序员应该都有感受，写代码最重要的是前面的思考的环节，写只占据很少时间，若思考不清晰，后续会有无尽的debug负担；做产品也一样，我个人看来，商业模式&gt;流量策略&gt;具体开发，商业模式定义了是否解决的是痛点问题，该问题是否给用户带来价值从而用户有付费意愿，该问题定义清楚后，流量策略和具体开发则是水到渠成的事情，而渠道的重要性往往要高于具体开发。发挥自己的比较优势社会分工之所以存在，是因为每个人有其比较优势，各自做擅长的事情并合作，会提升整体效率。对个人来说，发挥自己的比较优势，只做那 20% 自己擅长的或有热情的事情（热情本身也会变为擅长），其他事情则是最大程度自动化或者外包出去。当前AI能力如此强大，各细分领域服务极度充沛，特定问题付费解决可节省大量人力，成本远低于自己浪费时间。"
  },

  {
    "url": "/%E5%B7%A5%E5%85%B7/2023/12/19/%E5%AE%9E%E7%94%A8Mac%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90%E5%88%97%E8%A1%A8.html",
    "title": "实用Mac软件推荐列表",
    "content": "Apps日常使用ClashX Pro：科学上网只有先科学上网，才能装后面的Notion：笔记输入 + 博客输出的工具Chrome：浏览器Xnip：截图工具1password 7：密码管理工具其它的也用过，还是这个原生 App 比较流畅CleanMyMac X：Mac优化清理工具Warp WindTerm iTerm2：终端Alfred：本地搜索、应用启动、剪贴板 📋MarkEdit: Mac上开源markdown编辑器效率神器Karabiner-Elements：键盘键位修改神器一些配置 karabiner.json ，主要是改 HHKB 和 Apple Keyboard滴答清单 ：任务和规划时间（GTD）的应用flomo ：快速记录一些想法Bob 社区版 ：划词翻译和截图翻译工具支持多个翻译聚合还挺方便的Input Source Pro ：不同应用、不同网站自动切换输入法QQ Music ：网络音乐服务产品百度五笔输入法试过 Mac 上各类的五笔输入，还是这个好用NetNewsWire ：开源、免费、全平台的 RSS 订阅、阅读订阅 index.opmlBartender 4 ：菜单栏应用图标管理工具管理挺方便，就是 Mac 屏中间刘海那块没适配好OpenInTerminal：从 Finder 一键打开 Terminal之前的 Go2Shell 似乎不维护了，就用了这个IINA ：媒体播放器Kap ：开源录屏工具可转成 gif、mp4，支持插件新 Mac 生成 gif 基本是秒级导出TaskPaper ：文本编辑器模式的任务管理工具（GTD）经常用来管理工作上需要长期跟进的事，和滴答清单结合使用MindnodeTelegram ：相对匿名安全的聊天软件Cubox ：一站式信息收集、阅读、管理和回顾碎片化阅读时代的文章、视频收集器RunCat ：在任务栏奔跑的猫猫奔跑的速度会随着CPU使用率提升而越来越快（新 Mac 怎么开发都没看猫奔跑过）Magnet ：窗口管理MonitorControl ：显示器亮度调节StandUp ：提醒站立WiFriedX ：关闭 AWDL/AirDrop，优化 M1 系列 Mac 的 Wifi 连接 开发使用VSCode ：代码编辑器通过自带的 Settings Sync 功能一键同步GitUp ：Git GUI 软件比 SourceTree 等软件要简洁，日常开发中基本没有做不了 GUI 操作Sublime Text ：文本编辑器准确来讲，经常用这个编辑器快速做一些纪要DataGrip：数据库开发工具Goland：Gopher 开发工具Dash：API 文档和代码片段管理一直在用，找 API 文档和用法太方便了Postman ：API 调试神器SwitchHosts ：管理、切换多个hosts 方案的工具QuickLook 预览插件quicklook-jsonqlmarkdownQLVideo System Configuration触摸板三指拖拽系统设置 → 辅助功能 → 指针控制 → 触控板选项 → 启用拖移（三指拖移）退格键响应速度系统设置 → 键盘，按键重复 调到最快、重复前延迟调最短Github clone 加速屏保 Aerial Devbrewon-my-zshfzfautojumplazygit ：命令行版 Git GUIripgrep ：快速搜索文件/目录中包含的字符串batghglabgit-switchergraphvizNode.js 相关fnmnode 16 似乎用不了 node-gyp-buildPython 相关pyenvJava 相关jenvGomoddtree字体安装brew install –cask font-fira-code font-jetbrains-mono PluginsAlfred workflowsalfred-chromium-workflow ：浏览器历史记录搜索找一些页面很方便YoudaoTranslator ：有道搜索平时直接 yd 中英文单词/句子 很方便NpmSearch ：npm 包搜索npm 包名 搜索一些包版本，同时支持任意 registry 源"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/nginx/2023/12/05/Nginx-Ingress-%E5%9C%A8Kubernetes%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE.html",
    "title": "Nginx Ingress 在 Kubernetes 的高可用配置",
    "content": "在 K8s 中落地 Ingress-Nginx 时，如何配置高可用、弹性与灰度？本文给出实操 YAML、金丝雀流量与压测/演练手册。1. 基础部署（示例）apiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: web  annotations:    kubernetes.io/ingress.class: nginxspec:  rules:  - host: demo.example.com    http:      paths:      - path: /        pathType: Prefix        backend:          service:            name: web-svc            port:              number: 802. 金丝雀灰度metadata:  annotations:    nginx.ingress.kubernetes.io/canary: \"true\"    nginx.ingress.kubernetes.io/canary-weight: \"20\" # 20%3. HA 形态  DaemonSet + hostNetwork + externalTrafficPolicy=Local，保持源地址；  或 Service L4 LB + 多副本 Ingress Controller。4. 压测与演练  fortio/vegeta 压测 10-30 分钟，观察 2xx/4xx/5xx 与 P95；  演练：杀死节点/Pod、模拟 LB 抖动，验证会话粘性与重试策略。5. 拓扑与调度（反亲和/跨区扩散/PDB/容忍）controller:  replicaCount: 3  affinity:    podAntiAffinity:      requiredDuringSchedulingIgnoredDuringExecution:        - labelSelector:            matchLabels:              app.kubernetes.io/name: ingress-nginx              app.kubernetes.io/component: controller          topologyKey: kubernetes.io/hostname  topologySpreadConstraints:    - maxSkew: 1      topologyKey: topology.kubernetes.io/zone      whenUnsatisfiable: ScheduleAnyway      labelSelector:        matchLabels:          app.kubernetes.io/name: ingress-nginx          app.kubernetes.io/component: controller  tolerations:    - key: \"node-role.kubernetes.io/ingress\"      operator: \"Exists\"      effect: \"NoSchedule\"PodDisruptionBudget（避免滚动/维护时一次性驱逐）：apiVersion: policy/v1kind: PodDisruptionBudgetmetadata: { name: ingress-nginx-pdb, namespace: ingress-nginx }spec:  minAvailable: 1  selector:    matchLabels:      app.kubernetes.io/name: ingress-nginx      app.kubernetes.io/component: controller6. 升级与优雅收敛controller:  updateStrategy: { type: RollingUpdate }  minReadySeconds: 10  terminationGracePeriodSeconds: 60  config:    worker-shutdown-timeout: \"30s\"    proxy-next-upstream: \"error timeout http_502 http_503 http_504\"    proxy-next-upstream-tries: \"2\"    proxy-read-timeout: \"30s\"    proxy-send-timeout: \"30s\"要点：  minReadySeconds 确保就绪后才接流量；worker-shutdown-timeout 提供连接迁移时间。  与上游的重试与超时上限要保守，防止风暴。7. 容量与弹性（HPA）controller:  metrics:    enabled: true    serviceMonitor:      enabled: true  autoscaling:    enabled: true    minReplicas: 3    maxReplicas: 20    targetCPUUtilizationPercentage: 60    targetMemoryUtilizationPercentage: 70建议：基于 CPU/内存或自定义 QPS/连接数指标（需自定义 Metrics Adapter）弹性扩缩容。8. 上游容错与连接复用controller:  config:    keep-alive-requests: \"1000\"                # client &lt;-&gt; ingress 长连接复用上限    upstream-keepalive-connections: \"512\"      # ingress &lt;-&gt; upstream 空闲长连接上限    max-worker-connections: \"65536\"    retries: \"1\"    retry-non-idempotent: \"false\"注意：若上游有会话亲和（如登录态），需与 session-cookie/一致性哈希配合，避免跨请求状态混淆。9. 可观测与演练清单（扩展）  指标：活动连接、$upstream_response_time 分位数、5xx 率、队列与 fd 用量。  日志：统一 JSON 格式，保留版本/路由/上游信息，便于问题回溯。  演练：          杀 Pod/节点；      人为提升上游错误，验证 proxy-next-upstream；      LB 抖动/跨区故障；      扩缩容/滚动升级下的会话粘性与连接复用表现。      "
  },

  {
    "url": "/web3/2023/08/09/Web3-%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%8E%E9%92%B1%E5%8C%85%E6%B3%A8%E5%85%A5%E6%A0%87%E5%87%86.html",
    "title": "Web3 浏览器与钱包注入：EIP-1193/6963 与隐私实践",
    "content": "Web3 浏览器的要义是“让网页安全地调用用户的加密身份与链上资源”。核心落在 Provider 标准（EIP-1193）、多钱包发现（EIP-6963）与网络切换（EIP-3085/3326），同时还要面对隐私合规、反钓鱼、兼容性与多链适配等现实问题。本文从标准到工程实践，系统讲解如何构建“安全、可靠、好用”的 Web3 浏览器/前端。1. EIP 标准速查  EIP-1193：Provider 请求/事件接口；  EIP-6963：多钱包发现与选择；  EIP-3085：向钱包添加链配置；  EIP-3326：请求钱包切换链；  EIP-155（签名交易链ID）、EIP-712（结构化签名）。常用调用：await provider.request({ method: 'eth_requestAccounts' })await provider.request({ method: 'wallet_addEthereumChain', params: [{ chainId:'0x1', rpcUrls:['...'], chainName:'Ethereum', nativeCurrency:{name:'ETH',symbol:'ETH',decimals:18} }] })await provider.request({ method: 'wallet_switchEthereumChain', params: [{ chainId:'0x1' }] })2. 多钱包与注入（EIP-6963）  发现：页面监听 eip6963:announceProvider 事件，聚合候选；  选择：弹出钱包列表，用户选择后注入该 Provider；  兼容：Fallback 到 window.ethereum。document.addEventListener('eip6963:announceProvider', (event) =&gt; {  const detail = event.detail; // { info, provider }  wallets.push(detail)})3. 权限与安全  权限最小化：仅在需要时请求账户与签名；  白名单域名与签名域隔离（SIWE domain binding）；  反钓鱼：明确签名提示含意，拦截 setApprovalForAll 弹窗的风险提示；  Sandboxing：对第三方脚本注入做 CSP 限制；  兼容 DNT/隐私：不上传可识别信息，客户端缓存敏感数据。4. 签名与交易  登录：SIWE（EIP-4361）签名会话；  交易：预估 Gas，失败提示与替代交易；  批量与 AA：账户抽象（EIP-4337），用 UserOp 合并多个动作；  非 EVM：签名格式差异（Solana/Polkadot），抽象 Provider 层。5. 多链与兼容性矩阵  EVM 兼容链：主网/L2（Arbitrum/Optimism/zkSync/Linea/Base/…）；  非 EVM：通过特定 SDK/适配器；  检查清单：链ID、单位、RPC 限流、交易池差异、确认规则；  错误处理：网络切换失败/链不支持 → 降级只读。6. 调试与监控  调试：启用 eth_call 与 debug_traceTransaction（权限谨慎）；  监控：钱包连接率、签名拒绝率、交易失败率、平均确认时间、非预期链切换次数；  前端埋点：区分 Provider 版本、钱包类型（扩展/移动/内嵌）。7. 用户体验优化  首屏无需连接钱包（只读模式），用户操作再请求授权；  断线重连与会话恢复（SIWE + 短期 token）；  错误文案本地化与“下一步指引”；  一键复制错误详情到工单；  预加载常用合约 ABI 与代币列表；  慢链/高拥塞时的友好提示与替代方案（切 L2）。8. 反钓鱼与合规  域名与合约白名单：显示“已验证合约/域名”；  显示授权范围：spender/tokenId/amount；  风险评分：黑名单/社交举报/交易图谱；  法务：隐私政策、KYC/AML 适配（若涉及法币出入金）。9. 示例：最小可用多钱包接入import { createConfig, http, createStorage } from 'wagmi'import { injected, walletConnect, coinbaseWallet } from 'wagmi/connectors'export const config = createConfig({  chains: [mainnet, arbitrum, optimism],  transports: {    [mainnet.id]: http('https://...'),    [arbitrum.id]: http('https://...')  },  connectors: [injected(), walletConnect({ projectId:'...' }), coinbaseWallet({ appName: 'app' })],  storage: createStorage({ storage: window.localStorage })})10. 小结一个好的 Web3 浏览器前端，既要“懂标准”也要“懂用户与风控”。以 EIP-1193/6963 为锚点构建 Provider 层，围绕权限/隐私/多链/监控/反钓鱼持续打磨，才能在复杂生态中提供长期可靠的体验。"
  },

  {
    "url": "/web3/2023/03/22/Web3-DAO-%E6%B2%BB%E7%90%86%E4%B8%8E%E5%8D%8F%E5%90%8C%E5%AE%9E%E8%B7%B5.html",
    "title": "DAO：治理、金库与协同实践",
    "content": "DAO（Decentralized Autonomous Organization）强调“公开规则 + 透明资产 + 社区协作”。要把 DAO 从“概念”落地为可持续运作的“组织”，需要同时构建规则（合约/章程）、流程（提案/投票/执行）、工具（多签/投票/论坛/工单）与度量（金库/参与度/交付）。本文从治理模型到金库运营、从合约到日常协同，给出可直接落地的实践手册与脚本示例。1. 治理模型概览  Token-based：一币一票，参与门槛低但易受“鲸鱼”影响；  Delegated（委托制）：将投票权委托给代表，兼顾广泛参与与专业决策；  二次方投票（Quadratic）：缓解大户垄断影响，但需反女巫措施；  基于声誉/贡献积分：非金融化权重，强调长期贡献；  混合模型：不同领域/金额使用不同门槛与投票机制（如技术提案 vs. 市场预算）。2. 提案生命周期（从草案到执行）1) 草案（RFC）：论坛/Discord 讨论，明确动机、方案、预算、风险；2) 影子投票/温度测试（Snapshot 温度计）：收集倾向；3) 正式提案（SIP/DAOIP 等）：链上/链下同步发布；4) 投票：Snapshot（off-chain）或 Governor（on-chain）；5) 执行：多签 Safe 模块/Timelock 合约触发链上动作；6) 复盘：记录影响、里程碑达成情况、后续跟踪 KPI。2.1 模板（提案正文）  摘要：一句话说明；  动机与目标：解决什么问题；  方案与里程碑：阶段、交付物、完成标准；  预算：金额、释放节奏、验收条件；  风险与替代方案：关键假设与兜底；  法务与合规：需要注意的限制；  执行方式：多签/合约接口/可验证凭证；  监控指标：成功/失败的量化定义。3. 投票与执行：Snapshot + Safe  Snapshot（off-chain）：使用签名（EIP-712）完成不可抵赖投票，低成本；  Safe 多签（Gnosis）：金库与执行器，支持模块化扩展；  自动执行：Snapshot 的 SafeSnap 模块可将投票结果自动化为多签交易批次；  门槛设置：法定人数（quorum）、通过阈值、投票时长；  防作弊：反女巫、投票权截快照、委托机制。配置片段（Snapshot space）：{  \"name\": \"Example DAO\",  \"strategies\": [{\"name\":\"erc20-balance-of\",\"params\":{\"address\":\"0xToken\",\"symbol\":\"TKN\",\"decimals\":18}}],  \"quorum\": 0.1, \"voteDuration\": 5}4. 链上治理：OpenZeppelin Governor/Timelock  Governor Bravo / OZ Governor：支持法定人数、投票/延时/执行窗口；  Timelock：为关键变更设置最短延时（如 24~72 小时），保证公众可审阅；  模块化：可组合多策略读权重（ERC20、NFT、声誉积分）。部署要点（Foundry 伪代码）：Governor g = new Governor(\"DAO\", token, quorum, votingDelay, votingPeriod);Timelock t = new Timelock(minDelay, proposers, executors);g.setTimelock(address(t));5. 金库与预算管理  收入：协议费/捐赠/资助；  支出：运营/研发/社区激励/生态合作；  预算流程：提案 → 执行里程碑释放 → 结项复盘；  资产配置：稳定币 vs 原生代币，风险敞口与对冲；  支付工具：多签批量支付、流式支付（Sablier/Stream），可回收未完成预算。多签批量交易（Safe API/脚本）：// 组装批量转账与合约调用，提交到 Safe 服务，收集签名后上链执行6. 角色、工组与激励  角色：理事会（多签签署人）、运营（主持流程）、审计（风险/合规）、贡献者；  工组（Working Group）：按照领域划分（协议、市场、内容、数据）；  激励：按里程碑支付 + 绩效加权；  声誉系统：非金融化的贡献度积分，与资金激励分离；  透明度：公开任务看板/排期/预算消耗。7. 法务与风险  法人格：基金会/非营利组织/公司壳；  合规：税务、KYC/AML、地区限制；  知识产权：内容与品牌使用授权；  保险/代偿：关键风险（跨链桥、金库）购买保险或建立风险准备金；  紧急权限：仅限暂停关键合约/支出，必须有时效与审计日志。8. 运营度量与工具栈  指标：提案数、参与率、委托覆盖率、预算执行率、交付完成率；  金库仪表：资产构成、资金流出入、 runway；  安全告警：异常转账、权限变更、合约事件；  工具：          协同：Discourse/Notion/GitHub Projects/Discord；      治理：Snapshot、Tally、Boardroom、Charmverse；      金库：Safe、Llama、Sablier；      数据：Dune、Flipside、自建 ETL。      9. 应急与回滚演练  触发条件：关键 KPI 恶化（参与率骤降/预算滥用/安全事件）；  行动：临时冻结非关键支出 → 召开紧急会议 → 提案通过后执行回滚或更换模块；  演练：季度进行“带压回滚/金库紧急冻结/密钥更换”演练；  日志：所有应急动作记录在案（链上事件 + 协作平台日志）。10. 案例（示意）  目标：为协议升级与市场推广申请 50 万 USDC；  流程：1) RFC 收集需求与 KPI；2) Snapshot 温度计投票，&gt;60% 支持进入正式投票；3) 正式投票通过 → Safe 批量交易分期付款；4) 里程碑验收：GitHub Release / 合约已上线 / 监控指标达到阈值；5) 复盘发布与预算结项，未用资金退回金库。11. 小结DAO 的难点不是“投票按钮”，而在于“透明、可持续的组织工程”：规则清晰、角色分明、流程可审计、资金可追踪、风险可控。以 Snapshot + Safe + Governor 为核心治理栈，配合度量与演练，DAO 才能在开放环境中长期稳定运转。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/mysql/2023/02/27/MySQL-%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96-%E4%BB%8E-explain-%E5%88%B0%E7%81%AB%E7%84%B0%E5%9B%BE.html",
    "title": "MySQL-慢查询优化-从-explain-到火焰图",
    "content": "在大多数互联网业务中，性能问题往往集中在查询侧（读多写少、读写比常见为 10:1），而慢查询占据了主要矛盾的“C 位”。要系统性地把慢查询优化好，必须同时理解数据库的底层原理（磁盘 IO、B+ 树、优化器）、索引设计的工程原则、可落地的重写与调参手法，以及边界条件——哪些场景即便你用尽 SQL 和索引也很难救。本文在高技术细节的基础上，结合一线经验进行结构化扩展与工程化整理，以期给出一份可直接借鉴的优化指南。一、底层原理速览：为什么索引有效、为什么会慢  磁盘 vs 内存的数量级鸿沟          随机磁盘 IO 的代价远高于内存访问。一次随机 IO 需要经历寻道、旋转延迟、传输时间，数量级毫秒；CPU 指令数量级纳秒。我们优化的核心目标，是让“每次查询落盘的随机 IO”尽量变少甚至可控。        InnoDB 与 B+ 树          InnoDB 二级索引和聚簇索引（主键索引）均是 B+ 树。B+ 树扇出高、树高低（常见 2～4 层），单次定位数据通常 2～3 次 IO 即可。二级索引叶子节点只存被索引列和主键值，真实行数据在聚簇索引上，因此“二级索引命中但需要回表”会产生额外 IO。        页与顺序读取          InnoDB 页默认 16KB，局部性/预读使得顺序 IO 的吞吐远优于大量随机 IO。覆盖索引、索引下推、减少回表，本质都是在“让更多命中停留在更少的页里”。      这组常识决定了：合理的索引与查询改写，能把“全表扫描 + 大量随机 IO”变成“极小范围树检索 + 少量随机/顺序 IO”。二、方法论：从观测、定位到验证  观测          开启并分析慢查询日志（slow_query_log、long_query_time、log_queries_not_using_indexes）      使用 pt-query-digest 聚合热点 SQL；借助 performance_schema/sys schema 获取 Wait、IO、Lock 等维度        定位          EXPLAIN 与 EXPLAIN ANALYZE（8.0.18+）评估真实执行路径与耗时分布      关注 type、key、rows、filtered、Extra（Using index、Using where、Using temporary、Using filesort、Using index condition）        验证          基线采样（QPS、P95/P99 延迟、Rows examined/Rows sent、临时表与回表次数）      审慎灰度：MySQL 8.0 可用 Invisible Index 验证索引有效性；在线 DDL 降低变更风险        回归          用真实业务参数覆盖极端分支；关注“看似更快但在特定参数下灾难性退化”的情况（本文后面会给典型案例）      三、索引优化的核心原则（工程可落地）  核心一：围绕“查询模式”而不是“字段”建索引          只为 WHERE、JOIN、ORDER BY、GROUP BY 等过滤/排序参与列建立索引      高基数（高选择性）列优先（如 user_id &gt; status）；极低选择性列（如性别）单独加索引意义不大        核心二：联合索引的列序必须与谓词和排序兼容          “等值列在前，范围列靠后”，让尽量多的谓词参与到索引扫描而非回表过滤      同时需要权衡“列选择性”和“使用频率”，一般建议：等值频繁且选择性高的列靠前；用于排序/分组的列一并纳入并统一升降序      兼顾 ORDER BY/ GROUP BY 的“索引有序性”，避免 Using filesort/Using temporary        核心三：覆盖索引优先          SELECT 的列尽量被索引覆盖，Extra 出现 Using index 表示“无需回表”。这对热点 TopN 查询、Feed/列表页尤其致命有效        核心四：让条件可 SARGable（可由索引评估）          避免对列做函数或表达式：如 UPPER(col) = ‘X’、DATE(create_time) = ‘2025-08-01’      解决手法：函数生成列 + 函数索引（MySQL 8.0 支持 Functional Index）；或用范围改写（create_time &gt;= ‘2025-08-01’ AND create_time &lt; ‘2025-08-02’）        核心五：LIKE 前缀命中与全文检索          LIKE ‘abc%’ 可用 btree 前缀走索引；LIKE ‘%abc%’ 需全文索引（FULLTEXT/倒排/NGRAM）或改造数据结构（反向存储 + 前缀匹配 + 函数索引）        核心六：ORDER BY/分页优化          避免“大偏移”分页（LIMIT 100000, 20）；推荐“基于游标”的 Seek 方法（WHERE (k, id) &gt; (?, ?) LIMIT N）      如必须排序分页，尽量使用能满足排序的联合索引（与 WHERE 子句兼容）        核心七：主键与二级索引协同          InnoDB 主键即数据物理顺序。主键应短、递增（雪花 ID/自增/UUIDv7），避免随机 UUIDv4 导致频繁页分裂      二级索引叶子存主键，回表代价与主键长度、行大小、局部性直接相关        核心八：统计信息与优化器          定期 ANALYZE TABLE，开启持久统计（innodb_stats_persistent）；必要时使用直方图（MySQL 8.0 histogram）提升基数估计      在小概率误判时使用优化器 Hint（STRAIGHT_JOIN、USE INDEX、INDEX_MERGE、BKA/BKA ON/OFF 等）        核心九：分区不是索引的替代          分区降低“被扫描的数据量”，但分区内仍需索引；分区键必须参与查询谓词才能有效裁剪分区        核心十：变更安全          使用 Invisible Index 验证效果；在线 DDL 降低锁表风险；灰度发布与回滚预案必备        四、实际慢查询案例与可落地重写            案例 1：多条件计数 + 时间范围业务 SQL（简化自业界常见模式）：SELECT COUNT(*)FROM taskWHERE status = 2  AND operator_id = 20839  AND operate_time &gt; 1371169729  AND operate_time &lt; 1371174603  AND type = 2;常见问题  单列索引分散在各列，导致优化器选一个索引，再对其它条件做回表过滤，Rows examined 仍然很大。  时间范围是“范围谓词”，放在联合索引中靠后更合理。建议索引  建立联合索引：(status, operator_id, type, operate_time)。等值列在前，范围列 operate_time 放最后。  若查询还常常 ORDER BY operate_time，可考虑 (status, operator_id, type, operate_time) 同时覆盖排序。验证要点  EXPLAIN 观察 type: range/ref、key: idx_s_o_t_ot、rows 明显下降；Extra 无 Using filesort/Using temporary。  COUNT(*) 可结合覆盖索引实现“无回表计数”。案例 2：排序 + LIMIT 的 TopN 与 Join 的悖论目标 SQL（取最新创建的 10 条）：SELECT c.id, c.name, c.created_timeFROM contact cJOIN ... -- 复杂多表过滤WHERE ...ORDER BY c.created_time DESCLIMIT 10;两种思路  先全量 Join 后排序再 LIMIT：如果 Join 过滤后仍有海量行，再排序与分页，代价巨大。  优化策略：基于 c.created_time 可排序的联合索引（如 (created_time, id) 或与 WHERE 兼容的更长索引），先从 c 上用索引顺序取 TopN，再做 Join 过滤，不够再取下一批（Loop 取 TopN+Join 过滤）。巨幅加速 vs 灾难性退化  在“Join 过滤率较高但非极端”的情况下，这种“先取 TopN 再 Join”的策略往往带来数量级的速度提升（实践中可从秒级降到毫秒级）。  但当 Join 过滤极端严格，TopN 的候选一再被过滤掉，则会出现“反复取 10 条、反复 Join、始终不够”的灾难性退化，整体甚至比原始写法更慢。由于 MySQL 的 Nested Loop 特性，这类退化在优化器层面很难被完全消弭。工程建议  预先把 Join 侧过滤做“强裁剪”（如用子查询或派生表先把候选主键集缩小到 O(1e3) 级别，再回表取 TopN）  若业务允许，把排序字段与过滤字段合并为能被同一联合索引同时支持的模式  极端场景交由应用逻辑优化，例如缓存预计算 TopN 候选集、分层存储、异步刷新等案例 3：EXISTS + 多表 Join 的过滤上移原始 SQL（示意）：SELECT c.id, c.name, c.created_timeFROM contact cWHERE EXISTS (  SELECT 1  FROM contact_branch cb  JOIN branch_user bu ON cb.branch_id = bu.branch_id AND bu.status IN (1,2)  JOIN org_emp_info oei ON oei.data_id = bu.user_id                        AND oei.node_left &gt;= 2875                        AND oei.node_right &lt;= 10802                        AND oei.org_category = -1  WHERE c.id = cb.contact_id)ORDER BY c.created_time DESCLIMIT 10;优化思路  为 Join 键与过滤列建立必要索引：cb(branch_id, contact_id)、bu(branch_id, status)、oei(org_category, node_left, node_right, data_id) 等  半连接（Semi-join）重写：在 MySQL 8.0 上，优化器对 EXISTS/IN 有半连接转换，可显著减少回表  将“组织区间过滤”下推产生“候选 user_id 集合”，再回表关联 contact，避免大范围 Join 后再过滤  使用 STRAIGHT_JOIN 在个别误判时固定 Join 顺序案例 4：模糊匹配与全文搜索原始 SQL：SELECT id FROM article WHERE title LIKE '%分布式事务%';结论  %xxx% 前导通配符使得无法按 btree 自左向右利用索引，只能全表扫描  备选路径：全文索引（FULLTEXT/倒排/NGRAM）、ES/搜索服务；或改造为“前后缀可命中”的查询模式；或建立“反向字符串 + 函数索引”的特定业务替代方案（有代价）案例 5：函数过滤与 SARGable 改写问题 SQL：SELECT * FROM ordersWHERE DATE(create_time) = '2025-08-09';改写SELECT * FROM ordersWHERE create_time &gt;= '2025-08-09 00:00:00'  AND create_time &lt;  '2025-08-10 00:00:00';  或在 MySQL 8.0 上使用函数索引/生成列：          生成列 create_date = DATE(create_time)，并对其建索引，查询改为 WHERE create_date = '2025-08-09'      五、那些“很难优化或不该在数据库层面优化”的场景  先排序再 Join + LIMIT 的极端退化          如前述案例 2，当 Join 过滤极端严格且结果集稀疏，MySQL 将反复取 TopN 候选再 Join，导致“指数级”重试。优化器很难自动摆脱这种结构性退化，通常需要业务/架构层面改造（缓存/预计算/拆查询）。        低选择性列的大范围过滤          如 status IN (1,2,3)、gender in (0,1)，索引帮助不大。通常是全表扫描更快。需通过复合谓词联合高选择性列，或改业务模型/分区/冷热分表        全字段模糊匹配          LIKE ‘%keyword%’、跨多列 OR 混合匹配，本质是搜索问题。应引入搜索引擎或全文索引。强行在 MySQL 用索引 merge 往往治标不治本        返回超大行/大字段          查询即便命中索引，但需要回表读取大量列（BLOB/TEXT、大 JSON），IO 成本依旧高。考虑列裁剪、行列分离（大字段外置）        复杂 UDF、存储过程型逻辑          复杂运算难以下推，无法被优化器重写与索引利用。需要在应用层/ETL 预处理，或改写为可下推的谓词        数据太小/Buffer 命中率极高          小表全表扫描更快，建索引可能适得其反（维护成本 &gt; 受益）。应基于基线指标权衡        高更新写入压力下的过度索引          每个索引都是写放大。对高频写表，索引数量应严格节制；必要时离线/异步索引化（如汇总表/物化视图）      六、实施清单：从方案到上线的工程流程  明确目标与基线          指标：平均/尾延、QPS、Rows examined、临时表、回表次数、网络时间、锁等待        重写/加索引的操作顺序          先改写使 SARGable；再评估联合索引顺序；验证 ORDER BY/WHERE 兼容性      能覆盖索引则覆盖；无法覆盖时最小化回表列        EXPLAIN/EXPLAIN ANALYZE 验证          看 rows x filtered 评估真实扫描量；观察 Extra 是否出现 Using filesort/temporary        统计信息与优化器纠偏          执行 ANALYZE TABLE；必要时直方图；少量使用 Hint 纠偏误判        安全上线          使用 Invisible Index 预验证；在线 DDL；灰度与回滚；限流与隔离（读写分离、只读副本压测）        回归测试与极端参数          针对“TopN + Join 过滤极端稀疏”等已知退化路径，设计覆盖性测试数据，避免“线上才暴雷”      七、EXPLAIN 关键信号的快速判读  type：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL（越靠左越好）  key：命中的索引名；key_len：使用的索引前缀长度  rows、filtered：估计扫描行数与过滤比例；rows * filtered 近似为后续参与的行数  Extra：          Using index：覆盖索引，无回表      Using where：回表或额外条件过滤      Using index condition：索引下推（ICP）      Using temporary/Using filesort：排序/分组代价高，多半需要改写/加索引      Using join buffer：说明发生了 Block Nested-Loop Join，索引缺失或不匹配      八、索引设计的可执行准则（Checklist）  必做          为最常用的查询模式建立联合索引，等值列在前，范围列靠后      能覆盖就覆盖；返回列尽量落在索引上      避免函数包裹列；避免 %keyword% 的模糊匹配；避免大偏移分页      优化 ORDER BY/WHERE 一致性，必要时使用降序索引（MySQL 8.0 支持）      定期维护统计信息与直方图；使用 Invisible Index 做灰度验证        慎做          对低选择性列单独加索引      为“读少写多”的表加过多索引      在数据量很小的表上执意强索引化        不做          期望“先排序后 Join + LIMIT”在极端稀疏条件下自动变快      在数据库层硬啃“搜索引擎问题”（跨列 OR + 模糊）      九、总结  索引与慢查询优化的本质，是利用 B+ 树和统计信息，让绝大多数查询在“极小的页数与极少的随机 IO”中完成。  工程上，索引顺序、覆盖索引、SARGable 改写、ORDER BY 与 WHERE 的兼容性，是性价比最高的四大抓手。  “先排序 + LIMIT + 再 Join”的策略在大多数情况下很香，但在极端稀疏过滤下会灾难性退化，这是优化的边界之一，通常需要业务侧改造。  不要迷信“给所有条件列都加索引”，依查询而建才是正道。  持续基线化、灰度验证与极端参数回归，是让优化“安全落地”的保障。本文重点覆盖了索引优化原则、典型慢查询案例（含“排序+LIMIT+Join”悖论）、以及不可优化或不宜在数据库层优化的边界场景；提供了实施清单与 EXPLAIN 判读清单，可直接按清单逐项落地。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/golang/2022/10/07/Go-%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B-Channel%E4%B8%8EContext%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html",
    "title": "Go 并发模型：Channel 与 Context 最佳实践",
    "content": "如何用 Channel 建模生产者-消费者、扇入扇出、超时与取消？Context 在线程间传递取消与元数据，避免协程泄漏。1. 扇入扇出func fanOut(in &lt;-chan T, n int) []&lt;-chan T { /* ... */ }func fanIn(cs ...&lt;-chan T) &lt;-chan T { /* ... */ }2. 超时select {case &lt;-time.After(200*time.Millisecond): /* timeout */case v := &lt;-ch: _ = v}3. 泄漏排查  goroutine 泄漏：未读的 channel 阻塞；  使用 pprof 的 goroutine profile 与阻塞分析。"
  },

  {
    "url": "/web3/2022/10/01/Web3-NFT-%E6%A0%87%E5%87%86%E4%B8%8E%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5.html",
    "title": "NFT 标准与应用实践：ERC-721/1155、元数据与版税",
    "content": "NFT（Non-Fungible Token）不是“把图片放上链”，而是在链上记录“不可替代的资产凭证”，其核心在于可验证的所有权、可组合的协议接口和链上/链下协作的系统工程。本文从标准、元数据与存储、铸造与交易、版税争议、动态 NFT、跨链、索引与运维全方位实战讲解。1. 标准概览与对比  ERC-721：一物一权，每个 tokenId 独立；适合独特资产（艺术品、门票）。  ERC-1155：同一合约内可发行“半同质/多类型”资产，节省 Gas；适合游戏道具/批量空投。  EIP-2981（版税建议）：提供 royaltyInfo(tokenId, salePrice) 接口，市场可选择是否尊重。  元数据 URI：tokenURI(tokenId) -&gt; string，可返回 HTTP/IPFS/Arweave 等。接口最小集合：interface IERC721 {  event Transfer(address indexed from, address indexed to, uint256 indexed tokenId);  function ownerOf(uint256 tokenId) external view returns (address);  function safeTransferFrom(address from, address to, uint256 tokenId) external;  function tokenURI(uint256 tokenId) external view returns (string memory);}2. 元数据与存储：IPFS/Arweave 与缓存  结构：name/description/image/attributes（OpenSea 等通用字段）；  存储：          中心化 HTTP（快速，但需确保持久与防篡改）；      IPFS：内容寻址（CID），需 pin 服务保障可用性；      Arweave：长久存储付费一次。        缓存：CDN 前置（Cloudflare IPFS Gateway），前端做占位与懒加载；  防篡改：在链上记录 CID（如 ipfs://CID/123.json），并将根目录 CID 固定到事件或不可变变量。生成与上传脚本（Node.js）：// 生成 10k 元数据并上传到 IPFS（示意）const { create } = await import('ipfs-http-client')const ipfs = create({ url: 'https://ipfs.infura.io:5001/api/v0' })const meta = { name:'Art #1', description:'...', image:'ipfs://.../1.png', attributes:[{trait_type:'Rarity',value:'Rare'}] }const { cid } = await ipfs.add(JSON.stringify(meta))console.log('tokenURI=ipfs://'+cid)3. 铸造/交易流程与合约实践  铸造（Mint）：公开/白名单/签名授权（EIP-712）；  交易：P2P、拍卖、订单簿；  安全：重入防护、白名单签名防复制、safeMint/safeTransferFrom 防止接收方丢失。签名白名单铸造（示意）：contract MintPass is ERC721, EIP712 {  mapping(bytes32=&gt;bool) public used;  function mint(address to, bytes calldata sig) external {    bytes32 digest = _hashTypedDataV4(keccak256(abi.encode(keccak256(\"Mint(address to)\"), to)));    require(!used[digest],\"used\");    address signer = ECDSA.recover(digest, sig);    require(signer==whitelistSigner,\"!auth\");    used[digest]=true; _safeMint(to, ++id);  }}4. 版税争议与处理  背景：部分市场为提高流动性取消强制版税，仅保留可选打赏；  链上强制：通过转移白名单/Operator Filter 限制交易场所（兼容性差）；  现实折中：EIP-2981 提供建议值 + 市场生态共识，或链下结算；  运营建议：透明声明、签约支持版税的平台、给创作者留足分润空间。5. 动态与可组合 NFT  动态元数据：tokenURI 返回的 JSON 随链上状态或时间变化（需缓存刷新策略）；  可组合（Composable NFT）：装备/组件作为子 NFT（EIP-998/可组合规范），或通过外部合约组合查询；  关联状态：质押/解押、升级、跨合约权限校验。6. 跨链与桥接  方式：锁定-铸造、燃烧-铸造、轻客户端证明；  风险：桥被攻击、双花、流动性不足；  建议：尽量在单链内沉淀资产，通过显示跨链凭证映射，或使用成熟跨链基础设施。7. 索引与缓存：高性能展示  单个查询：ownerOf/tokenURI 直读 RPC；  批量：订阅 Transfer 事件构建持有关系；  缓存图像与元数据：CDN/边缘缓存 + 定期刷新；  SEO/社交：预生成 OpenGraph 卡片（标题/图），避免钱包/市场的拉取超时。索引器（Node + DB）示例：provider.on({ address: NFT, topics: [topicTransfer] }, async (log)=&gt;{  const { from, to, tokenId } = decode(log)  await db.tx(async t =&gt; {    if (from !== ZERO) await t.none('DELETE FROM hold WHERE addr=$1 AND id=$2',[from, tokenId])    if (to !== ZERO)   await t.none('INSERT INTO hold(addr,id) VALUES($1,$2) ON CONFLICT DO NOTHING',[to, tokenId])  })})8. 反女巫与防钓鱼  反女巫：行为/社交/设备指纹综合评分；  防钓鱼：签名提示明确用途，警惕 setApprovalForAll 的授权弹窗；  白名单分发：与 DID/VC 结合减少机器人；  前端：标注“仅签名登录/不转移资产”的提示卡片。9. 运维与看板  指标：铸造成功率、二级交易量、地板价、持有者分布、活跃度；  异常：元数据拉取失败率、渲染错误、跨链失败；  资产备份：元数据与图像的多地备份（IPFS + HTTP 备份）。10. 实操清单  设计：标准选择（721/1155）、版税策略、元数据模式；  工程：合约安全、签名授权、事件设计；  内容：版权与授权、图像防伪与盲盒揭示；  上线：白名单预热、灰度分发、市场联动；  运营：看板与告警、创作者沟通、反作弊与法务合规。  结语：NFT 的价值在于“开放可验证的所有权”和“可组合的协议接口”。在实践中，工程与运营要素同样重要：安全、缓存、跨链风控、看板告警，缺一不可。"
  },

  {
    "url": "/web3/2022/05/18/Web3-%E4%BB%A3%E5%B8%81%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E4%BB%8E%E8%AE%BE%E8%AE%A1%E5%88%B0%E5%AE%9E%E6%93%8D.html",
    "title": "加密货币与代币经济：从模型设计到实操监控",
    "content": "代币经济（Tokenomics）是协议可持续的核心约束。成功的设计既要有工程严谨性（参数/代码/可观测）也要有博弈论直觉（激励一致性/抗攻击）。本文从“发行→释放→流动性→治理→风控→监控看板”构建一套可落地的代币经济方法论，附上可复用的合约与脚本片段。1. 发行与释放（Token Generation &amp; Emission）  初始分配：团队/顾问/投资人/社区/金库比例；  释放曲线：线性/阶梯/里程碑触发，避免短期砸盘；  锁仓与归属（vesting）：可撤回与不可撤回的权衡；  二级市场前的“冷启动”：空投/任务/白名单+反女巫。合约片段（Vesting）：contract Vesting {  IERC20 public token; mapping(address=&gt;uint256) public total; mapping(address=&gt;uint256) public claimed; uint64 public start; uint64 public cliff; uint64 public duration;  function claim() external { /* 线性释放，检查 cliff 后可领取 */ }}2. 治理与金库（Treasury）  治理代币与权重：一币一票/锁定加权/代表委托；  投票与执行：Snapshot+Governor，Timelock 管控；  金库支出：预算提案→投票→多签执行；  长期激励：生态基金、Grants、赏金计划。3. 流动性与做市（AMM/CEX/MM）  AMM：Uniswap v2（x*y=k）、v3 集中流动性（价格区间提供）；  初始流动性：金库注入与 LP 代币管理；  价稳策略：回购与销毁、协议费回流；  防闪崩：限价/时间加权平均（TWAP）价作为参考。操作脚本（提供流动性）：// 使用 viem/ethers 调用路由合约添加流动性4. 模型案例与参数  通胀模型：恒定/递减/事件触发；  双代币模型：治理代币 + 价值捕获代币（fee share/质押奖励）；  激励分配：按使用量/贡献度发放，反垃圾策略（行为签名/反女巫）；  费用结构：交易费/提取费/提前解锁罚金；  跨链发行：桥接与记账，避免双花。5. 反女巫与合规  反女巫：PoH、社交图、设备/行为指纹、多维度阈值；  合规：KYC/AML、地区限制、证券属性评估；  法务协调：条款、风险披露、隐私策略。6. 风控指标与告警  持仓集中度（头部地址占比）；  周转率与链上活跃度；  价格锚（预言机）与滑点监测；  资金流入/流出异常、跨链桥风险；  善意与恶意机器人占比（MEV/三明治）。7. 仪表盘与数据源  On-chain 指标：自建 ETL 或 dune/subsquid；  价格与流动性：The Graph、Coingecko API；  金库资产与支出：多签事件索引（Gnosis Safe）。8. 运营节奏与迭代  周期性回顾：代币释放/通胀/金库余额/激励效果；  参数治理：SIP/提案流程，临时变更走紧急流程；  防御演练：闪崩/预言机异常/桥被攻击时的兜底方案。9. 小结代币经济的“好坏”，体现在能否让参与者激励一致并抵御攻击。用工程化手段（合约/脚本/看板/告警）让模型“可测量、可回滚、可演进”，才是真正可持续的路径。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/java/2022/03/30/Java-Spring-%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E9%99%B7%E9%98%B1.html",
    "title": "Java Spring 事务传播与隔离级别陷阱",
    "content": "事务机制在软件开发中扮演举足轻重的角色。本文系统介绍数据库与分布式事务的原理与应用、隔离级别与典型并发现象示例，并结合 Spring 的传播机制与实现原理，最后从 CAP 视角给出大型系统中确保“相对一致性”的工程方案与实战蓝本。一、为何需要事务  目标：在并发与故障条件下，保证数据正确性与可预期性。  ACID：原子性、一致性、隔离性、持久性；工程上需在性能、可用性与一致性间权衡。二、数据库事务与隔离级别（含示例）  常见隔离级别与现象          Read Uncommitted：可能脏读；几乎不用。      Read Committed (RC)：避免脏读；仍有不可重复读与幻读（PostgreSQL 默认）。      Repeatable Read (RR)：同一事务内多次读取结果一致；InnoDB 的 RR 基于 MVCC + Next-Key Lock，普通一致性读看到“快照”，更新扫描加间隙锁抑制幻行（MySQL 默认）。      Serializable：最强隔离；性能代价大，通常依赖锁或乐观并发控制。        并发现象最小示例          脏读（只在 RU）：        -- 会话ABEGIN;UPDATE account SET balance = balance - 100 WHERE id = 1; -- 未提交-- 会话B（RU）SELECT balance FROM account WHERE id = 1; -- 读到未提交数据（脏读）                    不可重复读（RC）：        -- 会话ABEGIN;SELECT balance FROM account WHERE id = 1; -- 读到 1000-- 会话BBEGIN; UPDATE account SET balance = 900 WHERE id = 1; COMMIT;-- 会话ASELECT balance FROM account WHERE id = 1; -- 再读到 900（不可重复读）COMMIT;                    幻读（RC 或部分 RR 场景）：        -- 会话ABEGIN;SELECT * FROM orders WHERE amount &gt; 100; -- 返回 N 行-- 会话BINSERT INTO orders(id, amount) VALUES(999, 200); COMMIT;-- 会话ASELECT * FROM orders WHERE amount &gt; 100; -- 返回 N+1 行（幻读）COMMIT;                      实现与注意          MVCC：RC/RR 通过快照读减少锁冲突；RR 在 InnoDB 下对“锁定读/更新”使用 Next-Key Lock 抑制幻读。      加锁读：SELECT ... FOR UPDATE/LOCK IN SHARE MODE 可确保当前读一致且参与加锁，抑制写冲突与幻读。      建议：默认 RC/RR；强一致写路径（转账、库存）采用 RR + 加锁读，或使用可控的序列化/业务锁。      三、分布式事务模式与取舍  XA/2PC（协调器 + 参与者，两阶段提交）          优点：强一致；缺点：阻塞、对资源管理器要求高、性能与可用性差；云原生场景较少采用。        TCC（Try-Confirm-Cancel）          优点：业务可感知，接口粒度可控；缺点：实现复杂，需要补偿与悬挂/空回滚处理；适用于账务/库存等核心域。        Saga（编排/舞蹈）          优点：最终一致、扩展性好；缺点：中间态可见、补偿设计复杂；适用于电商下单等长链路。        可靠消息 + Outbox          优点：本地事务落库，与“待发消息”同库同事务，异步发布，消费端幂等；工程落地成熟。      缺点：引入异步与补偿复杂度；需要投递保证与去重。      四、Spring 事务：传播机制与实现原理  实现原理          AOP 代理（JDK/CGLIB）拦截 @Transactional 方法，委派 TransactionInterceptor。      PlatformTransactionManager（如 DataSourceTransactionManager/JpaTransactionManager）负责开启/提交/回滚。      TransactionSynchronizationManager 用 ThreadLocal 绑定连接/资源与同步回调。      回滚规则：默认对 RuntimeException/Error 回滚；受检异常需显式 rollbackFor。        源码级实现细节（传播行为如何生效）          激活入口（配置）：@EnableTransactionManagement → TransactionManagementConfigurationSelector → 注册 ProxyTransactionManagementConfiguration                  定义 BeanFactoryTransactionAttributeSourceAdvisor（切点）          使用 AnnotationTransactionAttributeSource 解析 @Transactional          注入 TransactionInterceptor（拦截器）                    代理创建：基础设施自动代理器（如 InfrastructureAdvisorAutoProxyCreator）为匹配切点的方法创建 JDK/CGLIB 代理，解决横切逻辑织入      拦截主链：TransactionInterceptor#invoke → TransactionAspectSupport#invokeWithinTransaction1) 解析事务属性：TransactionAttributeSource#getTransactionAttribute2) 解析事务管理器：determineTransactionManager（支持 transactionManager 指定）3) 按传播语义开/加入事务：createTransactionIfNecessary → PlatformTransactionManager#getTransaction4) 调用业务方法：invocation.proceed()5) 正常则 commit，异常走 completeTransactionAfterThrowing 判定回滚（TransactionAttribute#rollbackOn(Throwable)，默认仅回滚 RuntimeException/Error）      传播决策核心：AbstractPlatformTransactionManager#getTransaction(TransactionDefinition)                  若存在事务（isExistingTransaction）：                          PROPAGATION_REQUIRED/SUPPORTS/MANDATORY：加入当前事务（共享连接与同步）              PROPAGATION_REQUIRES_NEW：suspend 挂起当前事务 → doBegin 开新事务 → 结束后 resume              PROPAGATION_NOT_SUPPORTED：suspend 挂起，以非事务方式执行 → resume              PROPAGATION_NEVER：存在事务直接抛 IllegalTransactionStateException              PROPAGATION_NESTED：如支持保存点（useSavepointForNestedTransaction）则在当前事务 createSavepoint，失败回滚到保存点；否则可能抛 NestedTransactionNotSupportedException                                若不存在事务：                          REQUIRED/REQUIRES_NEW/NESTED：doBegin 开启新事务（NESTED 在无外部事务时等价于新事务）              SUPPORTS：非事务执行              MANDATORY：抛 IllegalTransactionStateException              NOT_SUPPORTED/NEVER：非事务执行                                          数据源事务实现（典型）：DataSourceTransactionManager                  开启：doBegin 获取连接并配置隔离级别、setReadOnly(true)、setAutoCommit(false)，绑定 ConnectionHolder 至 TransactionSynchronizationManager          挂起/恢复：doSuspend/doResume 解绑/重新绑定资源          提交/回滚：doCommit/doRollback；NESTED 通过 SavepointManager 创建/回滚保存点                    资源与同步：TransactionSynchronizationManager                  线程级别绑定资源：bindResource/unbindResource（如 DataSource → ConnectionHolder）          暴露上下文：isActualTransactionActive、getCurrentTransactionName、isCurrentTransactionReadOnly          注册同步回调：registerSynchronization（JPA/Hibernate flush、MQ 出库回调等借此挂接）                    隔离与只读映射：TransactionDefinition → JDBC Connection#setTransactionIsolation 与 setReadOnly（是否真正生效取决于驱动与数据库）      关键类型速览：TransactionAttribute/RuleBasedTransactionAttribute（回滚规则）、RollbackRuleAttribute、TransactionStatus（事务状态/保存点控制）      JPA/Hibernate Flush 时机与事务边界  Flush 不等于提交：Flush 将持久化上下文（一级缓存）中的变更同步到数据库，但仍处于当前数据库事务内，直到 commit。  触发时机（Hibernate FlushModeType.A\u00000UTO 默认）：          查询前：为保证查询结果与当前持久化上下文一致，可能在执行查询前先 flush（同表/相关实体时）。      显式调用：EntityManager.flush()/Session.flush()。      事务完成前：在 commit 前自动 flush。        Flush 模式：          AUTO（默认）：必要时自动 flush（查询前/提交前）。      COMMIT：延迟到提交前再 flush（可能减少中途多次 flush）。      MANUAL：仅在显式调用 flush() 时触发。        与 Spring 只读事务的关系：          Spring 在使用 Hibernate 时，@Transactional(readOnly = true) 通常通过方言（如 HibernateJpaDialect）将会话 flush 模式降为 MANUAL，减少不必要的脏检查与 flush；这只是“优化提示”，并不强制禁止写入。      仍需数据库权限控制与代码自律（如不在只读事务中执行写操作）。        一致性影响：由于 AUTO 模式下查询可能触发 flush，很多约束/唯一键冲突会在“查询时”或“提交前”抛出，而非在调用 persist() 当下，测试时需注意断言位置。@Transactionalpublic void demo(EntityManager em) {  user.setEmail(\"dup@example.com\");  em.persist(user);  // 这里未必立即抛异常  em.createQuery(\"select u from User u where u.email = :e\")    .setParameter(\"e\", \"someone@example.com\")    .getResultList(); // 若查询触发 flush，唯一索引冲突可能在此处抛出}OpenEntityManagerInView 模式影响与建议  原理：OpenEntityManagerInViewFilter/Interceptor 在 Web 请求整个生命周期内绑定 EntityManager 到线程，使得 Controller/View 层在 Service 事务结束后仍可进行延迟加载，避免 LazyInitializationException。  风险：          模糊事务边界：在“视图渲染期”继续访问数据库，容易形成 N+1 查询与不可预期的长连接占用。      可观测性降低：难以定位慢查询发生在业务层还是视图层。      写路径混入：若无约束，视图层也可能触发写相关 flush（尽管少见，但应避免）。        Spring Boot 默认：spring.jpa.open-in-view 在多数版本默认 true，官方已在 2.x/3.x 强烈提示谨慎使用。  建议：          对写请求或核心域接口，设置 spring.jpa.open-in-view=false，在 Service 层完成 DTO 裁剪/投影映射与必要的 fetch join。      对读多的页面，如确需开启，务必配合 @Transactional(readOnly = true)、限制查询数量、启用二级缓存/查询缓存谨慎优化。      通过 EntityGraph/fetch join/投影（如 Spring Data JPA interface-based projections）解决懒加载需求。      # application.ymlspring:  jpa:    open-in-view: false// 通过 fetch join 在事务内一次性加载所需数据@Query(\"select o from Order o join fetch o.items where o.id = :id\")Optional&lt;Order&gt; findWithItems(@Param(\"id\") Long id);调用链流程图（简化）sequenceDiagram  autonumber  participant Client  participant Proxy as AOP Proxy  participant TI as TransactionInterceptor  participant TAS as TransactionAttributeSource  participant TM as PlatformTransactionManager  participant Biz as BusinessMethod  Client-&gt;&gt;Proxy: 调用 @Transactional 方法  Proxy-&gt;&gt;TI: invoke()  TI-&gt;&gt;TAS: 解析事务属性  TI-&gt;&gt;TM: getTransaction(def)  TM--&gt;&gt;TI: TransactionStatus（可能挂起/新建/加入）  TI-&gt;&gt;Biz: proceed()  Biz--&gt;&gt;TI: 返回或抛异常  alt 正常返回    TI-&gt;&gt;TM: commit(status)  else 异常    TI-&gt;&gt;TM: rollback(status)（按 rollbackOn 判定）  end  TI--&gt;&gt;Proxy: 返回结果  Proxy--&gt;&gt;Client: 返回结果传播决策流程（核心分支）flowchart TD  A[进入 getTransaction] --&gt; B{是否存在事务}  B -- 否 --&gt; C{传播属性}  C -- REQUIRED/REQUIRES_NEW/NESTED --&gt; D[doBegin 新事务]  C -- SUPPORTS/NOT_SUPPORTED/NEVER --&gt; E[非事务执行]  C -- MANDATORY --&gt; F[抛 IllegalTransactionStateException]  B -- 是 --&gt; G{传播属性}  G -- REQUIRED/SUPPORTS/MANDATORY --&gt; H[加入当前事务]  G -- REQUIRES_NEW --&gt; I[suspend 挂起 -&gt; doBegin 新事务]  G -- NOT_SUPPORTED --&gt; J[suspend 挂起 -&gt; 非事务]  G -- NEVER --&gt; K[抛 IllegalTransactionStateException]  G -- NESTED --&gt; L[createSavepoint 保存点]精简源码片段引用（Spring Framework）// org.springframework.transaction.interceptor.TransactionInterceptorpublic Object invoke(MethodInvocation invocation) throws Throwable {    Class&lt;?&gt; targetClass = AopUtils.getTargetClass(invocation.getThis());    return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);}// org.springframework.transaction.interceptor.TransactionAspectSupportprotected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass,                                         InvocationCallback invocation) throws Throwable {    TransactionAttributeSource tas = getTransactionAttributeSource();    TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null);    PlatformTransactionManager tm = determineTransactionManager(txAttr);    TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, methodIdentification(method, targetClass));    try {        Object ret = invocation.proceedWithInvocation();        commitTransactionAfterReturning(txInfo);        return ret;    }    catch (Throwable ex) {        completeTransactionAfterThrowing(txInfo, ex);        throw ex;    }    finally {        cleanupTransactionInfo(txInfo);    }}// org.springframework.transaction.support.AbstractPlatformTransactionManagerpublic final TransactionStatus getTransaction(TransactionDefinition definition)        throws TransactionException {    Object transaction = doGetTransaction();    if (isExistingTransaction(transaction)) {        // 根据传播行为: REQUIRED/SUPPORTS/MANDATORY/REQUIRES_NEW/NOT_SUPPORTED/NEVER/NESTED        return handleExistingTransaction(definition, transaction, debugEnabled);    }    // 无事务，根据传播行为决定 doBegin 或非事务/异常    return startTransaction(definition, transaction, debugEnabled);}// org.springframework.jdbc.datasource.DataSourceTransactionManagerprotected void doBegin(Object transaction, TransactionDefinition definition) {    Connection con = DataSourceUtils.getConnection(this.dataSource);    con.setAutoCommit(false);    prepareTransactionalConnection(con, definition); // 隔离级别/只读    DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction;    txObject.setConnectionHolder(new ConnectionHolder(con), true);    TransactionSynchronizationManager.bindResource(this.dataSource, txObject.getConnectionHolder());}  版本注记：上述调用链在 Spring Framework 5.3.x 与 6.x 之间主体一致；个别方法签名与内部重构可能略有差异，但关键职责与流程相同。  传播行为（常用）          REQUIRED（默认）：有则加入，无则新建；通用首选。      REQUIRES_NEW：挂起外部事务，新建新事务；常用于审计/日志/可靠消息，避免与外层同生共死。      SUPPORTS：有则加入，无则非事务。      MANDATORY：必须在事务内，否则异常。      NOT_SUPPORTED：挂起事务，以非事务方式执行；适合大查询/报表。      NEVER：存在事务则抛异常。      NESTED：保存点；内层失败可局部回滚（需 JDBC Savepoint 与 DataSourceTransactionManager 支持；JPA 不支持真嵌套）。        关键示例          REQUIRED 与 REQUIRES_NEW：        @Servicepublic class OrderService {  @Transactional // REQUIRED  public void placeOrder() {    inventoryService.deduct();    auditService.record(); // 方法上标注 REQUIRES_NEW，独立提交  }}                    NESTED 局部回滚：        @Transactionalpublic void batchCreate(List&lt;Item&gt; items) {  for (Item item : items) {    userService.createOneNested(item); // @Transactional(propagation = NESTED)  }}                      常见陷阱          自调用不生效（同类内方法互调绕过代理）；将被调方法提取到另一 @Service 或注入自身代理。      private/final 方法、构造器不拦截；异步/新线程无事务上下文。      多数据源需独立 TransactionManager 或采用分布式事务模式。      readOnly=true 仅作优化提示，不保证不写；仍需权限与代码约束。      NESTED 仅在底层事务管理器支持保存点时才是真嵌套（如 DataSourceTransactionManager）；JpaTransactionManager 不支持嵌套，可能抛异常或退化为新事务策略。      五、大型系统一致性策略（结合 CAP）  CAP 取舍：分布式系统必须容忍分区（P），在一致性（C）与可用性（A）间取舍。          CP 优先：撮合引擎、资金账本、强一致库存；采用单主/共识、严格限流与降级，牺牲可用性换正确性。      AP 优先：订单、推荐、搜索、报表；采用最终一致、补偿/重试、幂等、读写分离、缓存旁路。        工程基线          本地事务 + 出库表（Outbox）+ MQ      幂等：幂等键/唯一索引/幂等表、去重缓存、乐观锁（version/timestamp）      显式状态机：订单/库存/支付状态跃迁，防止“写两份不同真相”      读模型：CQRS/物化视图；前台读可用性优先，后台对账纠偏      重试与时序：至少一次投递 + 幂等消费，必要时按业务键分区保证顺序      热点与锁：场景化选择悲观/乐观/分布式锁，控制锁粒度与超时      六、实战蓝本（落地建议）      可靠消息 + Outbox 工作流1) 业务服务本地事务内：写业务数据 + 写 outbox（状态 PENDING）2) 提交后由发布器轮询/CDC 发布 MQ；成功标记 SENT3) 消费者：用“消息ID 唯一索引/去重表”保证幂等；处理成功后标记完成4) 失败自动重试（指数退避）+ 死信队列 + 人工干预    @Transactionalpublic void createOrder(CreateOrderCmd cmd) {  orderRepo.save(order);  outboxRepo.save(Outbox.of(\"OrderCreated\", payload, msgId));}        Saga（编排型）：编排器持久化 Saga 状态，顺序调用步骤；失败按反向补偿逐一回滚。  TCC 接口：资源服务提供 try/reserve、confirm、cancel；实现幂等、空回滚与悬挂处理。七、测试与验证建议  隔离级别：集成测试开两连接/两线程，用 CountDownLatch 控制交错，验证 RC/RR 行为与锁持有。  传播机制：SpringBootTest + Testcontainers，验证 REQUIRES_NEW 独立提交、NESTED 保存点回滚。  一致性链路：本地起 MQ（Kafka/RabbitMQ），模拟网络抖动、重复投递、乱序，核验幂等。  观测性：为每个事务/消息打 traceId、msgId，收集提交时延、重试次数、DLQ 速率等指标。八、实施注意  严格控制事务边界与时长：仅包裹必要的 DB 写入与同库查询，不包远程调用/外部 IO。  明确每条链路的目标一致性等级与降级策略。  把“补偿与对账”作为一等公民：对账任务、自动巡检、纠偏脚本。"
  },

  {
    "url": "/web3/2021/11/06/Web3-%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%89%E5%85%A8%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html",
    "title": "智能合约工程与安全最佳实践：Solidity/Foundry 上手到上线",
    "content": "智能合约是 Web3 应用的“规则中枢”。它一经部署即“公开、自动、可验证”，带来强信任的同时也几乎没有运维回旋空间。要在生产环境长期稳定运行，必须以工程化与安全为第一原则：标准化目录结构、完善测试与审计流程、上线策略与紧急预案、可观测与变更留痕。本文体系化给出从 0 到 1 的落地路径与可直接复用的清单。1. 工程化目录与依赖管理  目录结构建议：    contracts/       # 合约源码└── modules/     # 复用模块（库、接口）src/             # 或 contracts/（Foundry 惯例为 src/）scripts/         # 部署与迁移脚本lib/             # 依赖（OpenZeppelin 等）test/            # 单元/属性/模糊测试out/             # 构建产物（abi、bin）        依赖：锁定版本，尽量固定到 commit（forge install OpenZeppelin/openzeppelin-contracts@v5.0.1）。  约定：Solidity ^0.8.x，启用 viaIR/优化器配置；启用 emit 与事件留痕，重要状态变化务必emit 事件。2. 测试金字塔：单元→属性→模糊→集成  单元测试：逻辑分支与边界（溢出/零地址/重复调用）；  属性测试（invariant）：在任意序列操作下不变式成立（余额守恒、权限不泄露、利率界限）；  模糊测试：随机生成输入与调用序列，捕获隐藏分支（Foundry forge test --fuzz-runs 10000）；  集成测试：与真实依赖交互（主网 fork），验证预言机、路由器、金库等外部合约适配。示例（Foundry）：contract Invariant is Test {  MyVault v; ERC20 token;  function setUp() public { /* 部署并注入 */ }  function invariant_totalSupplyLeBalance() public view {    assertLe(v.totalSupply(), token.balanceOf(address(v)));  }}3. 常见漏洞矩阵与防护| 类型 | 描述 | 防护 || — | — | — || 重入 | 外部调用后状态未更新 | Checks-Effects-Interactions、ReentrancyGuard、最小外部调用 || 访问控制 | onlyOwner 缺失/后门 | 明确角色（AccessControl）、多签、不可升级关键路径 || 算术 | 下溢/溢出（&lt;0.8） | Solidity 0.8+ 或 SafeMath || 授权 | ERC20 approve 竞态 | increaseAllowance/permit，或拉取模型 || 预言机 | 价格被操纵 | 取中值/时间加权、聚合源、熔断 || 可升级 | 存储冲突/不可逆 | UUPS/Transparent Proxy 模式，固定存储布局，脚本化校验 || 随机性 | blockhash 可预测 | VRF 或承诺-揭示（commit-reveal） || 初始化 | 代理未初始化 | initializer 修饰器与构造参数校验 |4. 审计前自查与工具  Slither：静态分析（可集成 CI）；  Mythril/ConsenSys Diligence：符号执行；  Echidna/Foundry：属性/模糊测试；  Surya：合约可视化，辅助审查调用图；  Foundry debug：调试交易回溯；  Gas Reporter：识别高消耗路径。CI 示例：name: solidity-cion: [push, pull_request]jobs:  test:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - uses: foundry-rs/foundry-toolchain@v1        with: { version: nightly }      - run: forge build      - run: forge test -vv --ffi      - run: slither . --solc-remaps @openzeppelin=lib/openzeppelin-contracts/5. Gas 优化与经济性  读/写路径拆分，减少 SSTORE 次数；  unchecked 包裹可证明安全的运算；  事件参数使用 indexed 提高检索效率；  小心 for/数组扩容，必要时映射替代；  批处理与“延迟结算”减少链上交互次数；  将重计算改为链下预处理+链上验证（ZK/签名校验）。6. 可升级/代理模式与版本治理  Transparent Proxy：用户总是通过 Proxy 地址交互；  UUPS：逻辑合约自持升级；  风险：存储槽冲突、初始化复用、访问控制绕过；  治理：升级由多签/Timelock 控制，至少 24h 延时+公告。存储布局对齐示例：contract V1 { uint256 a; }contract V2 is V1 { uint256 b; } // 仅追加，不可重排/删除7. 部署、参数与变更留痕  所有部署脚本参数入库（链ID、实现地址、Proxy 地址、owner 多签、初始化参数）；  生成 deployments.json，前端/后端/监控统一读取；  变更审计：每次升级/参数调整产生日志与签名人列表；  版本标签：事件中携带 VERSION，便于索引。Foundry 脚本：contract Deploy is Script {  function run() external {    vm.startBroadcast();    Impl impl = new Impl();    TransparentUpgradeableProxy p = new TransparentUpgradeableProxy(address(impl), admin, data);    vm.stopBroadcast();  }}8. 紧急预案与演练  Kill Switch（暂停开关）仅限关键逻辑，使用 Pausable；  金库提款白名单与日限额，防单点提空；  回滚流程：升级记录可随时回退至前版本实现；  演练：季度在低流量窗口做“带压回滚/暂停/恢复”演练。9. 观测与运营  事件流：关键事件建立告警规则（异常频次/金额阈值）；  交易成败与 Gas：P95 确认时间、失败率；  用户路径：签名拒绝率、网络切换失败率；  合作依赖：预言机更新延迟、路由合约可用性；  文档与教育：授权/签名解释页、风险披露、常见问题库。10. 小结合约开发不是“写几份 Solidity 就完事”，而是端到端的工程体系：安全第一、测试充分、可观测完备、上线有门禁、变更可回滚。以“最小信任后端+合约为规则源+严格审计与演练”的组合，才能在开放环境中长期生存。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/php/2021/06/10/PHP-%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E4%B8%8E%E9%9B%86%E4%B8%AD%E5%8C%96.html",
    "title": "PHP 实时日志采集与集中化",
    "content": "如何在 PHP 体系下实现实时日志采集、清洗、聚合与检索？本文结合物理机与 Kubernetes 两种运行环境，给出分阶段演进路线、最佳实践与可落地配置（EFK/PLG/ClickHouse/OTel），并附带 PHP 端具体实现建议。架构概览物理机 / VM 拓扑flowchart TD  A[\"微服务 (物理机/VM)\"] --&gt; B[\"应用日志: JSON 文件 / journald\"]  B --&gt; C[\"宿主机 Agent: Fluent Bit / Vector / OTel Collector\"]  C --&gt;|\"TLS+重试+背压\"| D[\"Kafka (可选缓冲)\"]  C --&gt; E[\"处理/路由: Logstash / OTel Collector / Vector\"]  D --&gt; E  E --&gt; F[\"Elasticsearch / OpenSearch\"]  E --&gt; G[\"ClickHouse\"]  E --&gt; H[\"Loki\"]  F --&gt; I[\"可视化: Kibana / Grafana\"]  G --&gt; I  H --&gt; I  J[\"治理: 时间同步(NTP) + 结构化Schema + 脱敏/掩码\"] -.-&gt; EKubernetes 拓扑flowchart TD  subgraph K8s[\"Kubernetes 集群\"]    A1[\"Pod: 微服务容器\"] --&gt; B1[\"stdout/stderr (结构化JSON)\"]    B1 --&gt; C1[\"DaemonSet: Fluent Bit / Vector\"]    A1 --&gt; D1[\"Sidecar(可选): OTel Collector / Fluent Bit\"]    C1 --&gt;|\"TLS+背压+限流\"| E1[\"集群网关: OTel Collector / Ingress\"]  end  E1 --&gt; F1[\"Kafka / NATS / Redis Streams (缓冲)\"]  E1 --&gt; G1[\"Loki / Elasticsearch / ClickHouse\"]  F1 --&gt; H1[\"处理与路由: Logstash / Vector / OTel Collector\"]  H1 --&gt; G1  G1 --&gt; I1[\"Grafana / Kibana / 自研埋点分析\"]  J1[\"治理: 多租户、标签、索引生命周期、合规脱敏\"] -.-&gt; H1演进阶段与适用场景  传统本地文件 + logrotate：单机/少量服务；简单但难检索、风险高。  中央化 Syslog（rsyslog/syslog-ng/journald）：轻量汇聚，结构化不足。  EFK/ELK：强检索与可视化；成本与治理压力需控制（ILM）。  容器化（stdout JSON + DaemonSet Agent）：与 K8s 契合；注意 label 基数。  事件流驱动（Kafka/NATS 缓冲解耦）：高吞吐可重放；链路更长。  OpenTelemetry 一体化：标准 OTLP，日志/链路/指标互相关联。  成本/性能优化（Loki/ClickHouse/对象存储分层）：性价比高，查询语义差异需适配。通用最佳实践  结构化与上下文：统一 JSON Schema（timestamp、level、service、env、trace_id、span_id、request_id、user_id）。  安全合规：采集端脱敏/掩码；TLS 传输；RBAC；多租户隔离。  稳定性：本地缓冲、断点续传、退避重试、背压/限流、时钟同步。  成本与性能：控制日志级别与采样；热/温/冷分层；限制高基数字段。  运维治理：ILM/TTL；集中配置与热更新；SLO/告警（延迟、拒收、落库错误率）。物理机/VM 最佳实践推荐：应用输出 JSON 到文件或 journald；宿主机 Agent（Fluent Bit/Vector/OTel Collector）采集→可选 Kafka 缓冲→后端（OpenSearch/ClickHouse/Loki）。Fluent Bit（Tail → Kafka → OpenSearch）[SERVICE]    Flush        1    Parsers_File parsers.conf    Log_Level    info[INPUT]    Name              tail    Path              /var/log/app/*.log    Tag               app.*    Multiline         On    Parser            docker    DB                /var/lib/fluent-bit/tail.db    Mem_Buf_Limit     50MB    Skip_Long_Lines   On[FILTER]    Name          modify    Match         app.*    Add           env prod    Add           service myservice[OUTPUT]    Name            kafka    Match           app.*    Brokers         kafka-1:9092,kafka-2:9092    Topics          logs.app    rdkafka.queue.buffering.max.ms 100    rdkafka.compression.codec      lz4    rdkafka.security.protocol      ssl[OUTPUT]    Name            es    Match           app.*    Host            opensearch.local    Port            9200    HTTP_User       fluent    HTTP_Passwd     xxxxxx    Logstash_Format On    tls             OnVector（Tail → 脱敏 → Loki）[sources.app]type = \"file\"include = [\"/var/log/app/*.log\"]ignore_older_secs = 86400fingerprint.strategy = \"device_and_inode\"[transforms.mask]type = \"remap\"inputs = [\"app\"]source = '''. = parse_json!(.message).email = replace!(.email, r'([\\\\w.%+-]+)@([\\\\w.-]+\\\\.[A-Za-z]{2,})', \"***@***\").credit_card = null'''[sinks.loki]type = \"loki\"inputs = [\"mask\"]endpoint = \"https://loki.local\"encoding.codec = \"json\"labels = {service=\"myservice\", env=\"prod\"}out_of_order_action = \"accept\"logrotate（与 tail/采集器配合）/var/log/app/*.log {  daily  rotate 7  compress  missingok  copytruncate  create 0640 app app}Kubernetes 最佳实践原则：应用只输出 stdout JSON；使用 DaemonSet（Fluent Bit/Vector/Promtail）统一采集 /var/log/containers/*，自动附加 k8s 元数据；Sidecar 仅在需本地解析/脱敏时使用；开启本地缓冲、资源限额、背压与基数治理。Fluent Bit DaemonSet（Containers → Loki）[SERVICE]    Parsers_File parsers.conf[INPUT]    Name              tail    Path              /var/log/containers/*.log    Tag               kube.*    Parser            docker    Docker_Mode       On    Mem_Buf_Limit     100MB    DB                /var/fluent-bit/tail.db[FILTER]    Name                kubernetes    Match               kube.*    Kube_URL            https://kubernetes.default.svc:443    Merge_Log           On    Keep_Log            Off[OUTPUT]    Name          loki    Match         kube.*    Host          loki-gateway    Port          3100    Labels        job=fluentbit, env=prod, kubernetes['namespace_name'], kubernetes['container_name']    Auto_kubernetes_labels OnPromtail（自动发现 Pods）scrape_configs:- job_name: kubernetes-pods  pipeline_stages:  - docker: {}  - labeldrop:      - filename  kubernetes_sd_configs:  - role: pod  relabel_configs:  - source_labels: [__meta_kubernetes_pod_label_app]    target_label: appOpenTelemetry Collector（OTLP/filelog → Kafka/Loki）receivers:  otlp:    protocols: {http: {}, grpc: {}}  filelog:    include: [/var/log/containers/*.log]    operators:    - type: json_parserprocessors:  batch: {}  attributes:    actions:    - key: env      value: prod      action: upsertexporters:  kafka:    brokers: [kafka-1:9092]    topic: logs.app  loki:    endpoint: http://loki:3100/loki/api/v1/pushservice:  pipelines:    logs/primary:      receivers: [filelog, otlp]      processors: [attributes, batch]      exporters: [kafka, loki]可落地方案与模板小团队低成本（PLG）  Promtail/Fluent Bit → Loki → Grafana；控制标签基数，分层保留。    limits_config:retention_period: 168hcompactor:working_directory: /data/compactorcompaction_interval: 5mdelete_request_cancel_period: 24h      中型团队检索优先（EFK + Kafka）  Fluent Bit/Vector → Kafka → Logstash/OTel Collector → OpenSearch；Kafka 缓冲与多消费者，OpenSearch 做 ILM。    {\"policy\": {  \"phases\": {    \"hot\": {\"actions\": {\"rollover\": {\"max_size\": \"50gb\", \"max_age\": \"7d\"}}},    \"warm\": {\"actions\": {\"forcemerge\": {\"max_num_segments\": 1}}},    \"cold\": {\"min_age\": \"30d\", \"actions\": {\"freeze\": {}}},    \"delete\": {\"min_age\": \"90d\", \"actions\": {\"delete\": {}}}  }}}      海量吞吐/性价比（Vector + ClickHouse）  Vector DS/Agent → Vector Aggregator → ClickHouse（MergeTree/表分区）。    CREATE TABLE logs.app(ts DateTime CODEC(Delta, ZSTD),level LowCardinality(String),service LowCardinality(String),trace_id String,message String,k8s_namespace LowCardinality(String),labels Map(String, String))ENGINE = MergeTreePARTITION BY toDate(ts)ORDER BY (service, ts)TTL ts + INTERVAL 30 DAY DELETESETTINGS index_granularity = 8192;      合规与审计  采集端脱敏（Vector remap/Fluent Bit grep），传输与落盘加密，审计日志 WORM/对象存储锁不可篡改。边缘/离线  本地持久化缓冲，网络可用回传；启用压缩与节流；按优先级丢弃非关键日志。PHP 实践与配置示例目标  统一 JSON Schema；stdout（K8s）或文件/journald（VM）；与链路追踪关联（trace_id/span_id）；采集端脱敏与缓冲。Monolog（stdout JSON + 关联上下文）&lt;?phprequire 'vendor/autoload.php';use Monolog\\\\Logger;use Monolog\\\\Handler\\\\StreamHandler;use Monolog\\\\Formatter\\\\JsonFormatter;$logger = new Logger('app');$handler = new StreamHandler('php://stdout', Logger::INFO);$handler-&gt;setFormatter(new JsonFormatter(JsonFormatter::BATCH_MODE_JSON, false));// 处理器：注入通用字段（建议从请求头、会话、OTel 上下文中提取）$logger-&gt;pushProcessor(function (array $record) {    $record['extra']['env'] = getenv('APP_ENV') ?: 'prod';    $record['extra']['service'] = 'my-php-service';    $record['extra']['request_id'] = $_SERVER['HTTP_X_REQUEST_ID'] ?? null;    $record['extra']['trace_id'] = $_SERVER['HTTP_X_TRACE_ID'] ?? null; // 或从 OTel SDK 获取    $record['extra']['user_id'] = $_SESSION['user_id'] ?? null;    return $record;});$logger-&gt;pushHandler($handler);// 示例$logger-&gt;info('user login', ['user_id' =&gt; 123]);$logger-&gt;error('db failed', ['error_code' =&gt; 'DB_CONN_TIMEOUT']);PHP-FPM/Nginx（容器化）将错误与访问日志输出到 stdout/stderr; php.inilog_errors = On; php-fpm.conf 或 www.conferror_log = /proc/self/fd/2; 可选：将 FPM 访问日志也导向 stdout/stderr; access.log = /proc/self/fd/2物理机（文件落盘）  Monolog 将日志写入 /var/log/app/app.log，配合 logrotate；采集器使用 tail 指纹/offset 防重。与 OpenTelemetry 关联  在反向代理或应用层透传 traceparent/baggage，在 Processor 中提取 trace_id/span_id；  采用 OTel PHP SDK（可选）向后端上报 Traces，与 Logs 通过共同字段实现互跳。常见坑与自检清单  时间戳/时区混乱；多行堆栈未结构化；  采集器与 logrotate 不匹配导致丢失；  生产误开 DEBUG/TRACE 导致成本暴涨；  在业务线程直连日志后端造成阻塞；  标签高基数（Loki/Prometheus 类系统致命）；  未做脱敏，泄露 PII/密钥；  无本地缓冲，网络抖动即丢；无 ILM/TTL 费用失控。迁移与落地步骤  盘点与分层：统一 Schema 与追踪字段，按服务/环境/吞吐/保留需求分层。  PoC：PLG/EFK/ClickHouse 各选一条链路做对比，回放历史日志估算成本与延迟。  渐进式上线：按业务域切流，灰度与采样并行，保留回滚通道。  治理与可视化：建立日志 SLO，Grafana/Kibana 看板与告警；  成本优化：ILM/TTL、热温冷分层、标签治理、对象存储归档。简要结论：统一 JSON Schema 与追踪上下文是基础；stdout（K8s）/文件或 journald（VM）为入口，Agent 端做脱敏与缓冲；强检索选 OpenSearch，性价比选 Loki/ClickHouse，高可靠加 Kafka；OTel 统一日志/链路/指标可显著提升排障效率；生产环境务必控制标签基数、采样与 ILM/TTL，并启用背压与本地缓冲。"
  },

  {
    "url": "/web3/2021/03/12/Web3-%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E5%BA%94%E7%94%A8DApps%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98.html",
    "title": "去中心化应用（DApps）架构实战：钱包、签名与读写分层",
    "content": "在 Web3 语境下，“应用”与传统 Web2 的差异并不只是是否使用区块链，而是信任模型从“平台背书”转向“代码即法律（Code is Law）”与“加密签名即授权”。DApp 的工程化落地，归根结底是围绕三件事：身份与授权（钱包）、状态与规则（智能合约）、读写与观测（RPC/索引器）。本文从体系结构到实战细节，带你搭建一个可上线的 DApp，并覆盖常见错误与运维要点。1. 架构概览与信任边界  前端（dApp）：运行在用户浏览器或移动端，负责连接钱包、发起签名、调用合约、渲染数据；  钱包（Provider/Signer）：保存私钥，EIP-1193 暴露统一接口，EVM 链上用 eth_* JSON-RPC；  合约（EVM Solidity）：在链上保存规则与资产，事件（logs）作为“事实来源”；  后端/索引器：尽量“最小信任”。使用 The Graph/SubQuery/自建 ETL，将事件抽取到可查询存储以供前端检索；  节点与网关：Infura/Alchemy/自建 Geth/Erigon；选择稳定 RPC 与指数退避策略；  可观测与告警：交易成功率、确认时间、事件延迟、钱包连接失败率、RPC 错误码分布。graph LR  UI[dApp Frontend] -- EIP-1193 --&gt; Wallet  Wallet -- sendTx/sign --&gt; Chain[Blockchain]  UI -- read --&gt; RPC  UI -- query --&gt; Indexer[(Indexer/DB)]  Chain -- logs --&gt; Indexer2. 钱包连接与权限模型（EIP-1193/6963）EIP-1193 统一了 Provider 的交互方式，EIP-6963 定义多钱包发现与选择机制。常见流程：1) 发现与连接钱包（请求账户权限）；2) 检查与切换网络；3) 监听账户/网络变化；4) 以签名/交易完成授权。// 探测 Provider（EIP-1193），兼容多钱包import { ethers } from 'ethers'const anyProvider = window.ethereumif (!anyProvider) throw new Error('No wallet provider found')// 请求账户权限（用户会看到弹窗）await anyProvider.request({ method: 'eth_requestAccounts' })const provider = new ethers.BrowserProvider(anyProvider)const signer = await provider.getSigner()console.log('address=', await signer.getAddress())// 监听账户/网络变化anyProvider.on('accountsChanged', (accs)=&gt;{ /* 刷新会话 */ })anyProvider.on('chainChanged', (chainId)=&gt;{ window.location.reload() })网络切换（EIP-3085/3326）：// 若链ID不匹配，引导用户添加并切换await anyProvider.request({  method: 'wallet_addEthereumChain',  params: [{ chainId: '0x1', chainName: 'Ethereum', rpcUrls: ['https://mainnet.infura.io/v3/xxx'], nativeCurrency: {name:'ETH',symbol:'ETH',decimals:18}}]})3. 合约设计与最小可行用例（Solidity）以“白名单凭证 NFT”举例：  功能：允许白名单地址铸造一次；  事件：Minted(address indexed to, uint256 tokenId)；  安全：只读视图函数 whitelisted(address)；  运维：合约版本标识与所有者（多签）。// SPDX-License-Identifier: MITpragma solidity ^0.8.20;import {ERC721} from \"solmate/tokens/ERC721.sol\";import {Owned} from \"solmate/auth/Owned.sol\";contract Voucher is ERC721, Owned {    mapping(address =&gt; bool) public used;    uint256 public nextId;    string public baseURI;    event Minted(address indexed to, uint256 indexed tokenId);    constructor(string memory _name, string memory _symbol, string memory _base) ERC721(_name,_symbol) Owned(msg.sender) {        baseURI = _base;    }    function tokenURI(uint256 id) public view override returns (string memory) {        return string(abi.encodePacked(baseURI, _toString(id), \".json\"));    }    function mint() external {        require(!used[msg.sender], \"used\");        used[msg.sender] = true;        uint256 id = ++nextId;        _safeMint(msg.sender, id);        emit Minted(msg.sender, id);    }}部署（Foundry）：forge create --rpc-url $RPC --private-key $PK src/Voucher.sol:Voucher \\  --constructor-args \"Voucher\" \"VCH\" \"ipfs://CID/\"4. 前端读写分层与索引器  写：调用 mint() 发起交易。需要 Nonce 管理（失败重发）、Gas 估算冗余（+10~20%）、提示用户确认。  读：合约状态（used(addr)、ownerOf）适合实时 RPC；批量列表（最近铸造）用索引器重放事件。// 写：mintconst voucher = new ethers.Contract(addr, abi, signer)const tx = await voucher.mint()const receipt = await tx.wait() // 等待确认，前端显示 Pending/Confirmed// 读：单点查询const used = await voucher.used(address)// 读：通过 subgraph/自建 indexer，// 例如请求 /api/minted?owner=0xabc 返回分页列表索引器方案：  The Graph：声明式子图，快；  自建 ETL：使用 ethers 订阅事件写入 PostgreSQL/ClickHouse，配合 REST/GraphQL 查询；  延迟与一致性：UI 上标注“最新区块高度”，避免用户对数据新鲜度的误解。5. 错误处理与用户体验  交易被用户拒绝：错误码 4001 → 友好提示；  Nonce 过低/冲突：后端给出“替换交易”指导；  Gas 估算失败：提供“手动输入”模式，并提示风险；  网络切换失败：指导手动添加 RPC，或降级到只读模式；  交易 Pending 过久：给出区块浏览器链接；  本地缓存：用 IndexedDB 缓存用户最近交互状态，提升体验。6. 安全清单  签名提示（EIP-4361 SIWE）明确用途，避免“盲签”；  前端不要保存私钥；  合约函数最小暴露，使用 reentrancy guard 与访问控制；  升级与多签：关键参数由多签修改，预留“暂停开关”；  依赖锁定：固定依赖版本，审计后再升级；  漏洞响应：准备紧急流程与白帽通道。7. 部署与运维  环境：Testnet（Sepolia/holesky）→ Mainnet/L2；  RPC：多供应商容灾（Infura/Alchemy/自建），退避+重试；  日志：合约事件/前端错误/链上回执三方对账；  指标：交易成功率、确认时间分布、钱包连接失败率、索引器延迟；  版本回滚：前端通过 CDN 回滚，合约通过“开关+迁移”方案；  风险演练：限流/拥塞/价格飙升场景压测。8. 典型问题与排查  交易总失败：检查链 ID、不足 Gas、Nonce 冲突、RPC 限流；  事件读取不全：索引器区块范围/重组处理、分片并行拉取；  钱包不兼容：提供 WalletConnect 与多 Provider 适配；  L2 差异：确认时间、手续费代币与跨链桥时延。9. 进阶：多链与账户抽象（AA）  多链：统一接口层（如 wagmi/viem），在 UI 与配置层做网络切换；  账户抽象（EIP-4337）：用 UserOperation 替代直接 sendTransaction，可实现“代付手续费”“批量操作”等体验优化。10. 小结一个可上线的 DApp，不只是一两个合约与一个页面，需要“端-链-索引-观测”的闭环设计。以钱包为入口、合约为规则源，辅以稳健的读写分层与索引器，是工程落地的通用路径。持续优化签名提示、错误处理与运维指标，才能支撑从爱好者到大众用户的跃迁。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/nginx/2020/09/22/Nginx-%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E4%B8%8E%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%E5%AE%9E%E8%B7%B5.html",
    "title": "Nginx 缓存策略与动静分离实践",
    "content": "CDN 前移与边缘缓存固然重要，源站 Nginx 的缓存与动静分离同样关键。本文给出缓存键、缓存层级与缓存失效策略。1. CDN 的概念与原理CDN（Content Delivery Network，内容分发网络）通过在全球各地部署边缘节点，将内容缓存并就近分发给用户，以缩短 RTT、降低回源压力和抖动。其核心机制包括：  路由调度：基于 Anycast、DNS 或 HTTP 重定向，将用户引导到就近/最优节点。  边缘缓存：边缘节点依据源站响应头（如 Cache-Control、Expires、ETag、Last-Modified、Vary、Surrogate-Control、s-maxage 等）决定存储与回源策略。  回源与验证：命中失败或过期后，边缘向源站回源；支持条件请求（If-None-Match/If-Modified-Since）。  失效与刷新：通过 API 触发 URL/PATH/Tag 维度的失效（Soft/Hard Purge），或自然到期。实践上，合理设计缓存层级（浏览器 → CDN 边缘/中间层 → 源站 Nginx）与一致的缓存语义，是稳定与性能的关键。2. 从 Nginx 反向代理角度：职责与作用Nginx 作为源站或中间层反向代理，承担：  协议终止：TLS 终止、HTTP/2/HTTP/3（QUIC），HSTS、安全头治理。  流量治理：限流、熔断、重试、健康检查、连接复用（keepalive）、负载均衡（轮询/一致性哈希）。  路由与动静分离：路径/主机名路由，将静态交给文件系统/对象存储，动态交给应用上游。  缓存与加速：proxy_cache/fastcgi_cache/uwsgi_cache 微缓存，削峰填谷（use_stale/background_update）。  可观测性：接入/上游日志、$upstream_cache_status、自定义头（如 X-Cache-Status）。3. Nginx 缓存原理与类型Nginx 缓存本质是以“缓存键 → 缓存对象（响应头+体）”的 KV 存储，命中由“键一致 + 仍在有效期 + 可用状态”决定。  缓存类型：          proxy_cache：反向代理上游（HTTP）      fastcgi_cache：PHP/FPM 等 FastCGI 应用      uwsgi_cache：uWSGI 协议上游        核心要素：          缓存键：常见构成为 scheme + method + host + uri + args + 关键头/变量，需谨慎纳入 Cookie/User-Agent/Accept-Language/Device 等差异维度，避免过度碎片化。      有效期：proxy_cache_valid（命中后 TTL），与上游头（Cache-Control/Expires）的关系可通过 proxy_ignore_headers、proxy_cache_revalidate on; 调整。      失效策略：自然过期、主动清理（ngx_cache_purge 或重新变更缓存键/版本位）。      抖动优化：proxy_cache_lock（合并并发 miss）、use_stale updating/error（错误/更新期间复用旧值）、proxy_cache_background_update（后台刷新）。      4. 缓存配置示例（微缓存 + 静态长缓存）http {  upstream api_upstream {    server 127.0.0.1:8080;    keepalive 64;  }  proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:256m inactive=1d max_size=20g use_temp_path=off;  # 登录/写操作等绕过缓存  map $http_cookie $bypass_cache_cookie { default 0; ~*(session|token|auth) 1; }  map $request_method $bypass_cache_method { default 0; ~^(POST|PUT|PATCH|DELETE)$ 1; }  map \"$bypass_cache_cookie$bypass_cache_method\" $bypass_cache { default 0; \"10\" 1; \"01\" 1; \"11\" 1; }  # 可选：版本位，灰度/全量刷新时提升为新版本（与 CDN Tag/Key 搭配）  # map $http_x_cache_version $cache_version { default \"v1\"; }  server {    listen 443 ssl http2;    server_name www.example.com;    # 与 CDN/前置代理配合的真实 IP 处理（将网段替换为实际 CDN 出口段）    # set_real_ip_from 203.0.113.0/24; real_ip_header X-Forwarded-For; real_ip_recursive on;    # API 微缓存：强削峰、弱一致（1s~3s 级别）    location /api/ {      proxy_pass http://api_upstream;      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;      proxy_set_header X-Forwarded-Proto $scheme;      proxy_cache api_cache;      proxy_cache_key \"$scheme$request_method$host$request_uri\"; # 可拼入 $cache_version 等变量      proxy_cache_lock on;                 # 合并并发 miss，避免狗群效应      proxy_cache_lock_timeout 5s;      proxy_cache_background_update on;    # 后台刷新      proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;      proxy_cache_valid 200 1s;            # 微缓存 TTL（示例）      proxy_cache_valid 301 302 10m;      proxy_cache_valid any 1m;            # 其他状态的保守缓存      proxy_no_cache $bypass_cache;        # 条件下不写入缓存      proxy_cache_bypass $bypass_cache;    # 条件下不读取缓存      add_header X-Cache-Status $upstream_cache_status always;    }    # HTML：短 TTL + s-maxage 交给 CDN，浏览器不持久缓存    location = /index.html {      etag on; if_modified_since exact;      expires -1;      add_header Cache-Control \"public, s-maxage=60, stale-while-revalidate=120, stale-if-error=86400\" always;      add_header Vary \"Accept-Encoding, Accept-Language\" always;      try_files $uri /index.html;    }  }  # 静态域（动静分离）：长缓存 + 指纹命名 + immutable  server {    listen 443 ssl http2;    server_name static.example.com;    root /var/www/static;    location / { try_files $uri =404; }    location ~* \\.(?:css|js|woff2?|ttf|otf|eot|svg|png|jpg|jpeg|gif|ico)$ {      access_log off;      expires 1y;      add_header Cache-Control \"public, max-age=31536000, immutable\" always;    }  }}5. 缓存删除与灰度刷新  源站侧：          ngx_cache_purge：对指定 URL/key 做强制清理（需相应模块/规则）。      版本位切换：将 $cache_version/路径前缀/资源指纹切换到新版本，实现“旧缓存自然淘汰，新缓存即时生效”。      use_stale updating + background_update：对热点内容采用平滑刷新。        CDN 侧：          Tag/Key/路径维度的 API 失效（尽量 Soft Purge + stale-while-revalidate，避免缓存雪崩）。      对 HTML/聚合页先 Soft 后 Hard，控制潮汐效应。      6. CDN 与 Nginx 的协同（通信与对齐）  缓存语义：          浏览器用 max-age/immutable，CDN 用 s-maxage/Surrogate-Control，两者各司其职。      条件请求：启用 ETag/Last-Modified，允许 CDN 及 Nginx 复用 304 验证，减少字节回源。      Vary 对齐：与实际差异维度一致，避免误合并或碎片化；慎用 Vary: Cookie（更推荐在 CDN 端剥离无关 Cookie）。        连接/身份：          透传链路：X-Forwarded-For、X-Forwarded-Proto，并在源站恢复真实 IP（set_real_ip_from）。      观测头：统一 X-Cache（CDN）、X-Origin-Cache（Nginx）等便于排障。        回源与削峰：          CDN 打开 Collapsed Forwarding/Origin Shield；Nginx 打开 proxy_cache_lock/use_stale，双层合并并发 miss。      7. 动静分离最佳实践  域名分离：www.example.com（动态/HTML 短缓存）与 static.example.com（静态资源长缓存）分域，便于策略与权限隔离。  指纹命名：静态资产使用内容哈希（如 app.&lt;hash&gt;.js），配合 Cache-Control: immutable 与 1 年 TTL。  HTML/接口：          HTML 由 CDN 短 TTL + stale-while-revalidate，源站可微缓存 1s~3s 抗尖峰。      API GET 可微缓存；写操作/登录态通过 Cookie/Method 映射绕过缓存。        资源下沉：将图片/视频等大文件迁移至对象存储 + CDN 边缘，Nginx 只做签名鉴权与 302 跳转（或代理带范围请求）。  压缩与协议：开启 brotli/gzip（二选一优先 brotli），启用 HTTP/2/3，合理的 TLS 会话复用与 OCSP Stapling。8. 注意事项（坑点清单）  语义不一致：源站与 CDN 的 Cache-Control 冲突，导致双层缓存不可控；确保 s-maxage 与 max-age 区分清晰。  过度 Vary：将 Cookie、User-Agent 直接纳入键导致碎片化；优先在 CDN 端规整头部/剥离无关 Cookie。  个性化内容被缓存：涉及用户态/地域/AB 实验的页面需加 private, no-store 或显式绕过。  重复压缩：CDN 与源站同开 gzip/brotli 可能叠加问题；只保留一处压缩（通常边缘）。  清缓存风暴：大规模 Hard Purge 触发回源雪崩；优先 Soft + stale-while-revalidate，并打开合并回源。  Range 与视频：确认 CDN 与源站均支持 Range；Nginx 需 aio on; directio 等以优化大文件。  真 IP 获取：补全 CDN 出口网段至 set_real_ip_from，否则访问日志皆为边缘 IP。9. 排错清单（最小化工具）  响应头核对：curl -I https://www.example.com/ | sed -n '1,200p'，检查 Cache-Control、Age、ETag、Vary、X-Cache、X-Cache-Status。  分层命中：分别查看 CDN 命中（X-Cache: HIT）与 Nginx 命中（X-Cache-Status: HIT）。  条件请求：If-None-Match/If-Modified-Since 是否 304；如无 ETag，考虑在 HTML/静态启用 etag on;。  键确认：临时把 proxy_cache_key 响应回显到头部以核对（调试时用，勿在生产保留）。10. 小结合理的“浏览器 → CDN → 源站 Nginx”三层缓存设计，配合动静分离与微缓存，可同时获得低时延、高吞吐与稳定性。关键在于：一致的缓存语义、谨慎的缓存键设计、可控的失效策略，以及双层削峰机制的配合。"
  },

  {
    "url": "/web3/2020/08/19/Web3-%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%E4%B8%8E%E6%A0%88.html",
    "title": "Web3 的链上基础：共识、状态机与扩容栈",
    "content": "区块链是“可验证状态机复制”（Replicated State Machine）。要把 DApp 做稳，必须理解状态如何被转换、共识如何达成、数据如何被持久化与对外可读。本文从状态机、共识、存储与扩容（L2/DA）出发，构建一条可实践的技术路径，并附带节点与索引的工程建议。1. 状态机与区块  交易（Tx）是对状态的变更请求；  区块是时间窗口内的交易集合；  状态机：state_{n+1} = transition(state_n, block_txs)，其中 transition 由虚拟机（EVM/WASM）与合约逻辑决定；  真实性：通过 Merkle/Patricia Trie/Verkle commitment，为状态/交易/收据生成可校验根。2. 共识算法与容错  PoW：算力竞争，安全性来源于经济成本与难度调节；  PoS：权益质押 + 随机选举/委员会 BFT；  BFT 家族（Tendermint/HotStuff）：低延迟、确定性最终性，容忍 f 个拜占庭节点需总数 ≥ 3f+1；  最终性（Finality）：概率型（PoW） vs. 确定性（BFT/PoS 的检查点最终性）；  安全-去中心化-性能“铁三角”权衡。3. 存储与索引  账户/存储：以太坊账户模型、合约存储槽；  索引：事件（logs）作为可订阅变更源；  历史访问：归档节点（Erigon）与快照；  自建索引：消息队列 + ETL（ClickHouse/PostgreSQL），支持分页、聚合与时间序列；  校对：按区块高度对账，处理链重组（reorg）。4. 扩容：Layer2 与数据可用性（DA）  Rollup：Optimistic（欺诈证明）与 ZK（有效性证明）；  Validium：链下数据可用性，吞吐更高但信任更强；  DA 层：Celestia/EigenDA 作为数据发布层，L2 提交证明到 L1；  桥接安全：原生桥/轻客户端桥/流动性桥的风险比较。5. 读写路径与最终一致  写：tx -&gt; mempool -&gt; proposer -&gt; block -&gt; consensus；  读：RPC（视图函数） + 索引器（事件订阅）；  一致性：UI 上呈现“确认数/最终性状态”，避免用户误解；  重组处理：短暂回滚时，索引器需要撤销并重放受影响区块。6. 节点与网络  客户端：Geth/Nethermind/Erigon；  RPC 网关：Infura/Alchemy/self-hosted Nginx 负载；  P2P：节点发现、区块/交易传播；  指标与日志：区块延迟、孤块率、重组率、peer 数量；  安全：私钥隔离、远程签名（HSM/Signer）。7. 工程与运维建议  多供应商 RPC 容灾，指数退避与幂等机制；  节点同步：快速同步/快照/检查点；  资源：IO/CPU/网络的均衡，SSD 与队列深度；  压测：fork 主网、回放真实负载；  成本：根据读写比例选择 L2/缓存/索引器策略。8. 代码与命令片段  使用 ethers.js 订阅事件并写入数据库：    const provider = new ethers.JsonRpcProvider(RPC)const iface = new ethers.Interface(abi)provider.on({ address: CONTRACT, topics: [iface.getEventTopic('Transfer')] }, (log)=&gt;{const evt = iface.decodeEventLog('Transfer', log.data, log.topics)// 写入数据库，带 blockNumber/txHash，便于去重与回滚})        Geth 启动与快照：    geth --http --http.api eth,net,web3 --syncmode snap --datadir /data/geth        Erigon 归档节点（示）：    erigon --chain mainnet --http --http.api=eth,debug,net,web3 --datadir /data/erigon      9. 小结链上是“慢且稳”的全局真相，链下是“快且灵活”的读取与分析。将状态转换、共识与数据可用性理解清楚，配合合理的索引与缓存，才能在可用性与可信度之间取得平衡。选择成熟 L1 + 合适 L2，减少自研链的复杂性，是当下工程落地的主路径。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/mysql/2020/07/19/MySQL-%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%9B%9E%E8%A1%A8%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html",
    "title": "MySQL 索引设计与回表优化实战",
    "content": "索引，是 MySQL 性能工程的地基。设计得当，查询如行云流水；设计不当，慢查询、锁等待、CPU 飙高全都找上门。本文在原“回表优化实战”的基础上，系统扩展到索引必要性、InnoDB B+ 树底层原理、索引大小对性能的影响、工程化建索引方法论与排障清单，给出一套可直接落地的完整方案。1. 为什么需要索引：必要性与代价的平衡没有索引时，只能全表扫描，I/O 与 CPU 成本随数据量线性增长。索引将“查找”从 O(N) 降为 O(log_f N)，其中 f 为 B+ 树扇出（可达数百至上千），并提供有序访问能力，显著优化范围扫描、排序与分组。同时必须正视代价：  写放大：DML 需要维护主键与二级索引，伴随页分裂/合并；  存储膨胀：索引页占用 Buffer Pool，命中率受影响；  计划风险：索引过多/质量差会让优化器选择困难，出现计划抖动。结论：索引不是越多越好，而是“必要且刚好”。2. 底层原理：为什么是 B+ 树？InnoDB 采用 B+ 树组织数据与索引（聚簇索引与二级索引），核心动机：  磁盘/页友好：节点存大量键指针，扇出大、树高低（亿级数据常 3~4 层）；  顺序扫描：叶子节点双向链表，天然支持范围/排序；  缓存友好：热路径节点易命中 Buffer Pool；  对比哈希/红黑树：B+ 树既支持范围/排序，又以页为单位贴合块设备。两个关键事实：  聚簇索引叶子存整行，主键既是逻辑主键也是物理组织；  二级索引叶子为“索引键 + 主键”，因此二级索引命中后常需“回表”。这解释了覆盖索引为何能避免回表：当查询列全被索引覆盖时，无需回到聚簇索引取整行。3. 索引大小如何影响性能1) 树高与扇出：键越短、记录越小，扇出越大、树高越低；树高每 +1，未命中缓存时多一次随机 I/O，P95/99 延迟明显上升。2) 缓存命中与热点：索引越小，更多页常驻 Buffer Pool，随机 I/O 更少；大索引会稀释缓存，导致更频繁的落盘访问。3) 写放大与碎片：宽主键（如 UUID v4 文本）插入随机，页分裂与碎片更多；宽二级索引（长字符串/多列组合）放大维护成本。工程启示：  控制主键宽度，倾向递增或准递增（BIGINT 雪花、UUID v7/Binary(16)）；  长字符串用前缀索引或生成列（表达式持久化/CRC32）缩小叶子记录；  复合索引列顺序以短且高选择度列在前，降低树高。4. 设计方法论：如何系统化建索引4.1 读路径画像与选择度把 80% 关键查询归类为：点查、范围、排序、分组、Top-N、Join。逐条识别过滤列、排序/分组列、返回列与基数（选择度）。4.2 等值-范围-排序的列序复合索引常见顺序：等值列 → 范围列 → 排序/分组列。-- 典型 OLTP 列表页CREATE INDEX idx_u_s_ctid ON orders(user_id, status, created_at, id);-- WHERE user_id=? AND status=? AND created_at BETWEEN ... ORDER BY id LIMIT N注意：范围列之后的排序是否生效，取决于范围收敛与索引序可用性，否则仍可能 filesort。4.3 覆盖索引优先，尽量避免回表将 SELECT 所需列合入索引尾部，形成覆盖（Extra: Using index）。  列表页热点读优先覆盖；  谨慎控制索引宽度，避免为覆盖无限扩列；  搭配 LIMIT 收敛候选集。4.4 索引下推（ICP）与条件重写MySQL 5.6+ 支持 Index Condition Pushdown，在索引层预过滤，减少回表。  避免在索引列上包裹函数/隐式类型转换；  用生成列持久化表达式并建函数索引：ALTER TABLE t  ADD COLUMN created_date DATE GENERATED ALWAYS AS (DATE(created_at)) STORED,  ADD INDEX idx_created_date(created_date);4.5 低选择度列的处理将低选择度枚举（性别/状态）与高选择度列（租户/用户/时间）复合，提升过滤效率。4.6 排序/分组利用索引序  让 ORDER BY 列与 WHERE 等值列共用一个索引，避免外部排序；  GROUP BY 尝试松散索引扫描（loose index scan），在可跳跃场景显著降低代价。4.7 JOIN 场景  驱动表选高过滤性；  被驱动表在 Join key 建索引，保证 Nested Loop 点查高效；  Join + Order 时，考虑“Join key + 排序列”复合。4.8 反模式速查  LIKE '%kw%' 不走前缀索引：考虑反向索引、ngram、全文索引；  表达式在列外：WHERE DATE(ts)=...、col+1=... 阻断索引；  隐式转换：字符串列与数值比较触发转换，索引失效；  8.0 混合排序：按需指定 ASC/DESC，避免额外排序。5. 回表优化：理解并减少回表代价在于额外随机 I/O 与潜在锁冲突。1) 覆盖索引优先：尽可能避免回表。2) 限制回表次数：  提升过滤收敛；  ICP 在索引层筛除不匹配；  Top-N 列表减少 LIMIT，利用更强 WHERE。3) 利用主键有序性：  让二级索引输出的主键更“聚集”（时间段/自增 ID），减少跨页跳转；  使用 seek 分页替代深 OFFSET，避免无效回表。-- 基于主键的延续分页SELECT cols FROM t FORCE INDEX(idx_a_created_id)WHERE a=? AND (created_at,id) &gt; (?,?)ORDER BY created_at,idLIMIT 50;4) 特殊手段：  热点路径物化/汇总表，用写放大换读性能；  使用外部缓存兜热点主键查；  JSON/表达式查询用生成列 + 函数索引减少“索引参与度低”的回表。6. 主键设计：影响一切的根基  宽度：尽量短（BIGINT 优于 UUID v4 文本）；必要时用 BINARY(16) 或 UUID v7；  递增性：递增/准递增减少页分裂、提升局部性；  业务含义：避免在主键编码复杂业务语义，后期变更代价高。7. 统计与优化器：让选择更聪明  ANALYZE TABLE 刷新统计，保证基数估计；  8.0 直方图（CREATE HISTOGRAM）改善倾斜分布估计；  持久统计（innodb_stats_persistent=ON）减少重启抖动；  不可见索引（Invisible Index）灰度验证，新索引先不可见，验证后再切换可见。CREATE INDEX idx_demo ON t(col1,col2) INVISIBLE;ALTER TABLE t ALTER INDEX idx_demo VISIBLE;8. 实战建索引流程（可执行清单）1) 收集与分群：  慢日志、Top SQL（performance_schema / sys）；  按 DIGEST 聚类，统计 QPS、P95/P99、Rows Examined。2) 设计与评审：  为每类查询提出 1~2 个候选复合索引；  检查“等值→范围→排序/分组”、是否可覆盖；  评估索引宽度、写放大、与现有索引冗余关系。3) 预演与验证：  影子环境回放真实流量；  用 EXPLAIN ANALYZE 对比访问类型、rows/filtered、Extra；  评估 CPU/I-O/延迟改善与副作用。4) 渐进上线：  不可见索引或分批实例灰度；  观察计划回归、锁等待、写延迟；  冗余索引及时下线，保持索引集简洁。9. DDL 模板与技巧-- 1) 复合 + 覆盖：等值-范围-排序CREATE INDEX idx_a_b_c_id ON t(a, b, c, id);-- 2) 前缀索引：控制宽列大小（留意选择度与碰撞）CREATE INDEX idx_email_prefix ON users(email(16));-- 3) 生成列 + 函数索引：避免表达式阻断索引ALTER TABLE users  ADD COLUMN email_lc VARCHAR(255) GENERATED ALWAYS AS (LOWER(email)) STORED,  ADD INDEX idx_email_lc(email_lc);-- 4) 混合排序（8.0+）：与业务排序一致CREATE INDEX idx_city_score ON shop(city_id ASC, score DESC, id ASC);-- 5) JSON 多值索引（8.0.17+）ALTER TABLE doc ADD INDEX idx_tags(tags) COMMENT 'MVI on JSON array';-- WHERE JSON_CONTAINS(tags, '\"ai\"', '$')-- 6) 不可见索引灰度CREATE INDEX idx_hot ON t(a,b,c) INVISIBLE;ALTER TABLE t ALTER INDEX idx_hot VISIBLE;10. 监控与排障：发现“坏索引/缺索引”  慢日志：Rows_examined 远大于返回行；  performance_schema/sys：按 DIGEST 聚合最高延迟/扫描行；  EXPLAIN ANALYZE 指标：          type=ALL：全表扫；      key=NULL：未命中索引；      rows ≫ 返回行：回表/过滤浪费；      Extra 含 Using filesort/Using temporary：排序/分组未利用索引序；        InnoDB：Buffer Pool 命中率、页分裂率、history list length（长事务影响 purge 与统计）。11. 常见问答与取舍  外键列要不要建索引？建议要。否则外键检查/级联会加大锁范围与阻塞。  INDEX MERGE 能替代复合索引吗？不建议依赖。常需临时合并，CPU 与内存代价高。  宽文本如何索引？前缀 + 覆盖或生成列，全文检索需求引入专用引擎更合适。  是否删除“看似无用”的索引？先做不可见灰度并跨报表/离线窗口观察，避免尖峰慢查。12. 经典案例回顾（结合回表优化）问题：SELECT id FROM t WHERE a = ? AND b &gt; ? ORDER BY c LIMIT 20 filesort + 回表严重。方案：CREATE INDEX idx_a_b_c_id ON t(a, b, c, id);EXPLAIN SELECT id FROM t WHERE a = 1 AND b &gt; 10 ORDER BY c LIMIT 20; -- Extra: Using index要点：  等值 a 在前、范围 b 其后、排序 c 与主键 id 形成覆盖；  若范围过宽导致排序失效，缩小 b 的范围或改以 (a,c,id) 兜底并增加 WHERE 收敛；  LIMIT 收敛候选集，减少回表数量。13. SQL 排查脚本（保留与扩展）-- Top 慢 SQL 家族SELECT * FROM performance_schema.events_statements_summary_by_digest WHERE DIGEST_TEXT LIKE 'SELECT%FROM t%'ORDER BY AVG_TIMER_WAIT DESC LIMIT 20;14. 总结：可落地的准则  以查询为中心：有读路径画像，后有索引方案；  等值→范围→排序/分组组织复合索引，热点读优先覆盖；  控制索引大小：短主键、前缀/生成列、谨慎扩列；  减少回表：覆盖索引 + ICP + seek 分页；  喂饱优化器：直方图、持久统计、定期 ANALYZE；  灰度为先：不可见索引/影子环境验证；  持续治理：监控—评审—精简的闭环。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/java/2019/12/14/Java-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%B0%83%E4%BC%98-%E4%BB%8EG1%E5%88%B0ZGC.html",
    "title": "Java 垃圾回收调优：从 G1 到 ZGC",
    "content": "延迟敏感系统如何选择 GC？如何系统地读懂 GC 日志并做出有效调优？本文从 JVM 基础、STW 机制、垃圾回收算法、收集器演进到实战调优，给出可落地的方法与示例。1. JVM 内存模型与 STW/Safepoint 基础在 HotSpot 下，内存大体分为：  Java 堆（年轻代/老年代，G1/ZGC 采用 Region/分页结构）  线程栈（每线程独立）  元空间（Metaspace，用于类元数据）  本地内存（如直接缓冲区、JIT 代码缓存等）两个重要的分配/复制概念：  TLAB（Thread-Local Allocation Buffer）：线程本地的堆分配缓冲，减少分配锁竞争。  PLAB（Parallel/Promotion LAB）：年轻代向老年代晋升时的并行复制缓冲。Stop-The-World（STW）是 GC 暂停所有 Java 线程的时刻。JVM 通过 Safepoint 实现可停位置控制（比如方法调用边界、循环回边、异常处理器等），在进入关键阶段（如初始标记、重新标记、对象移动/重定位）时触发短暂停顿。理解 STW 有助于判断“为什么延迟尖刺发生在这个阶段”。观测 STW 的现代方式（JDK9+）：java -Xlog:safepoint,classhisto*=off:file=safepoints.log:tags,uptime -Xlog:gc*:file=gc.log:time,uptime,level,tags ...关键指标：暂停时长（p95/p99/p999）、分配速率、晋升速率、RSet 扫描成本、引用处理（Reference Processing）、类卸载、字符串去重等耗时分布。2. 垃圾回收算法与屏障技术HotSpot 基础算法与实现要点：  可达性分析：从 GC Roots（线程栈、静态引用、JNI 句柄等）做遍历。  三色标记（白/灰/黑）+ 写屏障/读屏障：保证并发标记/移动时的正确性。  标记-清除（Mark-Sweep）：快，但会产生碎片。  标记-整理（Mark-Compact）：消除碎片，但需要对象移动（常伴随 STW 或并发移动）。  复制（Copying）：典型用于年轻代（Eden→Survivor），快且局部性好。  分代假说：大多数对象“朝生夕死”，少数对象“越活越老”。引用语义（强/软/弱/虚）与终结（finalize/Cleaner）在 GC 中有独立处理阶段。引用处理过重时常见“长尾暂停”，建议：避免 Finalizer、使用 java.lang.ref.Cleaner 并限制队列堆积。3. 收集器演进路线  Serial/Parallel（Throughput 收集器）          关注吞吐，允许较长 STW；适合批处理、计算密集型、少交互的服务。      关键项：-XX:+UseParallelGC、-XX:ParallelGCThreads、-XX:NewRatio。        CMS（Concurrent Mark Sweep）          并发标记，降低暂停，但有碎片与“Concurrent Mode Failure”。      JDK9 起废弃，JDK14 移除。仅在历史系统中遇到，不建议新项目使用。        G1（Garbage-First）          基于 Region 的分代收集器。分为 Young、Concurrent Marking、Mixed 周期，按收益选择回收集（Collections Set）。      关键概念：Region（含 Humongous 大对象）、RSet/卡表（Remembered Set）、IHOP（Initiating Heap Occupancy Percent）。      优点：更可预测的暂停目标；可并发标记与分阶段回收。      常见瓶颈：RSet 扫描（卡表爆炸）、Humongous 对象回收不及时、Evacuation Failure（to-space/exhausted）。        Shenandoah（Red Hat）与 ZGC（Oracle）          共同目标：并发压缩/移动，极低暂停（亚毫秒到个位数毫秒级）。      屏障差异：Shenandoah 使用 Brooks Pointer + 写屏障；ZGC 使用“有色指针（Colored Pointers）”+ 读屏障，配合多阶段重标记/重定位。      ZGC 建议 JDK17+，JDK21 起支持分代 ZGC（-XX:+ZGenerational）。      4. 选择收集器的思路  吞吐优先（批处理/离线计算）：Parallel GC。  延迟优先（在线服务/交易系统）：G1（JDK11+），更高要求可选 ZGC（JDK17+/21+）。  小堆（&lt;4G）且并发不高：G1 也能给出稳定暂停；ZGC 在极小堆下优势不明显。5. 调优方法论（可落地流程）1) 设定 SLO：如 p99 暂停 &lt; 200ms，或 CPU/吞吐目标。2) 固定运行基线：容器/宿主 CPU/NUMA/THP 设置、JDK 版本、-Xms = -Xmx、-XX:+AlwaysPreTouch。3) 打开观测：GC/JFR/应用指标。java \\  -Xms8g -Xmx8g -XX:+AlwaysPreTouch \\  -Xlog:gc*,safepoint:file=gc.log:time,uptime,level,tags \\  -XX:ActiveProcessorCount=8   # 容器 CPU 配额感知（必要时）4) 建立压测基线：记录分配速率（Allocation Rate）、晋升速率（Promotion Rate）、混合回收频次、Humongous 分配率、RSet 扫描耗时。5) 定位瓶颈：  暂停超标多数发生在 Initial-Mark/Remark？→ 检查引用处理/类卸载/卡表维护。  Mixed 过于频繁？→ IHOP 偏低或老年代增长过快。  Evacuation Failure？→ to-space 不足，Region 预留或对象过大。6) 逐步调整参数与代码，单一变量、对比压测，保留实验记录。6. G1 实战参数与解释常用启动模板（JDK11+/17+）：java \\  -XX:+UseG1GC \\  -Xms8g -Xmx8g \\  -XX:MaxGCPauseMillis=200 \\  -XX:InitiatingHeapOccupancyPercent=45 \\  -XX:G1ReservePercent=20 \\  -XX:G1HeapRegionSize=4m \\  -XX:G1NewSizePercent=20 -XX:G1MaxNewSizePercent=40 \\  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=8 \\  -XX:+ParallelRefProcEnabled \\  -XX:+UseStringDeduplication \\  -Xlog:gc*,gc+heap=debug,gc+age=trace:file=gc.log:time,uptime,level,tags调参要点：  MaxGCPauseMillis：目标暂停时间。过低会引发更频繁 GC 与更重的并发负担。  IHOP：老年代占用触发并发标记阈值。负载有爆发时可调高（如 45→55），减少并发标记重叠时间。  G1ReservePercent：预留 to-space，减少 Evacuation Failure 风险。  G1HeapRegionSize：Region 大小影响 Humongous 阈值（&gt; 50% Region 即为 Humongous）。对象略大时可适当增大 Region，减少 Humongous 分配。  新生代比例与晋升阈值：平衡吞吐与老年代压力，避免 Survivor 放不下导致早晋升。常见告警与应对：  Mixed 过密：上调 IHOP、降低 G1MixedGCLiveThresholdPercent、限制 G1MixedGCCountTarget。  Evacuation Failure（to-space exhausted）：增大堆/预留比例、减少大对象、错峰分配高峰。  RSet 过大：排查跨区大量写入热点（缓存结构、共享对象），优化对象图或拆分。7. ZGC 实战参数与解释（JDK17+/21+）java \\  -XX:+UseZGC \\  -Xms8g -Xmx8g \\  -XX:ConcGCThreads=2 \\  -XX:ZUncommitDelay=300 \\  -Xlog:gc*,safepoint:file=gc.log:time,uptime,level,tags要点：  ZGC 通过读屏障与有色指针实现并发移动，对暂停极其敏感的在线业务非常友好。  内存回收的“拆借/归还”速度与分配速率密切相关。ZUncommitDelay 可控制未使用页面的回退时机。  JDK21+: -XX:+ZGenerational 以降低短命对象对并发标记的干扰（分代 ZGC）。何时不必用 ZGC：小堆、高分配峰值但暂停目标在百毫秒级时，G1 往往足够且更易调参。8. GC 日志快速解读示例（G1）[3.456s][info][gc,start     ] GC(12) Pause Young (Normal) (G1 Evacuation Pause)[3.456s][info][gc,heap      ] GC(12) Eden regions: 24-&gt;0(20)[3.456s][info][gc,heap      ] GC(12) Survivor regions: 3-&gt;4[3.456s][info][gc,heap      ] GC(12) Old regions: 120-&gt;123[3.460s][info][gc,phases    ] GC(12) Evacuate Collection Set: 3.2ms[3.462s][info][gc           ] GC(12) Pause Young (Normal) (G1 Evacuation Pause) 512M-&gt;498M(8G) 6.1ms关注点：  暂停类型（Young/Mixed）、暂停时长、堆前后使用、Region 变化。  Evacuation 耗时是否成为主因；Old 增长是否过快（晋升压力）。更多细节可打开 gc+age=trace 观察对象年龄分布，辅助设置 MaxTenuringThreshold。9. 代码层面的可操作优化  降低短命对象创建：复用 StringBuilder/ByteArrayOutputStream、批量处理、避免无谓装箱/拆箱与流式中间对象。  控制大对象：避免一次性构造超大 byte[]/String，对网络/IO 使用分片与缓冲；必要时改用直接内存并限制 -XX:MaxDirectMemorySize。  减少跨代/跨区写入：将热点可变状态下沉到局部，避免共享大图结构被频繁修改导致卡表膨胀。  善用 ThreadLocal 存放临时缓冲（谨防线程池泄漏，务必清理）。  让逃逸分析生效：内联/标量替换通常受益于“简单可分析”的代码路径（避免过度反射、动态代理链）。10. 两个简短实战案例  案例 A：在线 API（G1，8C/16G）          目标：p99 暂停 &lt; 200ms；现状：Mixed 频繁、p99 380ms。      调整：IHOP 45→55，G1ReservePercent 10→20，限制 Humongous（将 2.5MiB 的 JSON 拼接拆分为流式写出）。      结果：Mixed 降 35%，p99 降至 160ms。        案例 B：低延迟撮合（ZGC，16C/32G）          目标：单次暂停 &lt; 10ms；现状：G1 在 Remark 尖刺 30ms。      迁移 ZGC 并控制直接内存峰值，JDK17→21 开启 -XX:+ZGenerational。      结果：暂停 p99 约 1.2ms，尖刺消失；同时注意到读屏障开销，CPU 略增 4%。      11. 生产部署与容器注意事项  固定堆并预触达：-Xms = -Xmx、-XX:+AlwaysPreTouch，减少缺页与首次触达抖动。  容器配额：JDK8u191+ 或 JDK10+ 对 cgroup 友好；必要时 -XX:ActiveProcessorCount 显式指定。JDK8 老版本需 -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap。  关闭透明大页（THP）、合理设置 NUMA（大型物理机）。  日志与剖析：GC 日志、JFR（-XX:StartFlightRecording=...）、async-profiler 定位分配热点。12. 快速“配方卡”  吞吐优先：          -XX:+UseParallelGC -Xms16g -Xmx16g -XX:ParallelGCThreads=&lt;cpu&gt;        稳定低延迟（通用在线服务）：          -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:InitiatingHeapOccupancyPercent=45 -XX:G1ReservePercent=20        极低暂停：          -XX:+UseZGC [-XX:+ZGenerational] -Xms/-Xmx 固定      13. 参考命令与工具# 统一 GC 日志（JDK9+）java -Xlog:gc*,gc+heap=debug,gc+age=trace:file=gc.log:time,uptime,level,tags ...# 在线触发与诊断jcmd &lt;pid&gt; GC.runjcmd &lt;pid&gt; GC.heap_infojcmd &lt;pid&gt; VM.uptime# 快速观测分配/晋升（JDK8 仍常用）jstat -gcutil &lt;pid&gt; 1000 20 | cat如果要把一件事做对：先测量，再改变。GC 调优亦然。优先明确 SLO 与约束，打开观测，建立基线，然后用一两条假设驱动的改动去验证。让数据告诉你应该选 Parallel、G1 还是 ZGC。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/mysql/2019/08/02/MySQL-Online-DDL%E6%9C%BA%E5%88%B6%E5%AF%BC%E8%87%B4Duplicate-entry%E9%94%99%E8%AF%AF.html",
    "title": "MySQL Online DDL机制导致",
    "content": "MySQL Online DDL机制导致”Duplicate entry”错误的分析问题场景精准定位您描述的场景非常典型：  手机号字段早已存在唯一索引  原表中该手机号记录早已存在（”很早以前就存在数据库中”）  应用程序正确使用INSERT ... ON DUPLICATE KEY UPDATE  问题发生在执行非唯一索引相关的DDL操作时（如修改其他字段）这正是阿里云文档中提到的第三种场景：”使用结构设计功能进行不涉及唯一约束或唯一索引组成字段调整的DDL操作”时出现的冲突。核心问题：Online DDL的row log重放机制1. MySQL Online DDL执行流程（关键阶段）当执行一个不涉及唯一索引的DDL操作（如修改其他字段）时，MySQL的Online DDL流程如下：T0: 开始DDL，创建中间表(#sql-ibxxx)T1: 将原表数据复制到中间表（此时中间表已包含phone='xxxxx'）T2: 开始记录DML变更到row logT3: 应用程序执行INSERT ... ON DUPLICATE KEY UPDATET4: 将row log中的变更应用到中间表T5: 原子替换原表与中间表2. 问题发生的精确技术原因关键点：row log记录的是原始SQL操作，而非实际执行的操作当应用程序执行：INSERT INTO users(phone, name) VALUES('xxxxx', '张三') ON DUPLICATE KEY UPDATE name = '张三';MySQL的处理流程：  检测到唯一键冲突（phone=’xxxxx’已存在）  将INSERT操作内部转换为UPDATE操作  执行UPDATE，成功完成但是，在Online DDL过程中：  MySQL的row log只记录原始SQL语句（INSERT…）  不记录MySQL内部将其转换为UPDATE的事实  当重放row log到中间表时，MySQL会直接执行原始的INSERT语句3. 冲突发生的具体时间线T0: 开始DDL，创建中间表T1: 中间表从原表复制数据（已包含phone='xxxxx'）T2: 开始记录row logT3: 应用程序执行INSERT ... ON DUPLICATE KEY UPDATE    - 原表：检测到冲突，自动转为UPDATE，成功    - row log记录：INSERT INTO ... VALUES('xxxxx', ...)T4: DDL尝试将row log应用到中间表    - 中间表：已从T1复制拥有phone='xxxxx'的记录    - 执行INSERT操作 → 触发Duplicate entry错误T5: DDL操作失败为什么INSERT … ON DUPLICATE KEY UPDATE在这种场景下失效？1. 执行环境差异            环境      处理方式      结果                  正常执行环境      MySQL解析并执行完整SQL，识别ON DUPLICATE子句      INSERT转为UPDATE，无错误              Online DDL row log重放      仅执行row log中记录的原始INSERT语句      直接尝试插入，忽略ON DUPLICATE逻辑      2. 技术本质：row log的局限性MySQL的row log机制设计用于高效记录和重放DML操作，但有重要限制：  只记录物理操作，不记录SQL语义  不保存执行上下文（如唯一键检查结果）  不考虑约束触发的隐式操作转换当MySQL执行INSERT ... ON DUPLICATE KEY UPDATE时，这是一个逻辑操作，会被转换为物理操作（UPDATE）。但row log只记录了最初的逻辑操作（INSERT），没有记录最终的物理操作（UPDATE）。3. 中间表状态与原表状态的差异在T1到T4期间，原表和中间表的状态可能不同步：  原表：通过ON DUPLICATE KEY机制成功处理了冲突  中间表：没有机会执行相同的逻辑转换  当直接应用原始INSERT时，中间表严格检查唯一约束，导致失败MySQL底层源码级分析在MySQL源码中，这一问题的根源在于：  sql/ha_innobase.cc中的row_log_apply函数：          处理row log重放时，直接执行记录的原始操作      不会重新解析SQL或应用任何约束转换逻辑        sql/sql_insert.cc中的mysql_insert函数：          在正常执行路径中，会调用handle_duplicates处理唯一键冲突      但在row log重放路径中，绕过了这一逻辑        row/row0log.cc中的row log机制：          仅记录最基础的行变更（INSERT/UPDATE/DELETE）      不记录高级SQL语句的语义信息      为什么高并发会加剧这个问题？  row log积压：高并发下，T1到T4之间会产生大量DML操作，row log变大  状态差异扩大：原表与中间表的状态差异随时间推移而增大  重放复杂度增加：更多操作需要重放，冲突概率呈指数级增长解决方案的技术本质1. 根本原因  MySQL Online DDL的row log机制无法正确处理ON DUPLICATE KEY语句  row log记录的是原始SQL，而非实际执行的物理操作2. 有效解决方案方案A：避免在业务高峰期执行DDL  选择低峰期执行DDL操作，减少row log积压  降低原表与中间表状态差异方案B：使用LOCK=EXCLUSIVEALTER TABLE users MODIFY COLUMN age INT COMMENT '年龄' LOCK=EXCLUSIVE;  完全阻塞DML操作，确保数据一致性  代价：DDL执行期间表不可写方案C：分阶段执行（最佳实践）  先添加新列（不修改原列）  应用程序双写新旧列  数据迁移完成后，再删除旧列          避免长时间Online DDL操作      减少冲突窗口期      3. 为什么”先查询再插入”无效？即使应用程序改为：SELECT * FROM users WHERE phone='xxxxx';-- 如果存在则UPDATE，否则INSERT在Online DDL期间：  SELECT可能在T1前执行，看到记录存在  但INSERT/UPDATE操作在T2后执行  row log重放时仍会尝试插入已存在的记录结论      技术本质：MySQL Online DDL的row log机制无法正确处理INSERT ... ON DUPLICATE KEY UPDATE语句，因为它只记录原始INSERT语句，不记录MySQL内部将其转换为UPDATE的事实。        问题根源：当row log中的原始INSERT语句被应用到中间表时，中间表已通过数据复制拥有相同唯一键的记录，导致严格唯一性检查失败。        这不是应用程序错误：即使应用程序正确使用了ON DUPLICATE KEY，在Online DDL过程中仍会失败，这是MySQL底层机制的限制。        解决方案：避免在高并发期间执行DDL操作，或使用LOCK=EXCLUSIVE强制串行化，或采用分阶段变更策略。  "
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/golang/2019/04/18/Go-%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html",
    "title": "Go 内存逃逸与性能优化",
    "content": "当我们谈「性能优化」时，内存管理几乎绕不开。Go 的自动内存管理（GC）为开发效率带来极大提升，但如果不理解「内存逃逸（Escape to heap）」的成因与代价，很容易在高并发与低时延场景中踩到性能坑。本文将从跨语言视角解释什么是内存逃逸、为什么会发生，进而深入 Go 编译器的逃逸分析机制与常见触发场景，最后从编码规范与并发实践两个维度，系统性地给出可落地的性能优化方法与检查清单。什么是内存逃逸（跨语言视角）直觉上，函数内创建的局部变量应当位于栈上，随着函数返回被回收；而当变量「逃离」了其创建点的栈帧生命周期，就必须被分配到堆上，由 GC 统一回收，这就是「内存逃逸」。  在 C/C++ 中，没有 GC 的语境里很少使用「逃逸」一词，但同样存在「对象是否必须在堆上分配」这个问题：例如 new 分配的对象需要显式 delete，而局部对象则在栈上自动销毁。现代 C++（尤其是返回值优化、移动语义）会尽可能消除不必要的堆分配。  在 Java/JVM 中，JIT 会做逃逸分析：若对象不逃出方法，则可进行「栈上分配」与「标量替换」，显著减少 GC 压力。  在 Rust 中，是否在堆上分配由类型与所有权显示决定（如 Box&lt;T&gt;, Vec&lt;T&gt;）；编译器借助借用检查器保证生命周期安全，从根上避免了「悬垂指针」问题，但并不等价于不存在堆分配。  在 Go 中，编译器在编译期做逃逸分析：如果变量需要在其创建的函数返回后继续存活，或其地址被泄露到不受控的地方，就会被放入堆中。这降低了手工管理内存的复杂度，但也意味着我们需要理解逃逸触发的典型路径，以降低堆分配次数和 GC 负担。小结：内存逃逸不是 Go 独有，而是带有自动内存管理或抽象分配策略的语言在优化时必须面对的问题。区别在于：Go 把决策放在编译期，Java 多在 JIT 运行期，C++ 则更多由程序员显式决定。为什么会发生逃逸（Go 编译器视角）Go 编译器会在 SSA 阶段做逃逸分析。下列典型场景会触发「escapes to heap」或「moved to heap」：1) 返回局部变量的地址或引用func foo() *int {    x := 10    return &amp;x // x 必须活到函数外 -&gt; 逃逸到堆}2) 闭包捕获需要在函数返回后仍被使用的变量func counter() func() int {    n := 0    return func() int { // 闭包引用 n，需在外层函数返回后继续存活        n++        return n    }}3) 接口装箱与多态边界将具体类型赋给空接口或接口参数本身不会必然导致堆分配，但若其生命周期跨越创建点的栈帧、或者被放入堆对象（如切片、map、channel）中，往往会引发逃逸。反射（reflect）、fmt 家族函数也常在热路径里触发不必要的分配。4) 容器增长与不确定大小切片、map 需要动态增长时会触发重新分配；若元素本身位于堆中，容器扩容后的复制也会扩大堆数据规模。容量估计不足是常见诱因。5) 栈空间不足或跨协程传递当对象过大、或其地址被跨 goroutine 传递时，编译器更倾向将其放入堆上，以降低栈拷贝与复杂度。6) 逃逸链条一个变量一旦被放入「可能在堆上存活」的结构中（如存入 map、作为指针返回、作为接口传递到外层），就会沿链条放大逃逸范围，形成连锁反应。你可以用如下命令观察编译器的判断依据：go build -gcflags='all=-m -m' ./...# 关注输出中的 \"escapes to heap\"、\"moved to heap\" 等提示如何在 Go 中避免或减少逃逸逃逸不是「错误」，而是权衡。目标不是绝对禁止堆分配，而是减少「无谓」分配，降低 GC 压力与尾延迟。以下是可落地的策略与取舍说明：  值语义优先，小对象传值，大对象传指针          对于小型不可变数据（如坐标点、短小结构体），优先使用值传递与值接收者方法，以提高栈亲和与缓存局部性。      对于大型结构体或需要在多处共享的对象，用指针避免大拷贝，但需意识到这更容易触发逃逸与共享修改。        避免将临时对象暴露到堆          尽量不要返回局部变量的地址；使用值返回或让调用方传入缓冲区。      尽量避免闭包捕获大的可变对象；可改为显式参数传递，或将所需值复制到闭包内部的临时变量中。        减少接口边界与反射          热路径上避免 interface{}、fmt.Sprintf、fmt.Fprintf、reflect.Value 等动态机制；      使用具体类型与 strconv/strings.Builder/bytes.Buffer 等零分配或低分配替代物。        容器与缓冲预分配          为切片/Map 估计容量：make([]T, 0, n)、make(map[K]V, n)；      对 strings.Builder/bytes.Buffer 预先 Grow(n)，减少扩容与拷贝。        字符串与字节切片的转换          []byte(s) 与 string(b) 都会产生分配；尽量在同一层内保持一种表示，或通过 API 设计减少往返转换。      极端场景可考虑零拷贝（unsafe.String / unsafe.Slice）但需严格边界与版本约束，否则引入未定义行为风险。        使用对象池 sync.Pool（谨慎）          适合「短生命周期、创建代价高、可复用」的临时对象（如编码缓冲、压缩器、正则器）。      注意：sync.Pool 在 GC 时会被清空，不能用于缓存业务关键数据；在延迟敏感路径上，过大的对象也可能因跨 P shard 迁移带来额外开销。        函数内避免不必要的临时字符串          日志/错误在热循环中避免格式化；复用 []byte 缓冲并在边界一次性格式化。      下面给出若干示例对比（仅示意）：// 1) 返回值 vs 返回指针type Point struct{ X, Y int }// 更易留在栈上func NewPoint(x, y int) Point {    return Point{X: x, Y: y}}// 更可能逃逸（取决于调用场景）func NewPointPtr(x, y int) *Point {    p := Point{X: x, Y: y}    return &amp;p}// 2) strings.Builder 预分配func JoinWithBuilder(parts []string) string {    var b strings.Builder    // 粗略估算容量，避免多次增长    total := 0    for _, s := range parts { total += len(s) }    b.Grow(total + len(parts))    for i, s := range parts {        if i &gt; 0 { b.WriteByte(',') }        b.WriteString(s)    }    return b.String()}// 3) sync.Pool 使用范式var bufPool = sync.Pool{New: func() any {    b := make([]byte, 0, 4096)    return &amp;b}}func useBuf() {    bptr := bufPool.Get().(*[]byte)    b := (*bptr)[:0]    // ... 使用 b 作为临时缓冲 ...    *bptr = b[:0]    bufPool.Put(bptr)}基准、剖析与观测工具  编译期逃逸诊断          go build -gcflags='all=-m -m' ./... 或 go test -c -gcflags='all=-m -m'      聚焦输出中的 escapes to heap 与触发位置。        微基准与分配计数          go test -bench=. -benchmem -run=^$：同时观察 allocs/op 与 B/op。      注意基准可靠性：固定 CPU 频率、关闭涡轮、Pin 进程、GOMAXPROCS 固定、预热与多次运行。        运行期分析          pprof：CPU/内存/阻塞/互斥；go tool pprof -http=:0 交互浏览。      runtime/metrics、runtime.ReadMemStats：观察 GC 周期、堆增长、NextGC、Pause 总量。        GC 调参（视版本）          GOGC：目标堆增长百分比；数值越大，GC 越少但内存占用更高。      Go 1.19+：GOMEMLIMIT/debug.SetMemoryLimit 限制进程可用内存上限，避免节点 OOM。      基准阶段可临时 GOGC=off 排除 GC 干扰，但务必仅用于测试。      并发实践中的性能优化并发是 Go 的强项，但不当使用同样会放大分配与竞争。  协程数量控制与复用          不要「为每个请求创建一个 goroutine」而无节制；使用 bounded worker pool 控制并发度。      避免 goroutine 泄漏：退出路径必须能被关闭或取消（context.Context）。        Channel 设计          合理缓冲：突发流量下少量缓冲可降低抖动；过大缓冲可能隐藏上游背压问题。      避免在热循环中频繁 select { case &lt;-time.After(...) }：优先复用 time.Timer 并 Stop()。      对热点广播/订阅场景，单通道可能成为瓶颈，可用分片/多播结构降低竞争。        锁策略与无锁化          在读多写少场景使用 RWMutex，但写存在时 RLock 依然会被阻塞，读占比不高时反而慢于 Mutex。      热点 Map 可做分片（sharding）降低锁竞争；或在高度写竞争时改为批量聚合（log-structured）。      对计数器之类的轻量共享变量，使用 atomic 并考虑缓存行填充避免 false sharing。        数据布局与缓存友好          「切片元素为值」通常比「切片元素为指针」更具局部性（SoA/AoS 需结合场景权衡）。      小对象紧凑存储、减少指针追逐，有助于 CPU 预取与分支预测。        I/O 合并与批处理          通过缓冲、批量写入/读取降低系统调用次数；上游聚合（如 Kafka 批量）可降低端到端成本。      编程原则与规范（面向性能）以下清单可作为 code review 的关注点：  API 设计：          明确输入输出的所有权与生命周期，尽量不在接口边界做 string/[]byte 互转。      提供「带 buffer」的变体（如 Encode(dst []byte)），让调用方控制分配。        错误与日志：          热路径下避免 fmt.Errorf 及字符串拼接；使用哨兵错误、errors.Join 在边界汇总。      日志加采样与速率限制，避免结构化日志在高 QPS 下产生大量临时对象。        集合与字符串：          预估容量；避免在循环内反复增长。      频繁拼接使用 strings.Builder 或 bytes.Buffer，并尽量 Grow。        反射与泛型：          反射仅用于初始化与非热路径；      泛型减少了 interface{} 带来的装箱，更易于编译期优化与内联。        局部优化与边界权衡：          不为微不足道的 allocs/op 牺牲可读性；只在性能可观且可证实时引入复杂技巧。      实战对比：基准示例// go test -bench=. -benchmem -run=^$package demoimport (    \"bytes\"    \"strconv\"    \"strings\"    \"testing\")func BenchmarkConcat_Plus(b *testing.B) {    s := \"\"    for i := 0; i &lt; b.N; i++ {        s += strconv.Itoa(i)    }    _ = s}func BenchmarkConcat_Buffer(b *testing.B) {    var buf bytes.Buffer    for i := 0; i &lt; b.N; i++ {        buf.WriteString(strconv.Itoa(i))    }    _ = buf.String()}func BenchmarkConcat_Builder(b *testing.B) {    var sb strings.Builder    for i := 0; i &lt; b.N; i++ {        sb.WriteString(strconv.Itoa(i))    }    _ = sb.String()}上例中，+ 拼接在循环中通常会产生较多分配；bytes.Buffer 与 strings.Builder 通常能将 allocs/op 降到更低（依输入规模不同）。再看一个逃逸分析的例子：// go build -gcflags='all=-m -m' ./...type big struct { buf [1024]byte }func retPtr() *big {    b := big{}    return &amp;b // 逃逸}func retVal() big {    b := big{}    return b // 值返回，更易栈分配（由编译器决定）}GC 与内存上限控制（生产视角）  结合业务峰值与节点内存，设置合理的 GOMEMLIMIT（Go 1.19+）保障进程不被 OOM killer 终止。  根据延迟/吞吐目标调节 GOGC：较高的 GOGC 降低 GC 频率但增大内存占用；低 GOGC 提升回收频率但可能带来更多暂停与 CPU 占用。  通过分层缓存（本地+远端）与对象复用，尽量减少短命堆垃圾生成速率（allocation rate），从源头降低 GC 压力。检查清单（Cheat Sheet）  逃逸分析输出是否干净？是否有异常的热点函数产生大量 escapes to heap？  热路径是否避免了接口装箱、反射与 fmt？  切片/Map 是否做了容量预估与 Grow？  是否将大对象指针在协程间广泛传递，能否改为值拷贝或 ID 引用？  是否引入了不必要的 []byte ↔ string 转换？  是否可以通过 API 设计改为「调用方提供缓冲」？  是否合适地使用了 sync.Pool，并在 GC 清空后能自愈？  并发是否存在锁热点、goroutine 泄漏、time.After 泄漏？  是否通过基准与 pprof 证实优化收益？结语Go 的语言特性鼓励以简单的编程模型解决复杂的并发问题，但要在高性能场景下保持可预期的尾延迟和资源占用，就必须理解编译器如何在「栈与堆」之间做选择。把握逃逸触发的典型路径，利用好 -gcflags='all=-m -m'、-benchmem 与 pprof 等工具，辅以面向性能的 API 设计与并发策略，往往能在不牺牲可读性的前提下获得数量级的性能提升。牢记：优化应以度量为锚，先测量，再设计，最后验证。"
  },

  {
    "url": "/web3/2019/04/07/Web3-%E5%AE%9A%E4%B9%89%E4%B8%8E%E7%89%B9%E7%82%B9.html",
    "title": "Web3 的定义与特点：从愿景到工程落地",
    "content": "“Web3”不是一个单一产品，而是一组互相强化的理念与技术集合：密码学身份、开放协议、可组合金融/内容组件、链上可验证状态，以及逐步去平台化的组织与治理方式。本文从历史演进到工程落地，系统阐述 Web3 的核心特点、挑战与最佳实践，并给出可操作的架构与工具清单。1. 从 Web1 → Web2 → Web3：范式迁移  Web1（只读）：门户/个人主页，内容由站点生产，用户是“浏览者”；  Web2（读写）：用户生成内容（UGC）+ 平台算法分发，账号与数据由平台托管；  Web3（读写+拥有）：私钥拥有权与可验证规则，资产/身份与应用松耦合（可携带、可组合）。迁移的本质：从“中心化平台对数据与身份的控制”转向“用户用私钥控制身份与资产”，从“平台背书可信”转向“协议与加密保证可信”。2. Web3 的核心特征（工程视角）1) 去中心化身份（DID）：地址/公钥或 DID 文档作为标识，签名即授权；2) 合约化规则：规则公开、可验证、可复用，透明度优先；3) 可组合性（Money Legos）：协议接口标准化（ERC/EIP），上层快速组合创新；4) 开放互操作：跨链桥、消息传递与共享标准；5) 可验证与可追溯：状态在链上可校验、事件可重放，抗审查能力更强；6) 经济激励：代币与治理机制协调参与者行为。3. 用户体验的现实挑战  私钥与助记词管理门槛高；  Gas 与网络切换等概念复杂；  交易确认有延迟与不确定性；  欺诈与钓鱼风险（签名诱导、授权过大）。工程应对：账户抽象（代付/批量）、清晰签名提示（EIP-4361）、自动网络配置（EIP-3085/3326）、可回滚的 UI 设计。4. 参考架构graph LR  UI[dApp] -- EIP-1193 --&gt; Wallet  Wallet -- Tx/Sign --&gt; Chain[Blockchain]  Chain -- Logs --&gt; Indexer[(Subgraph/Indexer)]  UI -- Query --&gt; Indexer  UI -- Read --&gt; RPC  前端：与钱包交互、展示状态、触发交易；  合约：资产/规则中心；  索引器：对事件进行结构化，支撑列表/统计；  RPC：直接读取链上视图状态。5. 身份与资产：DID、VC 与 Token  DID（去中心化身份）：基于公私钥/文档解析；  VC（可验证凭证）：证明所有权/资格；  Token：Fungible（ERC-20）与 Non-Fungible（ERC-721/1155）；  授权：Permit（EIP-2612）减少批准交易；  治理：一币一票/权重委托。6. 互操作与扩容：L2 与跨链  Layer2（Rollup/Validium）提高吞吐并降低成本；  跨链桥风险管理：信任模型、消息证明与流动性桥；  数据可用性层（DA）：Celestia/以太坊 DA 提供可验证数据发布。7. 风险与监管  合约漏洞：重入、访问控制、数学错误；  经济攻击：预言机操纵、MEV；  法务合规：KYC/AML、证券属性判断；  隐私：链上透明与用户隐私的平衡（ZK/混币等）。8. 工具与生态清单  前端：viem、wagmi、ethers.js；  合约：Solidity、Foundry/Hardhat、OpenZeppelin；  索引器：The Graph、SubQuery、自建 ETL（ClickHouse/PostgreSQL）；  基础设施：Infura/Alchemy、自建 Erigon/Geth；  监控：Tenderly、Etherscan API、Prometheus/Grafana；  测试：本地链（anvil/hardhat），fork 主网验收。9. 经典案例剖析（简述）  DeFi 协议（Aave/Uniswap）：开放可组合与 LP 激励、风险参数治理；  NFT 市场：元数据与版税策略、跨市场可转移性；  DAO：资金透明、投票执行自动化。10. 最佳实践（工程落地）  信任最小化：后端仅做聚合/缓存；  可观测：交易/事件/索引延迟全链路指标；  文档化：签名提示清晰、错误码与引导页；  灰度发布：多网络/小流量上线；  安全上线流程：审计+Bug Bounty+多签开关。11. 小结Web3 的“拥有权”愿景并不与“良好体验”矛盾，关键在于以工程方法补齐体验鸿沟：钱包与账户抽象降低门槛、索引器与缓存支撑用户级响应、跨链与 L2 提供可用性。坚持“开放、互操作、可组合”的原则，才可能在复杂生态中保持长期生命力。"
  },

  {
    "url": "/%E6%88%90%E9%95%BF/2019/03/18/%E6%8A%80%E6%9C%AF%E6%88%90%E9%95%BF%E4%B8%8D%E7%94%A8%E7%AD%89%E5%8D%81%E5%B9%B4%E6%8B%86%E5%A2%99%E5%BC%8F%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97.html",
    "title": "技术成长不用等十年拆墙式进阶指南",
    "content": "技术成长不用等十年：拆墙式进阶指南身边总有人问：“每天写 CRUD，能成大牛吗？”“下班累得只想躺，哪有时间学新技术？”“学了半年框架，感觉还是没进步……”技术成长的焦虑，往往源于把 “成为大牛” 当成了遥不可及的山顶。但真实的成长，从来不是闷头爬坡，而是像拆墙 —— 拆掉挡在眼前的认知墙、行动墙、业务墙。每拆一块砖，视野就开阔一分，3 年能抵别人 5 年，这才是接地气的进阶逻辑。一、先拆认知墙：别被 “一万小时” 吓住《异类》的一万小时理论火了之后，太多人盯着 “10 年” 这个数字焦虑。但没人告诉你：这一万小时，藏在每天的碎片里，甚至能和加班 “搭伙过日子”。1. 别算总帐，算 “零钱”刚工作时我也觉得 “每天 3 小时” 是天方夜谭 —— 早上挤地铁，晚上加完班快 10 点，哪来整块时间？后来发现，把 “3 小时” 拆成 “5 分钟 + 15 分钟 + 20 分钟” 的零钱，反而更容易坚持。以学习 Java 开发为例：      上班前 5 分钟：打开收藏的 Java 集合框架源码片段，看 ArrayList 的 add 方法实现，了解它如何动态扩容数组，增加元素。比如看到 add 方法里，当数组容量不足时，会创建一个新的更大的数组，并将原数组元素复制过去。        午休后 15 分钟：用公司测试环境跑一段昨天学的多线程代码示例。例如写一个简单的多线程任务，模拟多个线程同时访问共享资源，观察线程安全问题，再尝试用 synchronized 关键字去解决。        睡前 20 分钟：在手机备忘录写 “今日踩坑笔记”。比如今天在写数据库查询语句时，因为没有给某个字段加索引，导致查询速度极慢，通过给该字段添加索引，查询时间从十几秒缩短到了几百毫秒。  这样一天下来，40 分钟不算多，但每周就是 280 分钟，一年积累 14560 分钟 —— 差不多 242 小时，足够啃完一本像《Effective Java》这样的源码书。2. 警惕 “伪努力” 的自我感动有人囤了 50G 教程，却只看了前 3 集；有人 GitHub 星标了 200 个项目，从没克隆过一个。这种 “收藏即学会” 的假努力，比不学习更坑 —— 它会让你产生 “我在进步” 的错觉。真成长的两个标志：      能说出 “上周学会的东西，这周用到了”。例如上周学习了 Redis 缓存技术，这周在项目中给频繁查询的热点数据加上了 Redis 缓存，大大提高了系统响应速度。原本查询数据库需要几百毫秒的接口，现在通过 Redis 缓存，响应时间缩短到了几十毫秒。        能指出 “以前写的代码，现在看是错的”。比如发现半年前写的单例模式代码，在多线程环境下会出现创建多个实例的问题，现在明白要使用双重检查锁机制或者静态内部类的方式来确保单例的唯一性。  二、再拆行动墙：把 “大目标” 砸成 “手边事”“今年要吃透 JVM”“年底前搞定分布式系统”—— 这种目标喊完就忘，因为太像 “要吃一头大象”。真正能落地的行动，是把大象切成 “今天能吃一口” 的小块。1. 目标拆解的 “三阶落地法”以 “3 个月学好 MySQL” 为例，别一上来就说 “要懂索引原理”，按 “用→优→理” 三阶拆：      第 1 个月（用）：每天花 10 分钟，给写的 SQL 加 explain 分析。比如在写一个查询用户信息的 SQL 语句时，使用 explain 关键字查看执行计划，发现因为使用了 “select *”，没有明确指定需要的字段，导致全表扫描，查询效率低下。通过优化 SQL，只查询必要字段，速度得到了提升。        第 2 个月（优）：每周挑一个慢查询，试着改写成 join。例如原本有三次单表查询，分别查询用户表、订单表、商品表，通过分析业务逻辑，将其改写成一次联表查询，减少了数据库查询次数，大大提高了查询效率。原本需要多次查询数据库并在应用层进行数据组装，现在通过一次联表查询就获取到了所需的关联数据。        第 3 个月（理）：每周末花 1 小时，对着《高性能 MySQL》看一个索引类型。比如学习聚簇索引和非聚簇索引的区别，了解到聚簇索引按照数据行的物理存储顺序构建，适合范围查询；非聚簇索引则与数据行的物理存储顺序无关，适合等值查询。并通过在测试数据库中创建不同类型的索引，进行查询测试，加深理解。  每个阶段都能立刻用在工作里，成就感会推着你走。2. 加班党的 “偷时间” 技巧上周和一个大厂朋友聊天，他说 “我加班多，但两年升了高级，靠的是加班时‘顺手学’”：      改 bug 时多问一句：“这个报错的底层原因是什么？” 比如遇到 NullPointerException 空指针异常报错，在修复 bug 的同时，顺手查阅 JVM 的空指针检查机制。了解到 JVM 在执行字节码指令时，当访问一个空引用的对象实例的属性或方法时，就会抛出这个异常。通过深入理解，以后在编写代码时能更注重对象的判空处理，避免类似问题。        部署代码时多做一步：“加个监控指标行不行？” 例如在给接口部署上线时，顺便添加一个响应时间监控指标。通过使用 Prometheus 这样的监控工具，配置好相应的指标采集规则，就可以实时观察接口的响应时间变化。这不仅能帮助及时发现系统性能问题，还让自己学会了 Prometheus 的基础用法。        下班前花 5 分钟：“今天的代码里，哪个地方能再简化一行？” 比如把重复的判断逻辑抽成工具类，练习了设计模式。原本在多个地方都有判断用户是否登录的重复代码，通过创建一个 UserUtil 工具类，将判断逻辑封装在其中，其他地方只需调用该工具类的方法，代码变得更加简洁、易维护，同时也加深了对设计模式中封装思想的理解。  加班不是成长的敌人，关键是别当 “代码搬运工”。三、最后拆业务墙：CRUD 里藏着 “进阶密码”“天天写业务，哪有技术含量？” 这是最大的误解。业务代码就像土壤，能不能长出技术的苗，看你会不会 “深挖三铲”。1. 业务代码的三层深挖法拿最普通的 “用户注册” 功能举例：      第一层（功能）：完成表单校验、入库（这是基础）。在实现用户注册功能时，首先要对用户输入的用户名、密码、手机号等信息进行表单校验，确保格式正确且符合业务规则。例如用户名不能包含特殊字符，密码长度要在一定范围内等。校验通过后，将用户信息插入数据库的用户表中。        第二层（优化）：加个手机号格式缓存（不用每次查数据库），加个异步发送短信（不阻塞注册流程）—— 这就用到了缓存和多线程。可以使用 Redis 缓存来存储已经校验过的手机号格式，当下次有新用户注册输入手机号时，先从 Redis 中查询该手机号格式是否已经校验过，若已校验则直接通过，无需再进行复杂的格式校验逻辑，减少数据库查询压力。同时，为了避免发送注册成功短信时阻塞用户注册流程，可以使用多线程技术，将发送短信的任务放到一个新的线程中执行。例如在 Java 中，可以使用线程池来管理这些发送短信的线程，提高系统并发处理能力。        第三层（原理）：想想 “为什么用 Redis 存验证码？”“线程池参数怎么设才不炸？”—— 逼着自己关联底层知识。思考为什么选择 Redis 存储验证码，是因为 Redis 具有高性能、支持分布式、数据结构丰富等特点，适合存储验证码这种时效性强的数据。对于线程池参数设置，要考虑任务类型、并发量等因素。比如如果是 CPU 密集型任务，线程池大小不宜设置过大，防止过多线程竞争 CPU 资源；如果是 I/O 密集型任务，可以适当增大线程池大小，充分利用 CPU 空闲时间处理其他任务。通过这样深入思考，能将业务实现与底层技术原理紧密联系起来，提升技术深度。  我见过有人把注册功能写成 “分布式锁防重复提交”“消息队列削峰” 的案例，业务没变，但技术深度完全不同。2. 用 “业务问题” 当钥匙别总等着 “学完再用”，要学会 “用了再学”。比如：      发现 “订单查询慢”，就去学索引优化。在实际业务中，如果订单数据量较大，订单查询速度慢，通过分析发现是因为查询语句没有合理利用索引。这时就可以学习索引优化知识，比如为经常用于查询条件的字段创建合适的索引，选择合适的索引类型（如 B - Tree 索引、哈希索引等）。通过实际业务问题驱动学习，能更快掌握索引优化技巧，并应用到项目中，显著提升订单查询速度。        遇到 “并发下单超卖”，就去学分布式锁。当电商系统中出现高并发下单时，可能会出现商品超卖问题。为了解决这个问题，需要学习分布式锁知识。可以了解基于 Redis、Zookeeper 等实现分布式锁的原理和方式。例如使用 Redis 的 SETNX 命令（SET if Not eXists）来实现简单的分布式锁，通过设置锁的过期时间来避免死锁。在实际项目中应用分布式锁，解决并发下单超卖问题，同时也加深了对分布式系统一致性问题的理解。        老板说 “系统总崩”，就去学监控和高可用。如果系统经常崩溃，影响业务正常运行，此时就需要学习系统监控和高可用技术。可以使用如 Grafana + Prometheus 组合进行系统监控，实时监测系统的 CPU 使用率、内存使用率、磁盘 I/O、网络流量等指标，及时发现系统性能瓶颈。对于高可用架构，可以学习如何使用负载均衡、集群部署等技术，将系统部署到多个服务器上，当一台服务器出现故障时，其他服务器能继续提供服务，保证系统的高可用性。通过解决业务中的这些痛点问题，推动自己不断学习新的技术知识。  业务中的痛点，恰恰是最好的学习路标。去年有个同事，因为负责的后台总卡顿，硬着头皮学了 JVM 调优，现在成了团队里的 “性能优化专家”。四、拆墙工具包：3 个随时能用的小技巧1. 5 分钟碎片法      蹲坑时：刷一篇 “10 行代码讲透 ArrayList 扩容”。在手机上阅读相关技术文章，了解 ArrayList 在添加元素时，如果当前容量不足，是如何通过创建新数组、复制元素等步骤实现扩容的，加深对集合框架底层原理的理解。        等电梯时：在脑子里过一遍 “今天改的那个 bug，根本原因是什么？”。回顾今天修复的某个代码错误，思考是因为逻辑判断失误、语法错误，还是对某个 API 的使用不当导致的，强化对问题的分析和解决能力。        外卖到了还没开吃：打开 IDE，跑一遍昨天记的代码片段。比如昨天学习了一段关于文件读写的代码，利用这几分钟时间在 IDE 中运行一下，确保自己真正掌握了这段代码的功能和使用方法，同时也能加深记忆。  碎片时间不用学新知识，能复盘、能巩固就够了。2. 进步可视化找个笔记本，每天写三行：      今天解决了什么问题？（哪怕是 “搞定了一个乱码 bug”）。例如今天在处理用户上传文件时，文件内容出现乱码，通过排查发现是文件编码格式与系统默认编码格式不一致，通过修改编码设置解决了这个问题。        用到了什么知识点？（比如 “知道了 UTF - 8 和 GBK 的区别”）。在解决乱码问题过程中，了解到 UTF - 8 是一种变长编码，支持全球几乎所有字符集，而 GBK 是针对简体中文的编码，二者在编码范围、存储方式上有所不同。        明天想搞懂什么？（比如 “为什么 Postman 发请求会跨域”）。由于在测试接口时发现使用 Postman 发送请求出现跨域问题，明天计划深入学习跨域产生的原因（浏览器的同源策略限制）以及解决方案（如使用 CORS、JSONP 等）。  三个月后翻一翻，会发现自己不知不觉懂了这么多。3. 业务代码的 “找茬游戏”每次写完代码，问自己三个问题：      这行代码，换个写法能更快吗？（比如用 for 循环代替 Stream，在数据量大时更快）。在处理一个对集合进行遍历操作的需求时，对比使用传统 for 循环和 Java 8 的 Stream API 的性能。通过测试发现，当集合数据量较大时，for 循环的执行效率更高，因为 Stream API 在内部会进行一些封装和函数式编程操作，有一定的性能开销。        这段逻辑，加个日志能方便排错吗？（比如给支付流程加 “订单状态变更” 日志）。在实现支付功能时，为了便于后续排查问题，在订单状态发生变更的关键节点添加日志记录，如记录订单从 “待支付” 变为 “支付中”“支付成功”“支付失败” 等状态的时间、操作人等信息，方便在出现问题时快速定位和分析。        这个功能，未来可能会怎么变？（比如用户量涨 10 倍，数据库要不要分表）。考虑到业务的发展，如果未来用户量大幅增长，现有的数据库表结构可能无法满足性能需求。提前思考是否需要进行数据库分表操作，以及分表的策略（如按时间分表、按用户 ID 取模分表等），培养对系统扩展性的思考能力。  找茬多了，慢慢就有了 “架构思维”。结语：成长是 “今天比昨天多懂一点”没人能一口吃成胖子，技术成长也不用等十年。你不用每天学 3 小时，每天 20 分钟够了；你不用立刻搞定分布式，先把手里的 SQL 写明白；你不用羡慕别人懂源码，先搞懂自己项目里的框架怎么配置。就像拆墙，今天拆一块砖，明天拆一片瓦，突然有一天抬头，会发现自己已经站在以前仰望的高度。现在打开你的 IDE，从改好眼前的第一行代码开始吧。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/mysql/2018/11/22/MySQL-%E9%94%81%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90%E6%89%8B%E5%86%8C.html",
    "title": "MySQL 锁监控与死锁分析手册",
    "content": "如何系统化监控行锁/间隙锁与快速定位死锁？本文提供可复现脚本、标准化视图与操作手册。1. 死锁复现（RR 下 Next-Key）CREATE TABLE t_lock(  id INT PRIMARY KEY,  k  INT,  KEY idx_k(k)) ENGINE=InnoDB;INSERT INTO t_lock VALUES (1,10),(2,20),(3,30);会话A：SET tx_isolation='REPEATABLE-READ'; START TRANSACTION;SELECT * FROM t_lock WHERE k BETWEEN 10 AND 30 FOR UPDATE; -- 锁住[10,30]会话B：SET tx_isolation='REPEATABLE-READ'; START TRANSACTION;UPDATE t_lock SET k=11 WHERE id=1; -- 等待A释放-- 回到会话A：UPDATE t_lock SET k=21 WHERE id=2; -- 互等 -&gt; 死锁2. 死锁日志解读SHOW ENGINE INNODB STATUS\\G关注：  LATEST DETECTED DEADLOCK 中 WE ROLL BACK TRANSACTION 指出被回滚事务；  lock_mode X locks rec but not gap / locks gap before rec 定位间隙锁；  index idx_k of table 对应的索引与范围。3. 在线监控  8.0：performance_schema.data_locks / data_lock_waits 关联 threads 得到阻塞链；  5.7：information_schema.innodb_locks / lock_waits（较旧）。4. 自动化抓取脚本（示意）SELECT l.*, w.*FROM performance_schema.data_lock_waits wJOIN performance_schema.data_locks l  ON w.BLOCKING_ENGINE_LOCK_ID = l.ENGINE_LOCK_ID;周期抓取 + 告警（阻塞&gt;5s）。5. 规避策略  精确索引，避免大范围扫描引发大量 gap 锁；  将写入拆分为更细粒度范围；  业务侧重试+幂等；  读写分离，长事务落只读副本。6. 死锁成因全景（结合 InnoDB 锁模型）死锁的四个必要条件：互斥使用、占有并等待、不可剥夺、循环等待。InnoDB 在行级与间隙级锁语义下，以下模式最易触发循环等待：  不一致的访问顺序：          事务A更新 A→B，事务B更新 B→A；或一个通过二级索引回表更新，另一个直接按主键更新，锁顺序不同。        范围更新引入 Next-Key/Gap Lock：          在 RR 下，SELECT ... FOR UPDATE/UPDATE/DELETE 会对命中记录及其间隙加锁，多个事务在相邻范围内插入/更新易互等。        唯一键检查 + 插入意向锁：          插入唯一键前需要在唯一索引区间做 Next-Key 检查；与并发范围更新/去重查询交错形成环路。        二级索引与回表：          一方以二级索引扫描并回表，另一方以主键路径进入，组合出的锁申请序列不一致。        外键检查：          父/子表在不同顺序读写，外键检查需要额外 S 锁/间隙锁，改变锁顺序。        自增锁与热点：          大并发插入时，旧模式下 AUTO-INC 锁可能放大等待链；热点值导致索引页竞争与页分裂叠加。        缺索引与大事务：          无索引范围扫描扩大锁集合；慢 SQL/长事务持锁时间长，死锁概率上升。      典型两会话交错示意：-- 场景1：访问顺序不一致-- 会话ASTART TRANSACTION;UPDATE t SET v=v+1 WHERE id=1; -- 锁 id=1UPDATE t SET v=v+1 WHERE id=2; -- 等待会话B释放-- 会话BSTART TRANSACTION;UPDATE t SET v=v+1 WHERE id=2; -- 锁 id=2UPDATE t SET v=v+1 WHERE id=1; -- 等待会话A释放 -&gt; 环-- 场景2：RR 下范围更新 + 插入唯一键-- 会话ASTART TRANSACTION;UPDATE t SET status=1 WHERE idx BETWEEN 10 AND 20; -- Next-Key 锁-- 会话BSTART TRANSACTION;INSERT INTO t(uq, idx, ...) VALUES('X', 15, ...); -- 唯一检查 + 插入意向-- 两边在唯一索引/二级索引与主键上的锁互等7. 事务隔离级别与锁行为（InnoDB 语义）  Read Uncommitted（读未提交）：几乎不用；当前读仍会加锁，允许脏读。  Read Committed（读已提交）：一致性读不加锁；大多数场景不使用 Gap Lock（外键/唯一检查仍可能使用），死锁概率低于 RR。  Repeatable Read（可重复读，默认）：一致性读用 MVCC；当前读采用 Next-Key Lock 防幻读，范围操作更易死锁。  Serializable（可串行化）：读也加锁，吞吐大降，除非强隔离需求。要点：  普通 SELECT（快照读）不加行锁；FOR UPDATE/LOCK IN SHARE MODE/UPDATE/DELETE 属于当前读会加锁。  RC 相比 RR 减少间隙锁；RR 下 Next-Key 是默认策略。  参数参考：innodb_autoinc_lock_mode=2 降低自增锁争用；innodb_deadlock_detect 控制检测器；innodb_lock_wait_timeout 控制等待上限。8. InnoDB 内部死锁处理机制（源码视角）InnoDB 锁与事务核心位于 storage/innobase：  锁子系统（lock_sys）：表锁 LOCK_TABLE、记录锁 LOCK_REC；模式 S/IS、X/IX、AUTO-INC、INSERT INTENTION；记录锁细分 Record/GAP/Next-Key。  事务结构（trx_t）：持有锁集合、等待中的锁 trx-&gt;lock.wait_lock、undo 信息。  锁入队：lock_rec_add_to_queue() / lock_table_add_to_queue() 将请求加入等待队列。  死锁检测：等待入队时，基于等待图进行环检测（lock0lock.cc 等）。从当前等待事务出发，遍历“阻塞我的锁→持锁事务→该事务正在等待的锁”，若回到起点即形成环。  牺牲者选择：按代价（已修改行数/undo 量/事务年龄/持有锁数量等）选择最小代价事务回滚，向其返回 1213，其余唤醒继续执行。  超时路径：未开检测器或无环，等待至 innodb_lock_wait_timeout 抛 1205。伪代码抽象：on_lock_wait(trx, lock_req):  if deadlock_detect_on and detect_cycle_from(trx):    victim = choose_lowest_cost_trx()    rollback(victim)    wake_up_waiters()  else:    wait_until_granted_or_timeout()诊断入口：SHOW ENGINE INNODB STATUS\\G 会输出最近一次死锁的等待链；设置 innodb_print_all_deadlocks=ON 可将所有死锁写入错误日志（生产谨慎）。9. 系统化诊断步骤（生产可用）1) 快速取证：  执行 SHOW ENGINE INNODB STATUS\\G，定位 LATEST DETECTED DEADLOCK。  抓取两个（或以上）事务的 SQL、索引名、锁模式（locks rec but not gap/locks gap before rec）。2) 在线视图：SELECT * FROM performance_schema.data_lock_waits; -- 等待边SELECT * FROM performance_schema.data_locks;      -- 锁明细SELECT * FROM sys.schema_lock_waits LIMIT 50;     -- 友好视图3) 执行计划核验：  对死锁 SQL 逐条 EXPLAIN，确认是否走了不同索引、是否回表、是否大范围扫描。4) 事务画像：  检查是否存在跨请求长事务、事务内外部 IO、批量扫描；确认提交点是否靠后。5) 复现与回归：  用最小化数据集在两个会话复现；将复现脚本纳入回归库。10. 工程实践：如何避免死锁  统一访问顺序（首要）：          规定跨表/跨索引的访问次序（如按主键升序 A→B→C），避免交叉顺序。        拆小事务，尽早提交：          批量更新分批提交；把只读校验前置；缩短持锁窗口。        索引到位，路径一致：          where 条件命中索引，尽量落到 Record Lock；必要时 FORCE INDEX 统一路径，减少“二级索引回表 vs 主键直达”的差异。        隔离级别策略：          OLTP 优先 RC（若业务允许），RR 场景要避免范围更新；或将“读→算→改”改为“精确定位→改”。        善用 8.0 特性：          FOR UPDATE SKIP LOCKED 跳过已锁行避免互等；NOWAIT 立即失败，应用快速重试。        热点打散与自增锁：          设计上分片热点键；配置 innodb_autoinc_lock_mode=2 减少 AUTO-INC 锁争用。        事务内禁止外部 IO：          避免 RPC/磁盘慢操作扩大持锁时间。        失败重试与幂等：          捕获 1213/1205 指数退避重试；以唯一键/业务幂等键确保多次提交安全。        代码层策略化：          收敛到统一 DAO/仓储层，内置锁序策略与“精确更新”模板；CR 强制检查。        监控预警与演练：          建立锁等待指标阈值；压测期开启 innodb_print_all_deadlocks，以现场日志反推 SQL 与索引设计。      11. 可复现实战案例案例A：二级索引范围更新 vs 主键更新CREATE TABLE t_a(  id BIGINT PRIMARY KEY,  k  INT,  KEY idx_k(k)) ENGINE=InnoDB;INSERT INTO t_a VALUES (1,10),(2,20),(3,30);-- 会话A（走二级索引）START TRANSACTION;UPDATE t_a SET k=k+1 WHERE k BETWEEN 10 AND 30; -- Next-Key + 回表-- 会话B（走主键）START TRANSACTION;UPDATE t_a SET k=25 WHERE id=2; -- Record Lock-- 两者在主键回表记录与二级索引范围上互相等待修复建议：  先用覆盖索引挑出主键集合，再按主键升序逐条精准 UPDATE；或在 RC 下改造范围操作；或对 B 强制走相同索引路径；或用 SKIP LOCKED 处理任务类更新。案例B：唯一键插入与范围更新CREATE TABLE t_b(  id BIGINT PRIMARY KEY,  uq VARCHAR(32) UNIQUE,  k  INT,  KEY idx_k(k)) ENGINE=InnoDB;-- 会话ASTART TRANSACTION;UPDATE t_b SET k=k+1 WHERE k BETWEEN 100 AND 200; -- Next-Key-- 会话BSTART TRANSACTION;INSERT INTO t_b(uq, k) VALUES('U-1', 150); -- 唯一检查 + 插入意向修复建议：  将范围更新拆小、改精确更新；或让插入避开竞争区间；或业务上统一顺序（先完成更新再插入）。12. 参数与配置建议  innodb_deadlock_detect=ON：可快速打断死锁；极端热点写场景可评估关闭并配合短超时+重试。  innodb_lock_wait_timeout：OLTP 建议 5–15s；务必配合应用层重试。  innodb_print_all_deadlocks=ON：压测/排障阶段开启，生产慎用。  innodb_autoinc_lock_mode=2：大并发插入友好。  隔离级别：OLTP 倾向 RC；需要 RR 时务必配合锁序策略与索引精确化。13. 上线前检查清单（Checklist）  是否定义并落地了“锁序白皮书”（跨表/跨索引）？  核心更新/删除是否命中索引并路径一致？  是否避免事务内外部 IO，定位了提交点？  是否为写操作设计幂等键并实现重试策略？  是否建立了锁等待/死锁指标与告警阈值？  是否准备了“死锁复现脚本”作为回归用例？14. 常用命令速查SHOW ENGINE INNODB STATUS\\G;SELECT * FROM performance_schema.data_lock_waits;SELECT * FROM sys.schema_lock_waits LIMIT 50;EXPLAIN FORMAT=JSON &lt;your SQL&gt;;  错误码：1213（Deadlock found）需重试；1205（Lock wait timeout）需优化或重试。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/mysql/2018/11/03/MySQL-MVCC-%E4%B8%8E%E5%BF%AB%E7%85%A7%E9%9A%94%E7%A6%BB%E6%B7%B1%E5%85%A5.html",
    "title": "MySQL MVCC 与快照隔离深入",
    "content": "本文系统拆解 InnoDB MVCC 的实现细节：undo log、隐式列、Read View、可见性判断与二级索引回表的一致性，并给出可复现实验、源码走读与排错清单。1. MVCC 结构  隐式列：trx_id（最近一次修改事务ID）、roll_pointer（回滚指针）。  undo log：维护历史版本链；读已提交/可重复读通过 Read View 选择可见版本。2. Read View 生成与可见性  关键字段：creator_trx_id、活跃集合 m_ids、low_limit_id、up_limit_id。  判断规则：trx_id &lt; low_limit_id 可见；trx_id &gt;= up_limit_id 不可见；在集合内不可见。SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;START TRANSACTION;SELECT * FROM t WHERE id = 1; -- 固定 Read View3. 二级索引一致性  二级索引条目不含行可见性信息，需回表到聚簇索引判断；  覆盖索引可避免回表，但仍受 MVCC 可见性约束。4. 可复现实验：幻读与间隙锁准备数据：CREATE TABLE t(  id INT PRIMARY KEY,  k  INT,  KEY idx_k(k)) ENGINE=InnoDB;INSERT INTO t VALUES (1,10),(2,20),(3,30);事务 A（会话1）：SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;START TRANSACTION;SELECT * FROM t WHERE k BETWEEN 10 AND 30 FOR UPDATE; -- Next-Key Lock事务 B（会话2）：INSERT INTO t VALUES(4,25); -- 阻塞：被间隙锁拦截，避免幻读切换 RC：SET GLOBAL transaction_isolation='READ-COMMITTED';-- 重新测试，观察 gap 锁减少与并发插入的行为变化5. 实验：RR 下版本可见性-- 会话1START TRANSACTION; SELECT * FROM t WHERE id=1; -- 读到 v1-- 会话2UPDATE t SET k=k+1 WHERE id=1; COMMIT;          -- v2-- 会话1SELECT * FROM t WHERE id=1; -- 仍读到 v1（同一 Read View）COMMIT;6. 源码走读要点（8.0）  read0read.cc：一致性读实现，基于 Read View 的可见性检查；  trx0trx.cc：事务生命周期与 ReadView 构建；  lock0lock.cc：Next-Key Lock 组合与冲突检测。关注点：m_ids 计算的边界、长事务导致的 purge 延迟对可见性的影响。7. 典型排错清单  长事务导致 history list length 过大，undo 堆积：          排查 information_schema.innodb_trx，定位阻塞的只读/未提交事务；        幻读与行锁升级：          检查是否遗漏索引导致范围扩大、或 RC 下并发写放大；        覆盖索引未生效：          EXPLAIN ANALYZE 对比 using index；确认选择列是否完全被索引覆盖。      8. 最佳实践  将批量只读分析放到只读副本，避免长事务阻塞主库 purge；  范围更新尽量精确，必要时逻辑分片降低锁冲突；  定期巡检长事务、undo 使用、innodb_purge_threads 与 IO 限流。"
  },

  {
    "url": "/web3/2018/03/12/%E6%AF%94%E7%89%B9%E5%B8%81-%E8%B5%B7%E6%BA%90%E4%B8%8E%E5%A5%96%E5%8A%B1%E6%9C%BA%E5%88%B6%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90.html",
    "title": "比特币的起源与奖励机制：底层逻辑与演进",
    "content": "比特币不是突然出现的一段代码，而是密码学、经济学与分布式系统三股力量长期积累后的工程综合体。本文从历史动机、共识与难度、奖励与费用市场、安全预算与长期可持续性等角度，对比特币的激励机制进行系统拆解，并给出工程视角的观察指标与常见误区澄清。1. 起源与设计动机  金融危机背景：2008 年全球金融危机后，中心化信用机制的脆弱性暴露。中本聪在创世区块留言 “Chancellor on brink of second bailout for banks”。  技术积累：工作量证明（Hashcash）、梅克尔树（Merkle Tree）、公钥密码学（ECDSA）、点对点网络（P2P）。  目标画像：无需许可的电子现金系统，任何人都可加入/退出，用计算工作替代机构信用，规则写入协议与代码而非人治。2. 创世区块与初始参数  区块间隔：目标 10 分钟（通过难度调整逼近）。  难度重算：每 2016 个区块（约两周）按实际出块时间调整难度；调整幅度被限制在目标时长的 1/4 到 4 倍之间，避免剧烈震荡。  奖励初始值：50 BTC/区块，约每 210,000 个区块减半一次（≈ 4 年）。  货币上限：几何级数收敛于约 2100 万枚（见下节推导）。3. POW 与难度调整的底层逻辑  工作量证明：矿工需找到使区块头哈希小于目标阈值的随机数（Nonce），概率与算力成正比。  难度与目标：难度越高，目标阈值越低，满足条件的哈希更稀有，从而拉长期望出块时间至约 10 分钟。  经济含义：算力越多，单位时间内期望产出的区块数不变（仍然约 6 个/小时），因此矿工的边际收益取决于自身算力在全网算力中的占比，而非绝对算力。4. 区块奖励与减半曲线（总量 2100 万如何得出）  每个减半周期的新区块奖励总量：50 × 210,000、25 × 210,000、12.5 × 210,000 …  这是公比为 1/2 的几何级数，极限总量：          210,000 × 50 × (1 + 1/2 + 1/4 + …) = 210,000 × 50 × 2 = 21,000,000。        工程注意：受早期客户端精度与奖励规则边界影响，实际铸币量略低于理论极限，约 20999999.9769 BTC，通常近似为 2100 万。5. 手续费市场：从补充到主角  收入结构：矿工收入 = 区块补贴（新币）+ 交易费（手续费）。  演进趋势：补贴随时间指数级衰减，长期安全预算需更多依赖费用市场。  费用形成机制：区块空间稀缺（区块尺寸与出块频率受限），用户以更高费用竞争打包优先级，形成“第一价格拍卖”近似的市场。  事件冲击：牛市高峰、铭文/Ordinals、L2 结算拥堵均会显著提高费率并提升矿工收入占比。6. 激励相容与博弈简析  诚实路径：遵守最长链/最多累计难度链规则、及时传播区块，获得稳定的期望奖励。  偏离代价：自私挖矿、双花尝试在高算力占比与网络延迟条件下才有正期望，且面临孤块风险、信誉受损、合规风险。  协议设计：通过难度调整与费用市场，使“诚实挖矿”成为占优策略（或近似占优）。7. 安全预算与长期可持续性  概念：网络抵御攻击的经济门槛 ≈ 攻击者需要的算力成本与机会成本之和。  趋势担忧：减半后补贴下降，若费用市场不足，理论上可能降低攻击门槛。  现实缓解：          成熟的 ASIC 产业链与能源合作降低单位算力成本，提高退出壁垒；      交易批量化与 LN/rollup 结算带来高峰期费用；      市场周期与叙事（如“数字黄金”）扩张链上结算需求。        工程应对：          观测“手续费/区块补贴”之比的长期趋势；      观察孤块率、难度带宽利用率、内存池深度分布；      评估减半窗口前后矿工哈希迁移与地理分布集中度。      8. 常见误区  误区 1：算力翻倍 → 价格必涨。事实：发行速率由协议决定，算力主要反映成本曲线与矿工对未来价格的预期。  误区 2：手续费永远会回到低位。事实：区块空间供给刚性，需求波动会形成有记忆的费率结构。  误区 3：减半一定推高价格。事实：供给收缩是必要但非充分条件，价格还取决于需求、流动性与宏观环境。9. 工程实践与观测指标  全节点运维：          同步模式（全量/修剪）、磁盘与带宽规划、快照校验；      指标：区块传播延迟、孤块率、mempool 尾部延迟（p95/p99）。        矿工/矿池侧：          收益分布（补贴 vs 手续费）与难度变化的弹性；      交易选择策略（费率/字节、Child-Pays-For-Parent、RBF）。        分析与风控：          监控大额未确认交易对费率的扰动；      减半窗口的区块时间方差与难度调整幅度。      10. 小结比特币用“可验证的工作”替代“中心化信用”，并以“递减补贴 + 费用市场”的双机制为网络安全买单。其长期健康取决于费用市场的成熟度与需求侧的持续性。对工程与研究从业者而言，理解难度调整、费用形成与矿工博弈，是评估网络安全预算与经济稳态的基础功夫。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/php/2018/01/26/PHP-%E5%8D%8F%E7%A8%8BSwoole-%E9%AB%98%E5%B9%B6%E5%8F%91%E5%AE%9E%E8%B7%B5.html",
    "title": "PHP 协程 Swoole 高并发实践",
    "content": "Swoole 将 PHP 带入常驻内存 + 协程并发时代。本文聚焦调度、Hook、协程上下文与与 MySQL/Redis 客户端协作细节，并提供压测脚本与避坑指南。1. 协程 Hook  Swoole\\Runtime::enableCoroutine() 对常见 IO 进行 Hook；  注意与第三方扩展兼容性（cURL、多进程）。2. 连接池示例class MySQLPool { /* ... 维护 Channel 与 连接对象 ... */ }// 请求开始从池获取，结束归还；确保协程安全3. 压测wrk -t8 -c200 -d60s http://127.0.0.1:9501/观察 QPS、P95、net.core.somaxconn、ulimit -n。4. 常见坑  全局单例污染：请求间状态泄漏；  异常处理：协程内抛出的异常要汇聚到日志与告警；  Composer 热更新失效：常驻进程需手动 reload。"
  },

  {
    "url": "/web3/2017/09/11/%E5%AF%86%E7%A0%81%E5%AD%A6-%E5%8F%91%E5%B1%95%E5%8F%B2%E4%B8%8E%E5%BD%93%E4%BB%A3%E7%BB%8F%E6%B5%8E%E5%BD%B1%E5%93%8D.html",
    "title": "密码学-发展史与当代经济影响",
    "content": "密码学不仅是保密术，更是现代经济的底层信任机器。从古典替换法到公钥革命，从TLS到区块链与零知识证明，密码学已成为互联网与数字经济的基础设施。本文按时间脉络梳理密码学主要里程碑，并分析其对金融、支付、数据市场与监管的深远影响。1. 古典密码学：对称“保密术”的时代  早期方法：凯撒移位、维吉尼亚表、一次性密码本（理论上不可破）。  工业化破解：二战期间的机械与电机加密（恩尼格玛、紫密），由统计分析与计算机器（图灵机）推动破解技术跃迁。2. 公钥密码学革命（1970s）  基本思想：将加密密钥与解密密钥分离，解决密钥分发难题。  代表算法：RSA（整数分解困难）、Diffie–Hellman（离散对数）、椭圆曲线 ECDSA/ECDH（以更短密钥提供相当安全性）。  重要配套：数字签名、消息认证码（MAC）、哈希函数（SHA 系列）、随机数生成器（CSPRNG）。3. 互联网与密码协议（1990s–）  TLS/SSL：为网页、支付与 API 提供端到端加密与身份认证；证书与 PKI 形成“信任锚”。  存储与传输：AES 成为对称加密事实标准，GCM/ChaCha20-Poly1305 提供高效认证加密。  典型应用：磁条到 EMV 的演进、FIDO 无密码认证、端到端即时通讯（Signal/WhatsApp）。4. 区块链与可验证计算  比特币：用工作量证明将经济激励与加密结构结合，形成无需许可的结算层。  以太坊与智能合约：在可验证状态机上运行通用逻辑，扩展到金融、游戏与治理。  零知识证明：SNARK/STARK 让“在不暴露数据的前提下证明计算正确”成为可能，支持隐私与扩容（Rollup）。5. 经济影响：密码学如何塑造现代经济  支付与清算：端到端加密与签名降低欺诈率，缩短清算周期，推动线上商业全球化。  金融市场：          交易所与托管：HSM、多签与 MPC 提升资产安全；      衍生品与预言机：签名与可验证数据输入降低对手方风险；      监管科技（RegTech）：可验证日志与选择性披露支持合规审计。        数据要素：          同态加密与多方安全计算（MPC）实现“可用不可见”，构建数据交易信任；      零知识 KYC/AML：证明“满足规则而不暴露隐私”，平衡隐私与合规。        实体经济：物联网与供应链使用硬件根信任（TPM/TEE）、签名与时间戳追溯真伪与责任。6. 风险与误区  脆弱实现：随机数偏差、侧信道攻击、时间侧道、重放与降级攻击。  过度依赖：密码学保证计算层可信，但无法替代法律治理与物理世界的安全控制。  算法寿命：量子威胁下的后量子密码（PQC）迁移成本不可忽视（NIST 标准化进行中）。7. 工程与治理建议  工程侧：          使用经过审计与广泛部署的库（OpenSSL、libsodium、BoringSSL），禁止自研原语；      默认启用 AEAD 与前向保密（ECDHE）；      秘密管理采用 HSM、KMS 或至少硬件隔离，轮换与分权控制。        治理侧：          建立数据最小化与零知识披露策略；      引入“加密账本 + 传统审计”混合治理，提升可追溯与合规性；      制定 PQC 迁移路线图与兼容测试。      8. 小结密码学已经从“保密术”成长为经济基础设施：它定义了我们如何签名、结算、定价风险与进行跨主体协同。在 Web3 语境下，密码学进一步承担了“可验证规则”的角色。理解其历史、原语与应用边界，是构建可靠数字经济系统的前提。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/java/2017/05/21/Java-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E4%BB%8ELock%E5%88%B0AQS.html",
    "title": "Java 并发编程：从 Lock 到 AQS",
    "content": "并发编程里，“锁”是跨线程协调和内存可见性的核心抽象。本文从 Java 对象头与锁位开始，系统梳理锁信息的存放位置、synchronized 与 Lock/AQS 的实现原理、CAS 的内存语义与常见陷阱，并从 x86/ARM 的汇编视角出发，解释 HotSpot 在不同平台上的底层逻辑。最后给出工程实践的选型建议与调优要点。1. Java 对象、对象头与锁位HotSpot 中对象的内存布局通常包含三段：  对象头（Header）：包含 Mark Word 和 Klass Pointer；数组对象还包含数组长度。  实例数据（Instance Data）：各字段的实际存储。  对齐填充（Padding）：保证对象按 8 字节对齐。1.1 Mark Word 与锁信息Mark Word 是一个会随对象状态复用的位段（32/64 位 JVM 分别是 32/64 位；在 64 位下如果启用指针压缩，Klass Pointer 为 32 位）：  无锁：存放对象哈希（identity hash code）、GC Age 等。  偏向锁：存放偏向线程 ID、Epoch、Age 等。  轻量级锁：存放指向线程栈上“锁记录（Lock Record）”的指针（Displaced Header）。  重量级锁：存放指向 Monitor（对象监视器）的指针。锁标志位（lock bits）与偏向标志位（biased bit）共同决定 Mark Word 当前的语义。需要注意：  一旦对象计算过 identity hash code（如调用过 System.identityHashCode，或对象参与了基于哈希的容器），Mark Word 需要存放 hash，偏向锁将无法使用（会导致偏向撤销或直接进入轻量级/重量级路径）。  锁状态是“可升级、不可降级”的：无锁 → 偏向 → 轻量级 → 重量级。1.2 JDK 版本对偏向锁的影响  JDK 6～8：偏向锁默认启用（可通过 -XX:-UseBiasedLocking 关闭）。  JDK 15：根据 JEP 374，偏向锁被默认禁用并标记为废弃。  JDK 18 起：HotSpot 中移除了偏向锁实现（仅保留语义历史说明）。工程上撰写面向“现代 JDK（11/17/21 LTS 及以上）”的代码时，可不再依赖偏向锁的收益模型，更多关注轻量级/重量级路径与锁粗细粒度的取舍。2. synchronized 的状态流转与 Monitorsynchronized 基于对象监视器（Monitor）实现。HotSpot 会根据竞争情况在不同状态间切换：1) 无锁：进入同步块首次尝试；2) 轻量级锁：线程在自己的栈帧创建“锁记录”，用 CAS 将对象头替换为指向锁记录的指针；3) 自旋：竞争不重时短暂自旋等待可避免阻塞开销；4) 重量级锁：自旋失败或竞争激烈时膨胀为 Monitor，失败线程进入阻塞，等待 unpark/notify 唤醒。Monitor 内部有两个队列概念：  入口队列（EntryList）：在 synchronized 入口处等待获取锁的线程。  WaitSet：调用 Object.wait() 释放锁并等待条件的线程集合，被 notify/notifyAll 转移回 EntryList。现代 HotSpot 中，阻塞/唤醒通常经由 Unsafe.park/unpark 实现，底层在 Linux 使用 futex，在 macOS 使用 pthread 条件变量等原语。2.1 轻量级锁细节（Lock Record）轻量级锁是“乐观地假设不存在并发”。流程：1) 将对象头的 Mark Word 复制到线程栈的锁记录。2) 使用 CAS 将对象头替换为指向锁记录的指针。3) 成功即获得锁；失败说明存在竞争，进入自旋或膨胀。4) 解锁时尝试用 CAS 将对象头还原为锁记录中保存的 Displaced Header；失败则说明发生竞争，转重量级解锁路径。轻量级锁的优势是在“短临界区、低冲突”场景下显著减少阻塞/唤醒的系统开销。3. 从 CAS 谈起：原理、内存语义与陷阱CAS（Compare-And-Swap/Exchange）是硬件提供的原子读-改-写指令族。以三元组 (V, A, B) 描述：当且仅当 V==A 时，将 V 置为 B；否则失败。Java 中的 CAS 主要通过 Unsafe/VarHandle 暴露：// Java 9+ VarHandle 示例class Counter {  private volatile int value;  private static final VarHandle VH;  static {    try {      VH = MethodHandles.lookup()          .in(Counter.class)          .findVarHandle(Counter.class, \"value\", int.class);    } catch (Exception e) { throw new Error(e); }  }  public int increment() {    int prev;    do {      prev = (int) VH.getVolatile(this);    } while (!VH.compareAndSet(this, prev, prev + 1));    return prev + 1;  }}3.1 内存语义不同于“互斥”，CAS 主要提供“原子性 + 指定的有序性”。HotSpot 在不同平台下映射为：  x86（TSO）：天然提供较强顺序性，LOCK CMPXCHG 隐含 acquire-release 语义；必要时配合 LFENCE/SFENCE/MFENCE。  ARMv8：使用 LL/SC 族指令 LDAXR/STLXR（带 acquire/release 语义）与 DMB ish 栅栏保证有序性。Java 语言层面，volatile 写具有“release”语义，读具有“acquire”语义；CAS 通常等价于“读-改-写的原子性 + acquire-release”。这保证了临界区内写入对随后持有同一变量可见。3.2 ABA 问题与对策CAS 的经典陷阱是 ABA：值从 A→B→A，单次 CAS 无法察觉变化。对策包括：  版本戳（如 AtomicStampedReference）、标记指针（AtomicMarkableReference）。  结构性约束（避免重用节点）、配合 GC 的安全点检查降低风险。3.3 多变量一致性CAS 天然只能覆盖单内存位置。多字段一致性可用：  粗粒度互斥（单锁包裹），简单可靠；  组合状态编码（如将两字段打包到 64 位 long）；  STM/事务日志（较重，工程中少见）。4. Lock 与 AQS：CLH 队列、独占/共享与条件队列AQS（AbstractQueuedSynchronizer）是 ReentrantLock、Semaphore、CountDownLatch、ReentrantReadWriteLock、StampedLock（部分实现）等的基础设施。其核心是：  一个 int state 表示同步状态（独占/共享语义由子类定义）；  一个基于 CLH 的双向 FIFO 同步队列，失败线程入队并 park；  成功释放时按队头顺序 unpark，维持有界公平性。4.1 独占与共享  独占（Exclusive）：如 ReentrantLock。tryAcquire/tryRelease 由子类实现；重入通过把 state 作为重入计数。  共享（Shared）：如 Semaphore、CountDownLatch。共享获取可同时唤醒多个等待者。4.2 公平 vs 非公平Lock fair = new ReentrantLock(true);Lock unf  = new ReentrantLock(false);  公平：严格遵循队列顺序，等待时间方差小，但吞吐稍低；  非公平：允许插队（tryAcquire 先试一次），吞吐更高，极端情况下存在饥饿风险。4.3 条件队列（Condition）ConditionObject 为每个条件维护独立等待队列：  await()：原子地释放主锁、入条件队列并 park；  signal()：将条件队列的首节点转移回同步队列，等待重新竞争主锁。4.4 AQS 获取/释放（独占）骨架1) 快路径：CAS 修改 state 成功直接获得；2) 失败入队：按 CLH 入同步队列，park 自己；3) 被前驱释放 unpark 后，竞争重试；4) 释放：tryRelease 成功则唤醒后继。5. 平台与汇编视角：x86 与 ARM 的差异5.1 x86（TSO）  原子指令：LOCK XCHG/CMPXCHG/ADD 等，LOCK 前缀保证跨核原子性与缓存一致性协议的正确传播。  自旋优化：热点代码会插入 PAUSE（rep; nop）降低功耗与总线竞争。  内存模型：TSO 比 Java 的 JMM 更强，编译器仍需在 volatile/CAS 周边插入恰当屏障以维持 JMM 语义。5.2 ARMv8（弱内存序）  LL/SC：LDXR/STXR，带 acquire/release 版本 LDAXR/STLXR；失败返回标志，需循环重试。  内存屏障：DMB ish/DSB/ISB 控制可见性与排序。  Java 映射：VarHandle 的 acquire/release 泛化到上述指令与屏障组合。6. 不同锁形态的应用场景与选型  synchronized：          优点：语法简单，异常安全，JIT 内联友好；JDK 近年大量优化，开销显著下降。      适用：绝大多数互斥场景，特别是短临界区、低到中等竞争强度。        ReentrantLock：          优点：可中断、可定时、可选公平，配 Condition 多条件队列，诊断性更强。      适用：                  需要可中断获取（避免死等 IO）；          需要定时超时放弃；          需要多个条件队列；          需要公平策略限制尾延时。                      ReentrantReadWriteLock：          读多写少、读路径可并行；注意“读锁降级、写锁升级”的语义与死锁风险。        StampedLock：          乐观读避免锁竞态下的写者阻塞；需要二次校验，且不支持重入/条件队列，使用门槛更高。        CAS/无锁结构：          原子类（Atomic*）、LongAdder/LongAccumulator（热点分散）在高并发计数上优于单点 CAS；      适用读多写少或对延迟极敏感的路径；需警惕 ABA 与活锁，必要时退避回退或限次自旋转阻塞。      7. 性能与可见性：几个常见问题  自旋与阻塞的取舍：          临界区短、竞争偶发：倾向自旋（轻量级锁）；      临界区长、竞争激烈：尽快阻塞，减少 CPU 浪费与抖动（重量级路径/AQS 直接 park）。        假共享（False Sharing）：          计数热点应使用 LongAdder 或通过 @jdk.internal.vm.annotation.Contended（或手工填充）隔离写热点，避免不同核心在同一 cache line 争用。        粗细粒度：          业务上首先拆分为“无共享”的并行单元；无法拆分时，优先读写分离、分段锁/哈希分片；确需全局一致时再集中化。        可见性与发布：          共享数据通过 volatile/CAS/锁保护发布；避免未初始化对象逸出；      使用 final 字段保证构造后安全发布的不可变性。      8. 代码片段与基准示例8.1 synchronized 与 ReentrantLock 对比// synchronized 版class CounterS {  private int x;  public synchronized void inc() { x++; }  public synchronized int get() { return x; }}// ReentrantLock 版（可中断/可定时）class CounterL {  private final ReentrantLock lock = new ReentrantLock();  private int x;  public void inc() {    lock.lock();    try { x++; } finally { lock.unlock(); }  }  public int get() {    lock.lock();    try { return x; } finally { lock.unlock(); }  }}8.2 LongAdder 抗热点计数LongAdder adder = new LongAdder();// 并发线程直接 add，内部分片累加，读时汇总adder.add(1);long sum = adder.sum();8.3 读写锁与条件队列class RWCache&lt;K,V&gt; {  private final ReentrantReadWriteLock rw = new ReentrantReadWriteLock();  private final Map&lt;K,V&gt; map = new HashMap&lt;&gt;();  public V get(K k){    rw.readLock().lock();    try { return map.get(k);} finally { rw.readLock().unlock(); }  }  public void put(K k, V v){    rw.writeLock().lock();    try { map.put(k, v);} finally { rw.writeLock().unlock(); }  }}9. 调优与诊断建议  观测与基准：          JFR（Java Flight Recorder）采集阻塞/等待事件（Java Monitor Blocked、Thread Park）。      Async-profiler 观察 CPU 自旋热点、Unsafe.park 栈分布。      微基准使用 JMH，控制预热、线程数与绑定策略（pin 线程）。        编译与运行参数（按需验证，不做一刀切）：          -XX:+UseSpinWait：在部分 CPU 上更友好的自旋指令（如插入 PAUSE）。      -XX:PreBlockSpin（旧参数，现代 JDK 多已调整）：阻塞前自旋次数。      公平锁仅在尾延迟敏感时启用，常规吞吐优先用非公平。        架构相关注意：          x86 上一般更容易获得稳定低抖动的 CAS 行为；      ARM 上注意弱内存序引入的可见性问题，尽量通过 volatile/VarHandle 语义化实现并行算法。      10. 关键要点回顾  锁信息存放在对象头的 Mark Word 中，随状态复用位段：无锁/轻量级/重量级（偏向锁在新 JDK 中已禁用/移除）。  CAS 是无锁算法基石，提供原子性与 acquire-release 有序性，但需防范 ABA、活锁与高冲突热点。  AQS 以 CLH 队列串联失败线程，统一提供独占/共享与条件队列，支撑 ReentrantLock/Semaphore/CountDownLatch 等。  x86 与 ARM 的实现差异主要体现在原子指令与内存屏障上，JVM 屏蔽了差异以兑现 JMM 语义。  工程选型优先简单与稳定：能用 synchronized 就别过早引入复杂锁；计数热点用 LongAdder；高争用尽量结构化拆分，而不是盲目自旋。附：进一步阅读  Java Language Specification（JLS）与 Java Memory Model（JMM）章节  Doug Lea：AQS 源码与论文  OpenJDK JEP 374：Disable and deprecate biased locking（JDK 15）  Java Concurrency in Practice（JCIP）11. JIT 与锁优化：逃逸分析、锁消除、锁粗化  逃逸分析（Escape Analysis）：JIT 判断对象是否只在当前线程可见。若“未逃逸”，可进行标量替换、栈上分配，并消除不必要的同步。  锁消除（Lock Elision）：当 JIT 确认同步对象只在单线程上下文使用时，移除 synchronized/轻量级锁操作。  锁粗化（Lock Coarsening）：当热点循环中频繁短暂加解锁时，JIT 会把多次锁合并到更外层，降低加解锁频率与内存屏障开销。  自适应自旋（Adaptive Spinning）：JVM 依据历史竞争状况与持锁线程运行状态动态调整自旋时长（结合 park 切换），避免盲目自旋或过早阻塞。工程建议：  不要刻意将很多微小操作拆成多个极短的同步块，给 JIT 锁粗化留下空间；  热路径上的锁对象尽量局部化，利于逃逸分析与消除。12. AQS 的 Node 与 waitStatus 详解AQS 同步队列是双向链表（近似 CLH 的变体），核心节点字段：static final class Node {  // 等待状态：  //  1 CANCELLED（已取消）  // -1 SIGNAL（前驱释放时需要唤醒本节点）  // -2 CONDITION（在条件队列中）  // -3 PROPAGATE（共享模式传播）  volatile int waitStatus;  volatile Node prev, next;  volatile Thread thread;  // 标记独占/共享模式  static final Node SHARED = new Node();  static final Node EXCLUSIVE = null;}关键机制：  失败线程 CAS 入队，前驱的 waitStatus 置为 SIGNAL，当前驱释放时 unpark 后继；  取消（超时/中断）节点会被链路跳过，保持队列健康；  共享模式释放时使用 PROPAGATE 以继续唤醒后继共享获取者（如 Semaphore）。13. JMM 内存屏障与 happens-before 速查  程序次序规则：同一线程内，语句按程序顺序 hb。  监视器锁：解锁 hb 于后续对同一锁的加锁。  volatile：对同一变量的写 hb 于后续读。  线程启动：Thread.start() 之前的操作 hb 于 run() 内。  线程终止：线程内操作 hb 于检测到其终止（join/isAlive 返回 false）。  中断：interrupt() 先行于被中断线程检测到中断（isInterrupted/InterruptedException）。  final 字段：构造函数对 final 字段的写 hb 于其他线程看到该对象引用后的读。内存屏障类别（抽象到硬件）：  LoadLoad, LoadStore, StoreStore, StoreLoad（其中 StoreLoad 最强，常在释放-获取边界上出现）。14. 常见并发坑与对策  双重检查锁（DCL）缺 volatile：实例引用未发布完全可见，务必对实例引用使用 volatile 或改用静态初始化。  锁顺序不一致导致死锁：为多资源加锁规定全局顺序，或使用 tryLock 带超时与回退策略。  条件丢失与虚假唤醒：await() 后必须用 while 重新检查条件，不要用 if。  吞掉中断：捕获 InterruptedException 后应恢复中断位或按语义处理，避免“中断失效”。  读写混用容器：高并发下不要在无保护的 ArrayList/HashMap 上写入；使用并发容器或外部锁。  误用 notify()：多条件/多消费者模型优先用 Condition，或使用 notifyAll() 的同时配合条件判断。15. 基准与测试建议  JMH 微基准：          使用 @State 控制共享程度；      充分预热（@Warmup）与多次迭代（@Measurement）；      使用 Blackhole 消除 DCE；      设定不同的并发度（@Threads）和绑定策略（避免线程迁移）。        生产观测：          打开 JFR 事件（Monitor Blocked、Thread Park、Java Monitor Wait）；      使用 async-profiler 结合 -e lock/-e cpu 观察竞争与自旋热点；      采集等待时间分布（P50/P95/P99）而非仅均值。      16. OS 原语映射与实现细节  Linux：park/unpark → futex(FUTEX_WAIT/FUTEX_WAKE)；内核调度与优先级反转可能影响尾延迟（Java 层无优先级继承）。  macOS：基于 pthread 互斥量/条件变量；休眠/唤醒路径与时钟源会影响超时精度。  Windows：现代实现可映射到 WaitOnAddress/Slim Reader-Writer（SRW）等原语。结论：不同 OS 的调度策略与时钟、唤醒延迟差异会影响 AQS/Monitor 的尾延迟特征，服务端 SLO 设计需留冗余。17. 选型与落地清单（Checklist）  同步原语选择：          首选 synchronized，需要可中断/多条件/定时再用 ReentrantLock；      读多写少：ReentrantReadWriteLock 或 StampedLock（谨慎使用）；      计数热点：LongAdder 优于单点 AtomicLong；      信号量/门闩：Semaphore/CountDownLatch，或升级 Phaser。        结构性优化：          尽量无共享或分片（sharding）；      降低持锁时间（IO/阻塞移出临界区）；      缓存与批处理减少锁竞争频率。        诊断运维：          监控阻塞时长与争用次数；      采集线程栈与锁持有者；      压测覆盖极端并发与抖动场景。      "
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/java/2017/04/09/Java-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E4%B8%8ESPI%E6%9C%BA%E5%88%B6%E5%AE%9E%E8%B7%B5.html",
    "title": "Java 类加载器与 SPI 机制实践",
    "content": "本文系统梳理 Java 虚拟机的类加载流程、双亲委派模型与命名空间隔离，深入解析 SPI（Service Provider Interface）在容器与插件化架构中的使用要点与常见坑，并结合字节码增强与 Java Agent 的实践串联起类加载与运行期增强这一条主线，帮助你在工程中进行正确的架构取舍与问题诊断。0. 你为什么需要关心类加载与 SPI  定位复杂 ClassNotFoundException / NoSuchMethodError / LinkageError：多数与类加载边界和版本冲突相关。  搭建插件化平台与多租户隔离：自定义 ClassLoader 能在一进程内提供清晰的依赖边界与热插拔能力。  正确使用 SPI、JDBC、JNDI、日志门面：都依赖 ServiceLoader + 线程上下文类加载器（TCCL）。  运行期增强与诊断：AOP、性能探针、日志埋点、线上热修复都离不开字节码增强与 Java Agent。1. JVM 类加载全流程与命名空间JVM 将一个 .class 从“字节序列”变为可执行的类元数据，经历如下阶段：1) 加载（Loading）  读取字节流，形成 Class 对象的初始结构，确定其“定义加载器”（Defining ClassLoader）。2) 链接（Linking）  验证（Verification）：字节码结构合法性与安全检查。  准备（Preparation）：为静态字段分配内存并设零值。  解析（Resolution）：将符号引用解析为直接引用（可能懒解析）。3) 初始化（Initialization）  执行 &lt;clinit&gt; 静态初始化块，真正赋初值，保证线程安全一次性执行。类由某个 ClassLoader 定义后会进入该加载器的“命名空间”。同名类在不同命名空间是“不同的类”，这也是很多跨 ClassLoader 转型失败、方法找不到的根源。1.1 双亲委派模型（Parent Delegation）标准的类加载器层次：  Bootstrap ClassLoader（C/C++ 实现，加载核心类库）  Platform/Extension ClassLoader（加载平台扩展）  Application ClassLoader（加载应用 classpath）  自定义 ClassLoader（可作为子层）委派过程：loadClass 先委派给父加载器；父找不到（抛 ClassNotFoundException）才回落到子加载器自己加载。优势：  安全：防止用户代码伪造 java.lang.* 等核心类。  共享：上层定义一次，全局共享，减少重复加载与内存浪费。什么时候“打破”或“变形”委派：  容器隔离与热部署：如 Tomcat、OSGi、插件化框架会采用“先本地后父类”或双亲/并行策略以实现隔离与覆盖。  SPI 与 TCCL：JDK 某些 API 通过“线程上下文类加载器”来绕过严格的父委派边界。1.2 Class 等价性与常见异常  同名类如果由不同 ClassLoader 定义，则 clazzA != clazzB，即使字节码完全相同。  典型异常：          ClassCastException: X cannot be cast to X（两个 X 来自不同加载器）；      NoSuchMethodError/NoSuchFieldError（版本不一致）；      LinkageError: loader constraint violation（同名类被不同加载器以不同版本解析）。      工程建议：跨边界交互使用稳定的“数据结构或接口”包由公共上层加载器定义；不同插件内部类不外泄。2. 自定义 ClassLoader：隔离、覆盖与热插拔典型目标：  为每个业务域/插件创建独立的依赖边界（避免 jar 冲突）。  支持插件卸载与升级（释放旧 ClassLoader，让类与资源可被 GC 回收）。最小可用实现思路：public class IsolatedClassLoader extends ClassLoader {  private final Map&lt;String, byte[]&gt; classNameToBytes;  public IsolatedClassLoader(Map&lt;String, byte[]&gt; classNameToBytes, ClassLoader parent) {    super(parent);    this.classNameToBytes = classNameToBytes;  }  @Override  protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException {    byte[] bytes = classNameToBytes.get(name);    if (bytes == null) throw new ClassNotFoundException(name);    return defineClass(name, bytes, 0, bytes.length);  }}说明：  仅覆盖 findClass，仍保留“父优先”委派，以保证核心类安全。  需要自管资源获取与依赖链；若要“先本地后父类”，可在 loadClass 中调整策略，但务必限制可覆盖的包前缀（如只允许 com.example.plugins.*）。释放资源：卸载插件时断开对 ClassLoader 的所有强引用（包括线程、定时器、缓存、ThreadLocal、JNI 句柄等），否则类与字节码无法回收。3. SPI（Service Provider Interface）原理与实战SPI 的核心在于“调用方依赖接口，运行期按需装配实现”。JDK 提供 java.util.ServiceLoader，通过读取 META-INF/services/&lt;接口全名&gt; 文件完成发现。3.1 基本使用文件布局：  接口：com.example.spi.Storage  实现类：com.example.spi.impl.LocalStorage, com.example.spi.impl.S3Storage  声明文件：META-INF/services/com.example.spi.Storage          内容：                  com.example.spi.impl.LocalStorage          com.example.spi.impl.S3Storage                    代码：public interface Storage { void write(String key, byte[] data); }ServiceLoader&lt;Storage&gt; loader = ServiceLoader.load(Storage.class);for (Storage s : loader) {  s.write(\"k\", new byte[0]);}工作机制：  ServiceLoader 默认使用当前线程的 TCCL（Thread.currentThread().getContextClassLoader()）读取 META-INF/services。  若 TCCL 为空，则回退到 ServiceLoader 自身的加载器。3.2 容器与多 ClassLoader 环境的坑  在应用服务器、微服务框架、插件系统中，接口与实现往往位于不同加载器。若 TCCL 未指向“实现所在加载器”，会出现找不到实现的情况。  解决：在调用前设置合适的 TCCL，或使用 ServiceLoader.load(接口, 实现所在的ClassLoader) 显式指定。ClassLoader implLoader = pluginClassLoader; // 实现所在加载器ServiceLoader&lt;Storage&gt; loader = ServiceLoader.load(Storage.class, implLoader);常见依赖 SPI 的组件：JDBC 驱动加载、JUL Logging, JAXP, JSON-B/JSON-P、JCA、JDBC-URL 自动发现、SLF4J 的服务桥接等。排查相关问题时优先检查 TCCL 与 META-INF/services。3.3 与模块化（JPMS/OSGi）的关系  JPMS：在 module-info.java 中通过 uses/provides ... with ... 显式声明服务使用与提供；跨模块访问受导出规则约束。  OSGi：每个 Bundle 本质是独立 ClassLoader，导出/导入包决定可见性。SPI 文件通常需要打包到导出的资源路径，并确保上下文加载器在正确的 Bundle。工程建议：  为公共接口单独建“API 模块”由上层加载器加载；实现各自打包并在需要时通过 SPI 或容器注册方式装配。  避免将实现类泄漏到 API 包或公共加载器，减少“二义性解析”。4. 从 AOP 到字节码增强：把“加载时”与“运行时”串起来动态代理与 AOP 是“增强”的入口：  JDK 代理基于接口；CGLIB 基于子类；都属于“对象层”的拦截。  字节码增强则直接在“类定义层”改写方法体或插桩，覆盖更广（无接口限制）且可零侵入接入现有代码。增强的时间点：  编译期：借助 javac 插件或 Gradle/Maven 插件处理字节码（如 Lombok、MapStruct）。  加载期：通过 Instrumentation 的 ClassFileTransformer 在类被 JVM 定义前改写；  运行期：Attach 到目标 JVM，retransform/redefine 已加载类。常用类库与对比：  ASM：指令级 API，最灵活也最底层，性能最好，学习曲线陡峭。  Javassist：以“源码字符串/表达式”方式组装，易用性高，适合快速原型。  Byte Buddy：类型安全的 Fluent API，生态完善（与 Agent、Mockito、Android 兼容性好）。5. Java Agent 实战速览（加载期与运行期）5.1 预主代理（premain）：随进程启动MANIFEST.MF：Premain-Class: com.example.agent.DemoAgentCan-Redefine-Classes: trueCan-Retransform-Classes: trueAgent：public class DemoAgent {  public static void premain(String args, Instrumentation inst) {    inst.addTransformer(new TimingTransformer(), true);  }}Transformer（以 Byte Buddy 为例）：public class TimingTransformer implements ClassFileTransformer {  @Override  public byte[] transform(Module module, ClassLoader loader, String className,                          Class&lt;?&gt; classBeingRedefined, ProtectionDomain pd,                          byte[] classfileBuffer) {    if (className == null || !className.startsWith(\"com/example/service/\")) return null;    // 使用 ASM/Javassist/Byte Buddy 改写方法体，插入计时代码    // 返回新的字节码；返回 null 表示不改写    return enhance(classfileBuffer);  }}启动：java -javaagent:demo-agent.jar -jar app.jar5.2 运行期 Attach：无重启注入MANIFEST.MF：Agent-Class: com.example.agent.DemoAgentCan-Redefine-Classes: trueCan-Retransform-Classes: trueAgent：public class DemoAgent {  public static void agentmain(String args, Instrumentation inst) {    inst.addTransformer(new TimingTransformer(), true);    for (Class&lt;?&gt; c : inst.getAllLoadedClasses()) {      if (c.getName().startsWith(\"com.example.service\")) {        try { inst.retransformClasses(c); } catch (Exception ignore) {}      }    }  }}Attach 到目标进程：VirtualMachine vm = VirtualMachine.attach(\"&lt;pid&gt;\");vm.loadAgent(\"/path/demo-agent.jar\");vm.detach();要点与限制：  redefine/retransform 不能随意更改已加载类的结构（如新增/删除字段、方法签名变化），通常仅能改写方法体。  性能与稳定性优先：过滤目标类与方法范围；避免在 Transformer 中做 I/O 或重计算。  安全与合规：生产注入需严格审批与审计；避免收集敏感数据；为回滚预留“撤销增强”的能力。实践场景：  无侵入埋点与链路追踪、慢调用采样、SQL/HTTP 出入口观测。  线上紧急诊断（打印入参/返回值/堆栈）、热点修复（谨慎使用）。  框架级特性（如 Spring AOP、ORM 懒加载）背后常用到字节码增强。6. 将类加载、SPI 与 Agent 串成一条“工程实践链”面对实际系统时，可以按以下 checklist 设计与排错：  类加载边界          定义“API 包”（接口与 DTO）由上层加载器加载；实现各自位于独立 ClassLoader；      插件只暴露接口，避免对外泄漏实现类；      谨慎采用“先本地后父类”的策略，并限制可覆盖包前缀；        SPI 装配          确保 META-INF/services/&lt;接口全名&gt; 存在且内容正确；      在容器/插件环境中使用正确的 TCCL 或显式传入实现加载器；      对多实现场景，建立可配置的选择策略（优先级、条件加载）；        诊断与增强          开发态：使用 Byte Buddy/Javassist 快速验证增强点；      生产态：以 Agent 注入，限定类集合，提供开关与回滚；      记录增强带来的额外开销，建立 SLO 告警；      7. 常见问题速查  为什么 ServiceLoader 在本地能找到实现，部署到容器后找不到？          检查 TCCL 是否指向实现所在加载器；容器可能切换线程或包裹执行；显式使用 ServiceLoader.load(接口, 加载器)。        X cannot be cast to X 但类名完全相同？          两个 X 分别由不同 ClassLoader 定义。收敛公共类型到 API 包；跨边界仅传递接口或数据类。        引入 Agent 后偶发死锁/卡顿？          Transformer 中做了 I/O/日志锁争用；或改写引入了同步膨胀。减少锁、避开热点方法、加采样率。        能否在运行期给类“加字段/加方法”？          受限于 JVM 的 redefinition 能力，一般不可以；需通过“旁路存储”（ConcurrentHashMap&lt;Class&lt;?&gt;, Data&gt;）、invokedynamic 或“代理包装”规避。      8. 结语类加载与 SPI 决定了“模块如何被看见与装配”，字节码增强与 Agent 决定了“模块在运行期如何被观测与改变”。把二者打通，既能写出可演化、可观测的系统，也能在复杂运行环境中快速定位问题、降低故障恢复时间（MTTR）。参考与延伸阅读  The Java Virtual Machine Specification（ClassFile 与指令集）  Byte Buddy、ASM、Javassist 官方文档  JDK java.util.ServiceLoader 源码与 META-INF/services 约定"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/nginx/2017/02/13/Nginx-%E8%BF%9E%E6%8E%A5%E5%A4%8D%E7%94%A8%E4%B8%8E%E5%9B%9B%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.html",
    "title": "Nginx 连接复用与四层负载均衡",
    "content": "对比四层（stream）与七层（http）转发，从操作系统并发与 I/O 机制出发系统性说明：Nginx 的网络设计、连接复用原理与 Linux 内核调优，并附可执行配置与观测建议。1. 从操作系统角度看网络并发模型高并发网络服务的核心是“如何在有限 CPU/内存下同时处理大量连接”。关键是并发模型与 I/O 机制：  进程/线程模型：每连接一个进程/线程，易编程，但上下文切换与栈内存开销在 1k～10k 连接下迅速放大。  事件驱动模型（Reactor/Proactor）：少量线程管理海量非阻塞 fd，依赖内核事件通知。内核 I/O 通知机制：  select/poll：线性扫描，fd 数/开销受限，不适合高并发。  epoll（Linux）：O(1) 监听大量 fd，边缘/水平触发，EPOLLEXCLUSIVE 降低惊群。  kqueue（BSD/macOS）：高效通用事件队列。  IO_uring（Linux 新）：提交/完成队列，绕过部分系统调用开销；Nginx 主线仍以 epoll 为主。Reactor vs Proactor：Nginx 采用 Reactor（事件到来再发起 read/write），Windows 下的 IOCP 更接近 Proactor。常见瓶颈点：  fd 限制（ulimit -n、worker_rlimit_nofile、fs.file-max）。  监听/握手队列（somaxconn、tcp_max_syn_backlog、SYN flood）。  收发队列与网卡（netdev_max_backlog、RPS/RFS/XPS、队列/中断亲和）。  拥塞控制与队列管理（BBR、fq、TFO）。2. Nginx 的网络设计模型Nginx 采用 master + 多 worker 的事件驱动架构：  master：管理配置、热重载、worker 生命周期。  worker：每个 worker 一个事件循环，使用 epoll/kqueue 管理大量非阻塞连接；worker_processes auto; 通常与 CPU 核数一致。  连接与请求分离：一个连接可承载多个请求（HTTP/1.1 keepalive、HTTP/2 多路复用）。  accept 协调：accept_mutex 避免惊群；或 reuseport 让每个 worker 拥有独立监听套接字。  零拷贝与发送优化：sendfile、tcp_nopush、tcp_nodelay、aio threads。事件与监听示例：worker_processes  auto;worker_rlimit_nofile  1048576;events {  use epoll;               # Linux 下优先 epoll；macOS/FreeBSD 为 kqueue  worker_connections 65535;  multi_accept on;  # accept_mutex on;      # 与 reuseport 二选一}server {  listen 80 reuseport backlog=65535;  # listen 443 ssl http2 reuseport fastopen=512;}3. 连接复用：客户端、Nginx 与上游目标：减少握手与 TLS 开销、降低 TIME_WAIT 与端口消耗、提升吞吐。  客户端-&gt;Nginx：          HTTP/1.1 keepalive 串行复用      HTTP/2 多路复用并发流      HTTP/3（QUIC）在 UDP 上实现多路复用与 0-RTT        Nginx-&gt;上游：          upstream keepalive 将代理到上游的连接复用，显著降低后端握手压力      连接池为“每 worker 独立”，容量需乘以 worker 数      HTTP/1.1 与上游 keepalive：http {  upstream api_backend {    server 10.0.0.2:8080 max_fails=2 fail_timeout=10s;    keepalive 256;  # 每 worker 空闲长连接上限  }  server {    listen 80 reuseport backlog=65535;    keepalive_requests 10000;    keepalive_timeout  75s;    location / {      proxy_http_version 1.1;      proxy_set_header Connection \"\";      proxy_set_header Host $host;      proxy_connect_timeout 5s;      proxy_send_timeout    30s;      proxy_read_timeout    30s;      proxy_pass http://api_backend;    }  }}四层（stream）与上游：stream {  upstream mysql_backend {    server 10.0.0.1:3306 max_fails=2 fail_timeout=10s;  }  server {    listen 3306 reuseport backlog=32768;    proxy_connect_timeout 3s;    proxy_timeout        30s;    proxy_pass mysql_backend;  }}取舍提示：  上游存在会话亲和或连接态时，需配合一致性哈希/粘性策略，避免跨请求状态泄漏。  短连接/突发场景不宜给过大 keepalive 池，避免端口/内存占用。  数据库协议建议交由专业代理（ProxySQL、pgbouncer）做更精细的连接池与语句复用。    stream {upstream mysql_backend { server 10.0.0.1:3306 max_fails=2 fail_timeout=10s; }server { listen 3306; proxy_pass mysql_backend; }}      4. Linux 内核网络优化推荐基线（按环境渐进验证）：# /etc/sysctl.d/99-nginx-tuning.confnet.core.somaxconn = 65535net.core.netdev_max_backlog = 250000net.ipv4.tcp_max_syn_backlog = 65535net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syncookies = 1net.ipv4.ip_local_port_range = 10000 65000fs.file-max = 2097152net.ipv4.tcp_fin_timeout = 15net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_keepalive_intvl = 30net.ipv4.tcp_keepalive_probes = 5net.core.rmem_max = 134217728net.core.wmem_max = 134217728net.ipv4.tcp_rmem = 4096 87380 134217728net.ipv4.tcp_wmem = 4096 65536 134217728net.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbrnet.ipv4.tcp_fastopen = 3Nginx 侧连接与 fd：worker_rlimit_nofile 1048576;events { worker_connections 65535; }注意事项：  tcp_tw_recycle 已移除，勿用；tcp_tw_reuse 收益有限，勿过度依赖。  过度缩短 tcp_fin_timeout 可致异常断流；以观测为准。  reuseport 与 accept_mutex 二选一；多核下普遍优先 reuseport。  网卡队列/中断亲和等需要硬件与驱动配合，谨慎变更。5. 观测与压测  Nginx：stub_status、$upstream_response_time 分位数、active/reading/writing 分布。  系统：ss -s、ss -ti、sar -n TCP,DEV、ethtool -S、/proc/net/netstat。  压测：wrk（HTTP/1.x）、h2load（HTTP/2/3）、iperf3（链路）。示例：wrk -t8 -c1024 -d60s --latency http://127.0.0.1/h2load -n 100000 -c 200 -m 100 https://127.0.0.1:443/6. 常用配置快照http {  sendfile on;  tcp_nopush on;  tcp_nodelay on;  keepalive_timeout 75s;  keepalive_requests 10000;  upstream api_backend { server 10.0.0.2:8080; keepalive 256; }  server {    listen 80 reuseport backlog=65535;    location / {      proxy_http_version 1.1;      proxy_set_header Connection \"\";      proxy_set_header Host $host;      proxy_pass http://api_backend;    }  }}7. 排错 Checklist  5xx 或 upstream timed out：核查后端与上游连接池、proxy_*_timeout、网络丢包。  连接拒绝或超时：检查 somaxconn/backlog、worker_connections、ss -lnt 中队列与监听状态。  TIME_WAIT/端口耗尽：扩大 ip_local_port_range 与上游 keepalive，排查异常关闭。  吞吐增长受限：核查 sendfile、tcp_nopush、NIC 队列、CPU 亲和与磁盘 I/O。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/php/2016/08/17/PHP-FPM-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%8C%87%E5%8D%97.html",
    "title": "PHP-FPM 性能调优指南",
    "content": "本文系统性梳理 PHP-FPM 在高并发与高性能场景下的完整优化路径：从 Linux 操作系统内核与网络栈、到 Nginx 与 PHP-FPM 的通讯方式与参数调优，再到 PHP 运行时与业务代码层面的最佳实践，并给出生产可落地的配置示例与故障排查清单。目标读者为正在建设或运营中大型 PHP Web 服务的工程师与架构师。读者收益  清晰的容量规划方法与关键监控口径（QPS、P95/P99、错误率、队列长度）；  一套可复用的 Linux 内核与网络栈调优清单；  PHP-FPM pm 模式与核心参数的取舍建议与安全边界；  OPcache/JIT、realpath cache、Composer 自动加载与 APCu 等在生产中的最佳实践；  业务代码性能“十项准则”与常见反模式清单；  标准化配置样例：sysctl、systemd、Nginx、FPM pool 与 OPcache。一、性能目标与测量口径在优化之前，先把“好”的定义固定下来。  指标分层：          应用端：QPS、TP95/TP99 响应时间、错误率、超时率；      资源端：CPU 使用率、上下文切换、内存使用与 page faults、网络丢包/重传、磁盘延时；      PHP-FPM 专属：/status 的 accepted conn、listen queue、idle/active processes、max children reached。        容量评估：          峰值并发估算：通过压测或生产监控得到单位请求平均 CPU 时间与内存峰值；      Little’s Law：( L = \\lambda \\times W )，队列长度与延迟直接相关；      过载保护：在上游（Nginx 或网关）设置合理的连接与请求排队上限，宁可快速失败，避免雪崩。      二、Linux 系统层调优（以现代 Linux 为主）面向 PHP-FPM 的系统调优主要围绕“文件句柄/进程数量”“网络连接队列与吞吐”“内存与 I/O”三个方面展开。2.1 文件句柄与进程限制  系统级：          fs.file-max 与 fs.nr_open 调高总句柄上限；      结合进程数量与连接数，预留 2～3 倍余量。        服务级：使用 systemd 覆盖 PHP-FPM 单元，设置 LimitNOFILE，并确保 TasksMax 足够大。# /etc/systemd/system/php-fpm.service.d/override.conf[Service]LimitNOFILE=1048576TasksMax=infinityDelegate=yessudo systemctl daemon-reloadsudo systemctl restart php-fpm2.2 CPU 与调度  保持 irqbalance 开启，避免中断集中到单核。  大流量场景可考虑为 Nginx 绑定少量核心、FPM 绑定其余核心，减少争用：# /etc/systemd/system/nginx.service.d/cpu.conf[Service]CPUAffinity=0-1# /etc/systemd/system/php-fpm.service.d/cpu.conf[Service]CPUAffinity=2-152.3 内存、THP 与 Swap  关闭或降低 Transparent Huge Pages（THP），避免不可预期的停顿：    echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled        减小 Swap 干预：    sysctl -w vm.swappiness=10        关注 vm.overcommit_memory 与 OOM Killer 行为，容器化场景优先通过 cgroup/容器限制。2.4 网络栈与连接队列  增大 listen backlog 与队列，减少瞬时拥塞丢包：    sysctl -w net.core.somaxconn=65535sysctl -w net.core.netdev_max_backlog=250000sysctl -w net.ipv4.tcp_max_syn_backlog=262144        发送/接收缓冲区与窗口扩展：    sysctl -w net.ipv4.tcp_rmem=\"4096 87380 134217728\"sysctl -w net.ipv4.tcp_wmem=\"4096 65536 134217728\"sysctl -w net.core.rmem_max=134217728sysctl -w net.core.wmem_max=134217728        TIME_WAIT 管理：服务端配合长连接降低 TIME_WAIT 产生；谨慎使用 tcp_tw_reuse（新内核对服务端无效），不要依赖 tcp_tw_recycle（已移除）。  连接安全：确保 net.ipv4.tcp_syncookies=1 开启以应对 SYN flood。建议汇总到 /etc/sysctl.d/99-tuning.conf 并持久化。2.5 磁盘与 I/O  SSD 场景优先 mq-deadline 或 none 调度器；日志分区与数据分区独立；  调整 vm.dirty_background_ratio 与 vm.dirty_ratio 限制脏页冲刷对尾延迟影响。三、Nginx 与 PHP-FPM 通讯拓扑3.1 Unix Socket vs TCP  同机通讯优先 Unix Socket（更低开销），配置更简单；  跨机或容器网络必须使用 TCP；  配置 listen.backlog 与 Nginx fastcgi_connect_timeout/fastcgi_read_timeout 对齐，避免误判超时。3.2 Nginx FastCGI 关键项upstream php_backend {    server unix:/run/php-fpm/www.sock;    # TCP 场景可配置 keepalive，Socket 不需要}server {    location ~ \\.php$ {        include fastcgi_params;        fastcgi_pass   php_backend;        fastcgi_keep_conn on;           # 与 FPM 维持长连接        fastcgi_connect_timeout 1s;        fastcgi_send_timeout 5s;        fastcgi_read_timeout  5s;       # 视业务复杂度调整        fastcgi_buffers 32 32k;        fastcgi_buffer_size 64k;    }}四、PHP-FPM 关键参数与策略FPM 通过 Pool 管理工作进程。核心在 pm 模式与并发容量控制。4.1 pm 模式如何选  pm = static：固定进程数，最可预期，适合高负载稳定流量；  pm = dynamic：基于空闲/繁忙动态伸缩，线上最常见；  pm = ondemand：按请求惰性创建，适合低频/突发场景，冷启动成本较高。4.2 并发容量与内存估算  经验公式：pm.max_children = floor(可用内存 / 单进程RSS峰值)；  实测方法：          开启压测后观察 ps -o pid,rss,cmd -C php-fpm 或 /proc/&lt;pid&gt;/status；      以 P95 RSS 作为保守估计，并预留 15% 以上系统余量；      关注 max children reached，出现即表示进程池耗尽，需要增大 max_children 或优化单请求资源占用。      4.3 池配置示例（www.conf）[www]user = www-datagroup = www-datalisten = /run/php-fpm/www.socklisten.owner = www-datalisten.group = www-datalisten.mode = 0660listen.backlog = 65535pm = dynamicpm.max_children = 128pm.start_servers = 16pm.min_spare_servers = 16pm.max_spare_servers = 64pm.max_requests = 2000          ; 防止内存泄漏或碎片长期累积process_control_timeout = 10srequest_terminate_timeout = 10s ; 兜底中断超时请求request_slowlog_timeout = 3sslowlog = /var/log/php-fpm/slow.logcatch_workers_output = yesphp_admin_value[memory_limit] = 256Mphp_admin_value[error_log] = /var/log/php-fpm/www-error.logphp_admin_flag[log_errors] = on说明：  pm.max_requests 过小会增加进程重启开销，过大难以及时回收泄漏；  合理设置 request_terminate_timeout 与 request_slowlog_timeout，协同 Nginx fastcgi_read_timeout，保证故障可恢复；  多业务隔离：按应用拆分 pool，避免相互影响。4.4 状态页与健康检查pm.status_path = /statusping.path = /pingping.response = pong结合 Nginx 暴露只读管理端点，并以 Prometheus/StatsD 抓取指标。五、PHP 运行时：OPcache、JIT 与路径缓存5.1 OPcache 必备配置（生产）; /etc/php.d/10-opcache.iniopcache.enable=1opcache.enable_cli=0opcache.memory_consumption=256opcache.interned_strings_buffer=16opcache.max_accelerated_files=100000opcache.validate_timestamps=0        ; 生产禁用文件变更检查opcache.revalidate_freq=0opcache.save_comments=1opcache.fast_shutdown=1; 可选：文件缓存，容器内频繁重启时有价值; opcache.file_cache=/var/cache/php-opcache部署发布后务必 reload FPM 或使缓存失效，以加载新字节码。5.2 PHP 8 JIT（谨慎评估）Web I/O 密集型负载对 JIT 的收益有限。若要启用，建议：opcache.jit_buffer_size=64Mopcache.jit=1205   ; tracing JIT，适度激进上线前请通过基准压测与业务真实场景对比，确认稳定性与收益。5.3 realpath 与 include 优化realpath_cache_size=4096krealpath_cache_ttl=600避免在热路径做大量 file_exists()/is_file()，并减少动态 include。生产禁用 allow_url_fopen，降低 I/O 风险。六、业务代码性能最佳实践（FPM 模式）6.1 缓存分层  进程内缓存：APCu 存储热点小对象，适合只读配置/路由表。注意 FPM 进程间不共享；  分布式缓存：Redis/Memcached 缓存热点数据，设置合理过期与一致性策略；  页面与片段缓存：结合 Nginx proxy_cache 或应用内缓存，命中率优先。// APCu 示例：仅适合单进程内命中$key = 'hot_config_v1';$val = apcu_fetch($key, $ok);if (!$ok) {    $val = load_config_from_db();    apcu_store($key, $val, 300);}6.2 数据库与外部依赖  谨慎使用持久连接（PDO persistent），评估连接复用与连接泄漏风险；  统一定义客户端超时、重试与熔断策略，避免阻塞放大；  通过批量查询/写入降低往返（N+1 是性能天敌）。6.3 自动加载与 Composer  生产构建使用 composer dump-autoload -o -a，减少运行时扫描；  避免在热路径中动态组合类名或路径，提升 OPcache 命中效率；  若使用 APCu 优化 Composer autoload，可开启 apcu-autoloader：{  \"config\": {\"apcu-autoloader\": true}}6.4 代码层微优化与反模式  使用 isset($arr['k']) 替代 array_key_exists('k', $arr)；  循环中缓存 count($arr)；  字符串拼接优先 . 而非频繁 sprintf；  避免在热路径调用正则，改用更轻量的字符串函数；  控制异常用作流程分支的频度；  会话：使用 Redis Session，并开启 session.lazy_write=1、session.use_strict_mode=1；  降低全局状态与单例滥用，利于并发安全与测试。6.5 超时、降级与排队  为外部依赖设置严格超时（连接/读写）与预算；  为不可用下游提供读降级或本地兜底；  对突发流量采用限流与排队，保护 FPM 进程池。七、容量规划与发布策略  预估 pm.max_children 依据 P95 RSS 与可用内存，预留系统与 page cache 空间；  滚动发布：先下线流量（Nginx drain/权重降为 0），再 reload FPM，避免中断连接；  弹性扩缩：容器或虚机水平扩展往往优于单机“顶配”。八、监控、压测与故障排查8.1 监控建议  Nginx：请求率、状态码分布、upstream_response_time、队列/连接数；  FPM：/status 指标、max children reached 告警、慢日志采样；  系统：CPU 利用、软中断、上下文切换、TCP 重传/丢包、磁盘延迟；  应用：关键函数耗时分布与火焰图（XHProf/Blackfire/eBPF）。8.2 压测要点  区分冷/热缓存表现；  启用与生产一致的 OPcache/realpath/composer 优化；  采用阶段性压力递增与稳态长跑，观察尾延迟与 GC/重启行为。8.3 常用排查命令ss -lntp | grep php-fpmps -o pid,ppid,rss,pcpu,cmd -C php-fpmtail -f /var/log/php-fpm/www-error.logtail -f /var/log/php-fpm/slow.logjournalctl -u php-fpm -n 200 -fdmesg | egrep -i 'oom|killed'慢日志与火焰图结合能快速定位热点：先用慢日志发现可疑入口，再以火焰图拆解 CPU 时间。九、标准化配置样例9.1 sysctl（/etc/sysctl.d/99-tuning.conf）fs.file-max=2097152net.core.somaxconn=65535net.core.netdev_max_backlog=250000net.ipv4.tcp_max_syn_backlog=262144net.core.rmem_max=134217728net.core.wmem_max=134217728net.ipv4.tcp_rmem=4096 87380 134217728net.ipv4.tcp_wmem=4096 65536 134217728net.ipv4.tcp_syncookies=1vm.swappiness=109.2 systemd（Limit 与 CPU 绑定）[Service]LimitNOFILE=1048576TasksMax=infinityCPUAffinity=2-159.3 Nginx FastCGI 片段fastcgi_connect_timeout 1s;fastcgi_send_timeout 5s;fastcgi_read_timeout 5s;fastcgi_buffers 32 32k;fastcgi_buffer_size 64k;fastcgi_keep_conn on;9.4 FPM Pool 片段pm = dynamicpm.max_children = 128pm.max_requests = 2000request_terminate_timeout = 10srequest_slowlog_timeout = 3sslowlog = /var/log/php-fpm/slow.log9.5 OPcache 建议opcache.enable=1opcache.memory_consumption=256opcache.max_accelerated_files=100000opcache.validate_timestamps=0十、Checklist（上线前自查）  sysctl 已落盘，网络 backlog 与缓冲区放开；  systemd LimitNOFILE/TasksMax 生效；  Nginx 与 FPM backlog、超时与 keepalive 一致；  OPcache 命中率与内存占用达标；  FPM /status 指标健康、无 max children reached 持续告警；  慢日志与火焰图能力就绪；  压测覆盖冷/热缓存，尾延迟达标；  发布采用灰度/滚动，具备快速回滚。结语性能优化从来不是单点参数的“魔法值”，而是一条端到端的工程链路：系统内核提供足够的资源与稳态，Nginx 与 FPM 协同对齐超时与队列，OPcache/自动加载与路径缓存确保运行时轻量，业务代码以缓存为中心并控制外部依赖的不可控性。循着本文的方法论与配置清单，结合你们的业务负载画像与监控数据，才能得到真正可复制、可演进的高性能 PHP-FPM 生产实践。"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/mysql/2016/04/12/MySQL-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E7%83%AD%E7%82%B9%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8FID%E5%AE%9E%E8%B7%B5.html",
    "title": "MySQL 自增主键热点与分布式 ID 实践",
    "content": "在高并发写入场景下，InnoDB 的自增主键（AUTO_INCREMENT）会在聚簇索引上形成尾部写热点，导致插入抖动与间歇性锁等待。本文从 InnoDB 聚簇索引结构、插入缓冲、间隙锁协同等维度拆解热点成因，并给出分布式 ID 的落地实践与权衡。1. 聚簇索引与尾部写热点  InnoDB 的聚簇索引以主键排序存储，AUTO_INCREMENT 会将新记录追加到 B+Tree 右侧叶子。  高并发插入时，右侧叶子页存在锁竞争与页分裂放大，表现为插入 TPS 下降与 P95/P99 波动。CREATE TABLE orders (  id BIGINT PRIMARY KEY AUTO_INCREMENT,  user_id BIGINT NOT NULL,  amount DECIMAL(10,2) NOT NULL,  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,  KEY idx_user (user_id)) ENGINE=InnoDB;2. AUTO_INCREMENT 锁与并发  MySQL 5.7 之前，AUTO_INCREMENT 使用表级锁（不同模式）；8.0 之后改进为持久化计数器与更细粒度控制，但热点依旧存在。  插入批量提交（group commit）可缓解 WAL 压力，但右边界叶子页仍是竞争点。3. 方案对比  雪花算法（Snowflake）：时间戳 + 机房ID + 机器ID + 自增序列，单机内有序，跨机整体趋势递增。  数据库号段（Segment）：业务方一次申请号段，内存发号，落库更新游标，吞吐高但需要容灾与幂等。  Redis INCR：实现简单，单点需高可用（主从/哨兵/集群），序列漂移与冷启动需评估。            方案      顺序性      吞吐      复杂度      依赖                  AUTO_INCREMENT      强      中      低      MySQL              Snowflake      趋势递增      高      中      时钟、节点元数据              号段      趋势递增      极高      中      DB 持久游标              Redis INCR      强      高      低      Redis 可用性      4. 索引与二级索引代价  主键变长（如雪花 ID）会放大二级索引的指针大小（leaf 指向 PK），读放大明显。  建议：保持主键定长 BIGINT，避免 UUID(36) 直接做 PK，可用 BINARY(16) 存储 UUIDv1/v7。5. 可复现实验（sysbench + 尾部热点）# 1) 准备数据与表结构mysql -e \"DROP DATABASE IF EXISTS demo; CREATE DATABASE demo;\"mysql demo &lt; &lt;(cat &lt;&lt;SQLCREATE TABLE t_hot (  id BIGINT PRIMARY KEY AUTO_INCREMENT,  k  BIGINT NOT NULL,  v  VARCHAR(64) NOT NULL,  KEY idx_k(k)) ENGINE=InnoDB;SQL)# 2) 并发插入压测（64 线程，持续 120s）sysbench oltp_insert --mysql-db=demo --table-size=0 \\  --threads=64 --time=120 run# 3) 观察：# - performance_schema.events_waits_summary_global_by_event_name 中的锁等待# - information_schema.INNODB_METRICS 中的页分裂、btr_node_split对照改为雪花 ID（应用侧生成）并将 id 定长 BIGINT，重复压测，观察 TPS 与 P95 改善幅度。6. 源码走读要点（InnoDB）  btr0cur.cc：B+Tree 游标在右侧页插入与分裂路径；  trx0i_s.cc：自增计数器的持久化与并发控制；  log0write.cc：group commit 对日志刷盘合并的影响。关注点：右侧叶子页 latch 竞争、页分裂代价、secondary index 指针放大。7. 生产变更与回滚手册1) 灰度：在影子表启用新 ID 策略，双写比对一致性（ID 单调、越界、重复）。2) 切换：将业务写流量按 5%/20%/50%/100% 提升；监控写延迟、死锁、页分裂。3) 回滚：保留开关，出现异常立即退回 AUTO_INCREMENT；影子表数据对账。8. 观测指标基线  写延迟 P95/P99、QPS、redo fsync 次数；  btr_page_split、lock_time、待提交事务数；  二级索引大小增幅（变长 PK 带来的指针放大）。9. FAQ  雪花 ID 时钟回拨怎么办？          NTP + 单调时钟守护；回拨检测时暂停发号并降级到号段。        二级索引变大影响查询？          评估热点查询是否可走覆盖索引/缩短选择列；必要时引入只读副本。      "
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/golang/2015/11/02/Go-goroutine%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8E%9F%E7%90%86GMP.html",
    "title": "Go goroutine 调度器原理：GMP",
    "content": "这篇文章不只是“是什么”，而是从语言设计动机与系统实现细节出发，系统性拆解 Go 调度器的三元模型：G（goroutine）、M（OS thread）、P（processor）。围绕“为什么要引入 GMP”“GMP 解决了什么问题”“有哪些代价与权衡”“如何直观理解并用实验证明”，我们给出多维度、可操作的深度解读。一、动机：Go 想解决什么问题？如果回到 2007–2009 年 Go 诞生的背景，Google 内部已经在大规模分布式系统中挣扎：  需要写高并发服务，却要在复杂的回调、线程与锁之间艰难取舍；  线程创建与上下文切换成本高，每个线程动辄 MB 级别栈内存；  I/O 与 CPU 混合型负载让“要么阻塞、要么回调”的模型两头不讨好；  C/C++ 缺少一等公民的并发原语，异步代码可读性差而且脆弱。Go 的答案可以浓缩为三点：  基于 CSP 的并发观：以 goroutine 与 channel 为一等公民，用“看起来可阻塞”的直观代码描述并发；  用户态调度器：把大量 goroutine 以 M:N 方式复用到少量 OS 线程上，降低成本并提升可伸缩性；  面向工程实战：自动栈增长、抢占、网络 poller、分配器与 GC 协同，提供“默认高效、按需可调”的体验。GMP 模型正是在这样的目标约束下诞生：既要“写起来像同步”，又要“跑起来像高性能异步”，还要“在多核机器上自然扩展”。二、设计思想：从 1:1 到 M:N，再到 P 的引入线程模型的历史谱系大致有三类：  1:1（每个用户线程映射一个 OS 线程）：实现简单，但创建/销毁、上下文切换和栈内存都昂贵；  N:1（绿色线程，全在用户态）：切换快，但无法利用多核，遇到系统调用就会整体阻塞；  M:N（用户态与内核态混合）：折中路线，但实现复杂，边界条件众多。Go 选择 M:N，但早期只存在 G 和 M，很快遭遇扩展性与缓存局部性问题：多个 M 抢同一把全局锁从全局 run queue 取任务，导致抖动。Go 1.1 引入 P（processor）作为“执行 goroutine 的逻辑 CPU 配额与本地 run queue”，解决两个核心痛点：  把就绪 G 分散到 P 的本地队列，提升缓存命中并减少锁竞争；  通过 work stealing 在 P 之间均衡负载，避免个别 P 饥饿。因此，GMP 的真实目标不是“多一个字母”，而是让“可伸缩的用户态调度”成为现实。三、模型总览：G、M、P 分工与数量关系  G（goroutine）：用户态轻量执行单元，拥有栈（可动态增长）、状态（就绪/运行/阻塞/等待）与入口函数。  M（machine/OS thread）：真实的内核线程，负责执行 G 的载体。M 必须绑定一个 P 才能运行 Go 代码；无 P 的 M 只能执行 syscalls 或处于空闲。  P（processor）：调度器中的“核”和本地运行队列，数量等于 GOMAXPROCS。每个 P 维护 run queue、runnext 插槽、定时器等。典型约束：  同一时刻最多有 GOMAXPROCS 个 M 持有 P 并并行执行 Go 代码；  G 的创建很廉价，调度器倾向把新 G 放入当前 P 的 run queue；  无事可做的 P 会从全局队列或其他 P 窃取 G（work stealing）。四、调度循环：一条 G 的旅程1) 创建/就绪：go f() 创建 G，优先放进当前 P 的本地队列；2) 取出与执行：持有该 P 的 M 从 run queue 取 G，放到寄存器与栈上开始执行；3) 阻塞分流：  如果 G 调用 syscall/cgo 进入内核阻塞，M 也会阻塞；调度器把“被困”的 P 转借给其他空闲的 M，以保证 GOMAXPROCS 并行度；  如果 G 因 channel/锁/I/O 等用户态阻塞，M 让出当前 G，切回调度器，从本地队列或其他 P 继续取活；  网络 I/O 由 netpoller（epoll/kqueue/IOCP）负责等待并唤醒相关 G；4) 抢占与让出：  协作式：函数 prologue 设置安全点，允许在调用边界被切走；  异步抢占（Go 1.14 起）：runtime 可向线程注入信号，在抢占安全点强制把 G 让出，避免大计算长期独占；5) 完成与回收：G 正常返回或 panic 结束后，M 继续从队列取下一个 G。五、关键机制详解5.1 本地队列、全局队列与 runnext  本地队列：每个 P 维护一个环形队列，push/pop 均无锁或轻锁；  全局队列：系统级备用队列，多个 P 在饥饿时会从中批量拉取；  runnext：为提升缓存命中，调度器保留“下一个立刻运行”的插槽（如 go ready 刚唤醒的 G）。5.2 Work Stealing当某个 P 的队列耗尽，会从全局队列或随机挑选另一个 P 窃取一半任务（按块移动），在保持均衡的同时减少锁冲突。该策略在大规模 goroutine 场景下显著降低尾延迟。5.3 系统调用与 M/P 解耦对于可能长时间阻塞的内核调用：  进入 syscall 前记录状态；  M 进入内核后若长时间不返回，调度器将其 P 迁出给其他可运行的 M；  当 syscall 返回，若原 P 已被转移，则尝试从全局获取 P 或把 G 放回队列等待调度。5.4 NetpollerGo 的网络库用平台相关的 poller 将“看似阻塞的 Read/Write”转为“注册事件 + 等待唤醒”。当事件就绪，poller 把对应 G 标记为 runnable，放回某个 P 的队列。这是“看似同步、实则异步”的关键一环。5.5 抢占：从协作到异步早期 Go 主要依赖协作式抢占，即在函数调用边界（safe point）让出。对于紧密循环或内联后的长计算，可能长时间不让出，导致延迟抖动。Go 1.14 引入异步抢占：  runtime 向执行线程注入抢占信号；  在线程到达可抢占的安全点（如栈检查、轮询点）时挂起 G，切回调度器；  减少“计算型 goroutine”对系统的拖滞，提升吞吐与 P99 延迟。5.6 栈管理goroutine 使用“连续可增长栈”，初始很小（KB 级），随着深度增长按需扩容（拷贝并修正栈指针）。这使得创建百万 goroutine 成为可能，也与调度器的轻量切换协同增效。5.7 与 GC 的协作调度器与 GC 紧密耦合：  标记辅助（mutator assist）在分配压力大时让运行的 G 协助标记；  写屏障保证并发标记期正确性；  STW 窗口尽量缩小，但仍需要在世界停止时统一栈扫描与根收集；  抢占点也服务于 GC 对“尽快看到所有栈”的诉求。5.8 系统监控线程（sysmon）后台监控 goroutine/线程状态、定时器、抢占信号、垃圾回收触发等，是调度系统“保安 + 协调员”。六、GMP 解决了哪些实际问题？  低成本并发原语：创建/销毁 goroutine 成本远低于线程，栈按需增长；  多核可伸缩：GOMAXPROCS 决定并发执行 goroutine 的上限，通过 P 的本地队列与 stealing 在多核扩展；  同步代码风格的高性能 I/O：netpoller 让“看起来阻塞”的 API 拥有“异步性能”；  更好地处理混合负载：系统调用阻塞与用户态阻塞分流，保持整体吞吐；  可观测性与可调优：pprof、trace、schedtrace 等工具帮助定位性能瓶颈与调度异常。七、权衡与潜在弊端  实现复杂度高：调度器、GC、分配器、netpoller 的耦合提升了 runtime 复杂性与维护难度；  尾延迟与公平性：尽管有抢占与 stealing，极端负载下仍可能出现饥饿或抖动；  syscall/cgo 交互成本：频繁进入内核或调用 C 代码，会触发 P 迁移/线程增减，影响稳定性与预测性；  G 泄漏更隐蔽：看似阻塞的 goroutine 更容易“被遗忘”，如未消费的 time.After、无界 channel；  调参误区：盲目调大 GOMAXPROCS 可能加剧锁竞争与切换开销，未必提升吞吐；  平台细节差异：netpoller 依赖 epoll/kqueue/IOCP，不同平台边界行为可能不同。八、如何直观理解：一个工厂的类比把 P 想象成“装配线”，M 是“工人”，G 是“待加工的零件”：  每条装配线（P）有自己的待加工队列（本地 run queue），减少不同线之间的争抢；  工人（M）必须绑定一条装配线才能干活；  如果某条线不饱和，工人会去别的线“偷”一半零件回来（work stealing）；  遇到需要外部检验（syscall）时，工人要暂时离开车间，但这条线会很快分配给另一名工人，保证机器不停；  车间主任（sysmon）偶尔会打断某个工人，防止他在一个零件上磨蹭太久（异步抢占）。一个近似的 ASCII 示意：P0(runq) ←→ M0  执行 G...P1(runq) ←→ M1  执行 G...P2(runq) ←→ M2  执行 G...       ↖ stealing ↗   全局队列 / netpoller 唤醒九、实验：观察 GOMAXPROCS 与调度行为下面的程序用递归 fib 制造 CPU 压力，观察不同 GOMAXPROCS 的吞吐变化（实际结果取决于机器核数与调度器负载）。package mainimport (  \"runtime\"  \"sync\"  \"time\"  \"fmt\")func fib(n int) int { if n &lt; 2 { return n }; return fib(n-1)+fib(n-2) }func main() {  for _, p := range []int{1,2,4,8} {    runtime.GOMAXPROCS(p)    var wg sync.WaitGroup    start := time.Now()    for i := 0; i &lt; 100000; i++ {      wg.Add(1)      go func(){ _ = fib(20); wg.Done() }()    }    wg.Wait()    fmt.Println(\"P=\", p, \"cost=\", time.Since(start))  }}观察调度轨迹：GODEBUG=schedtrace=1000,scheddetail=1 ./app# 也可打开 pprof：# go tool pprof -http=:0 http://localhost:6060/debug/pprof/profile示例：对“长计算不让出”的可观测性（Go 1.14 前后对比思路）：// 紧密循环若无函数调用，旧版本更难被协作式抢占，// 新版的异步抢占可显著改善系统整体延迟。func busyLoop(deadline time.Time) {  for time.Now().Before(deadline) {    // 做一些计算  }}十、可观测性：trace/pprof/schedtrace 看什么  schedtrace：周期打印 P/M/G 的数量、全局/本地队列长度、spinning 线程数，快速判断是否存在饥饿或过度抢占；  pprof：          CPU profile 看热点函数与调度器开销；      Block profile 观察 channel/互斥等待；      Mutex profile 关注 runtime 锁与业务锁竞争；        go tool trace：时间轴上展示 G 的生命周期变化、网络事件与 syscalls，更直观地定位抖动来源。十一、实战建议与反模式  合理设置 GOMAXPROCS：通常默认即可。CPU 密集场景接近物理核心数；过大只会带来锁竞争与切换成本；  避免无界 goroutine：对输入做限流，用 worker pool 或 errgroup；  小心 time.After 泄漏：未读取的计时器会保留 G；可改用 time.NewTimer 并 Stop；  处理 syscall/cgo：尽量缩短阻塞时间，必要时隔离到专用池或进程；  使用 context 超时/取消：避免永久阻塞 goroutine；  明确选择 channel 与 mutex：小临界区用锁更直白，复杂编排用 channel 更可靠；  对热点路径保持函数边界：协作式抢占仍依赖安全点，过度内联与紧密循环要谨慎；  善用 pprof/trace：在压测环境下先度量再优化，避免拍脑袋调参。十二、常见问答  为什么不是 1:1？线程创建/栈成本与上下文切换太高，难以支撑数十万并发；  为什么不是 N:1？无法用多核并行，一次 syscall 可能阻塞整个进程；  P 的存在感是什么？减少全局争用、提升局部性，并成为并发度的“配额器”；  抢占是否 100% 及时？不是。异步抢占已大幅改善，但仍依赖安全点；  goroutine 真的“无限便宜”吗？不是。内存、调度、GC 都付成本；设计时要有边界与限流。十三、小结GMP 模型是 Go“以工程为中心”的体现：  以 goroutine/channel 的直观抽象降低并发编程的心智负担；  以用户态调度与 P 的本地队列/work stealing 实现高伸缩；  以 netpoller 与异步抢占保证 I/O 与计算的双向友好；  以完善的可观测性工具支撑“先度量再优化”的最佳实践。它并不完美，但在“简单可用”与“高性能可伸缩”之间给出了极佳的工程折中。这也是 Go 在云原生时代持续流行的底层原因之一。附：命令速查# 调度打印（每秒一次）GODEBUG=schedtrace=1000,scheddetail=1 ./app# 运行时剖析（HTTP pprof）go run main.go &amp;go tool pprof -http=:0 http://localhost:6060/debug/pprof/profile# 时间轴跟踪go test -run=NONE -bench=BenchmarkX -trace trace.out ./...go tool trace trace.out"
  },

  {
    "url": "/%E6%8A%80%E6%9C%AF/java/2015/09/08/Java-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8F%AF%E8%A7%81%E6%80%A7%E5%AE%9E%E8%B7%B5.html",
    "title": "Java 内存模型与可见性实践",
    "content": "JMM（Java Memory Model）定义了线程间可见性、原子性与有序性。本文通过可复现案例解释 volatile、happens-before、指令重排与发布/逃逸，并给出 JIT 层面的观测方法。1. 可见性问题复现public class StopFlagDemo {  // 去掉 volatile 观察现象  static /*volatile*/ boolean stop = false;  public static void main(String[] args) throws Exception {    new Thread(() -&gt; { while (!stop) { } }).start();    Thread.sleep(100);    stop = true;  }}无 volatile 时，JIT 可能将 stop 缓存至寄存器，循环无法观察到主线程写入。2. JIT 观测（hsdis/PrintAssembly）启动参数：-XX:+UnlockDiagnosticVMOptions -XX:+PrintCompilation -XX:+PrintAssembly观察 volatile 写前后的屏障指令（如 x86 的 lock 前缀原子指令 / mfence）。3. 指令重排与双检锁class LazySingleton {  private static volatile LazySingleton INSTANCE;  static LazySingleton get() {    if (INSTANCE == null) {      synchronized (LazySingleton.class) {        if (INSTANCE == null) INSTANCE = new LazySingleton();      }    }    return INSTANCE;  }}volatile 避免构造重排导致的“引用可见但对象未完成初始化”。4. Happens-Before 速查  程序次序、监视器锁、volatile、线程启动/终止、传递性。5. 排错清单  自旋等待变量需 volatile 或原子类；  不要在锁外读写与锁内读写混用同一状态；  使用 jcmd VM.print_touched_methods、jfr 观测热点与锁竞争。6. JMM 与内存屏障的演进（JSR-133）  JDK 5 以前（JSR-133 之前），内存模型对 volatile 与 final 的约束较弱，双检锁（DCL）可能失效。  自 JDK 5（JSR-133）起：          volatile 写建立 Store-Store 与 Store-Load 语义；volatile 读建立 Load-Load 与 Load-Store 语义（等价于写的释放、读的获取）。      final 字段发布语义明确：构造完成后对其它线程可见，避免“半初始化”。        抽象屏障分类（便于理解，具体实现依赖平台）：          LoadLoad, LoadStore, StoreStore, StoreLoad      一般而言：volatile 写 ~ Release（StoreStore + StoreLoad），volatile 读 ~ Acquire（LoadLoad + LoadStore）。      7. HotSpot 在不同硬件上的实现（概览）不同平台的内存一致性与可用指令不同，HotSpot 会在 C1/C2 后端针对性插入屏障/选用原子指令。7.1 x86/x64（TSO）  天然较强（Total Store Order）：已保证 LoadLoad / LoadStore，有风险的是 StoreLoad。  常见映射（HotSpot 版本与编译后端可能差异）：          volatile 写：使用带 lock 前缀的原子指令（如 lock xchg、lock add 0），或显式 mfence，以形成 Full Fence，确保写-读不可越过。      volatile 读：通常普通 mov 即可满足 Acquire 语义（TSO 已保证读的顺序），必要时可能配合轻量栅栏。        CAS/原子操作：lock cmpxchg，天然携带全栅栏语义。示例（节选，不同 JDK/编译器可能略有不同，仅供识别思路）：; volatile store 之前/之后的栅栏lock addl $0x0, (%rsp)   ; 作为全栅栏（或使用 mfence）mov DWORD PTR [field], eax ; 实际写入7.2 AArch64（ARMv8）  指令级提供获取/释放语义：          LDAR（acquire load）/ STLR（release store）      显式全栅栏：DMB ish        常见映射：          volatile 读：LDAR      volatile 写：STLR      VarHandle.fullFence() / Unsafe.fullFence()：DMB ish      7.3 其它（简述）  ARMv7：ldrex/strex + dmb 组合；  PPC：lwsync（轻量栅栏）、sync（全栅栏）。  关键点：JMM 语义是上层抽象，HotSpot 在不同平台选用“能满足该语义的最弱指令组合”，以减少开销。8. VarHandle 与 Unsafe 的屏障对应现代 JDK 推荐使用 VarHandle 指定精确的内存语义：  访问语义：getAcquire / setRelease / getOpaque / setOpaque / getVolatile / setVolatile  栅栏语义：VarHandle.acquireFence()、releaseFence()、fullFence()大致映射关系：  Acquire/Release -&gt; 对应硬件 acquire/release（如 AArch64 的 LDAR/STLR）；  Volatile -&gt; acquire + release（按点位插入栅栏，或选用更强指令）；  FullFence -&gt; 全序列栅栏（x86 可用 mfence 或 lock 原子操作；AArch64 用 dmb ish）。Unsafe（不推荐新代码使用）也提供：storeFence()、loadFence()、fullFence()，与 VarHandle 栅栏语义对应。9. hsdis 观测指引（示例）以 volatile 写为例，打开 -XX:+PrintAssembly 后，在输出中搜索目标方法：; ...; 关键位置常见：lock addl $0x0,(%rsp)   ; 或 mfence，形成 StoreLoad 屏障mov    %eax,0xNN(%rbx)  ; 写入 volatile 字段; ...在 AArch64：stlr    w0, [x1]        ; release store 到 volatile 字段说明：不同 JDK/编译器（C1/C2）、优化级别与 CPU 平台会有差异，识别“是否具备 acquire/release/全栅栏”语义是核心。10. 实战建议（落地）  选择合适语义：          只需要“发布事件/状态位”的写：setRelease；对应读取用 getAcquire。      必须与既有 volatile 交互且要求最强语义：使用 getVolatile/setVolatile。      仅跨线程传递“可能乱序但最终一致”的值：getOpaque/setOpaque（更弱，开销小）。        避免无谓全栅栏：全栅栏成本高，在热点路径优先 acquire/release 组合。  发布对象：          使字段 final，或在构造完毕后通过 volatile/release 语义发布；      避免“逃逸未完成初始化”的引用外泄。        诊断与基线：          用 JFR 观测锁竞争/线程状态；      用 hsdis 验证关键点的指令是否达成预期语义（仅在关键问题排查时使用）。      "
  }

]


